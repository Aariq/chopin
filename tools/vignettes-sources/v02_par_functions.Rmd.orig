---
title: "Parallelize spatial data operations"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Distribute computational workloads over multiple threads}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Plan

- Be planned before you distribute your workload to multiple threads. Major points include:
    - The peak memory consumption of your process with a small dataset: you can employ the power of parallel processing as far as your computational assets allow. The total memory size may be the highest hurdle for this. Users are strongly recommended to run a small (e.g., target points in a computational grid) example then estimate the total memory demand. Roughly speaking, your machine should be equipped with the memory exceeding (number of threads to be drawn) * (the peak memory usage per thread).
    - Small datasets are good with the single-thread processing: this package leverages `terra` and `exactextractr` in major processing helper functions. They are based on C++ backends, where users can get a decent performance with just one thread and a relatively small amount of memory capacity. Factors to choose to stay single-thread or go on with multi-thread processing are:
        - The spatial and temporal resolutions of raster datasets
        - The spatial extent and study period
        - The number of points to be processed
        - Other factors affect the intermediate products' complexity: when you use a set of polygons to summarize raster values, the intermediate memory consumption will depend on the number of vertices in polygon datasets. We recommend users simplify complex polygon features before processing if the simplification does not or trivially impact the expected results. 
        - These factors interact; for instance, even if the raster has a fine resolution and the large spatial extent, you will not find any performance gain with multi-thread processing when you have a small number of points to process.



```{r, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

- A motivating example is extracting mean elevation at 10 kilometers circular point buffers using digital elevation model (DEM) data from Shuttle Radar Topography Mission satellite. We prepared the dataset from `elevatr` package. You may consult the package tutorial for retrieving data directly from OpenTopography via `elevatr`.

- We start with a polygon dataset in North Carolina. This dataset is included in `sf` package.

```{r}
library(chopin)
library(dplyr)
library(sf)
library(terra)
library(future)
library(future.apply)
library(doFuture)
library(tigris)
options(sf_use_s2 = FALSE)
set.seed(2023, kind = "L'Ecuyer-CMRG")

```


# Use case 1: mean elevation at circular points buffers

```{r}
ncpoly <- system.file("shape/nc.shp", package = "sf")
ncsf <- sf::read_sf(ncpoly)
ncsf <- sf::st_transform(ncsf, "EPSG:5070")
plot(sf::st_geometry(ncsf))
```

- To demonstrate, a set of 1,000 random points are generated inside the polygons:

```{r point-generation}
ncpoints <- sf::st_sample(ncsf, 10000)
plot(sf::st_geometry(ncpoints))

# st_sample output is st_sfc. We should convert it to sf
ncpoints <- sf::st_as_sf(ncpoints)
ncpoints$pid <- seq(1, nrow(ncpoints))

```

- SpatRaster objects in `terra` package should be serialized to compress then reuse elsewhere. For serialization and de-serialization, `terra::wrap` and `terra::unwrap` need to be used.

```{r load-srtm}
srtm <- terra::unwrap(readRDS("../../tests/testdata/nc_srtm15_otm.tif"))
srtm
plot(srtm)
terra::crs(srtm) <- "EPSG:5070"
```

- Modern computers usually have more than two threads, which enables users to perform many tasks at the same time. Provided that users have machines with sufficient memory, which runs much faster than network or storage, one can reduce the total processing time by employing multiple threads for processing data.
- Users need to consider several things before leveraging multi-thread processing in geospatial computation:
    - The computation task should be divisible: the simplest statement would be the computation at each split must not be related to another.
    - Each dataset for processing needs to be split beforehand.
    - Know the characteristics of function you want to parallelize:
        - Does the function call entire data into memory or refer to the location then read values on demand?
        - Does the function work with parallel processing?

### Single-thread processing
```{r process-single}
ncpoints_tr <- terra::vect(ncpoints)
system.time(
    ncpoints_srtm <-
        chopin::extract_at(
            vector = ncpoints_tr,
            raster = srtm,
            id = "pid",
            mode = "buffer",
            radius = 1e4L) # 10,000 meters (10 km)
)
```


### Multi-thread processing
- Given that the data are distributed across North Carolina, we will consider splitting the points into subregions by grids.
- `scomps` package has `par_pad_grid` to help splitting the entire study region.
    - Please note that `par_pad_grid` will accept `padding` argument, by which users can get _padded_ grids to avoid missing raster cells from original unit grid boundaries.

```{r generate-compregion}
compregions <-
    chopin::par_pad_grid(
        ncpoints_tr,
        mode = "grid",
        nx = 8L,
        ny = 5L,
        padding = 1e4L
    )

names(compregions)

oldpar <- par()
par(mfcol = c(1, 2))
plot(compregions$original, main = "Original grids")
plot(compregions$padded, main = "Padded grids")
par(oldpar)
```

In the figure above, the padded grids have overlaps one another. `par_pad_grid` automatically expand a little more than the input argument `padding`.

Now, we will distribute the computational process for these grids.

```{r process-multithread}
plan(multicore, workers = 4L)
doFuture::registerDoFuture()

system.time(
    ncpoints_srtm_mthr <-
        chopin::par_grid(
            grids = compregions,
            grid_target_id = NULL,
            fun_dist = chopin::extract_at,
            vector = ncpoints_tr,
            raster = srtm,
            id = "pid",
            mode = "buffer",
            radius = 1e4L
        )
)

```


```{r check-equal-results}
ncpoints_srtm_mthr <-
    ncpoints_srtm_mthr[order(ncpoints_srtm_mthr$pid),]
all.equal(ncpoints_srtm, ncpoints_srtm_mthr)


```

Let's find what the results look like.

```{r vis-results}
ncpoints_s <-
    merge(ncpoints, ncpoints_srtm)
ncpoints_m <-
    merge(ncpoints, ncpoints_srtm_mthr)

plot(ncpoints_s[, "mean"], main = "Single-thread")
plot(ncpoints_m[, "mean"], main = "Multi-thread")
```



## Distribute computation through geographic hierarchy
- We consider "hierarchy," which is usually embedded in many geospatial datasets. Suppose we want to summarize elevation across census geographies in North Carolina. The census geographies are highly organized in order; think of state, counties, zip code areas, census tracts, block groups, and blocks. Some of these are exhaustive to the higher order geographies (e.g., census block groups are exhaustively delineated in a census tract), whereas some do not (not all zip code areas are exhaustively covered by a county).
- In this example, we consider census tracts and counties to distribute the computation task for mean elevation values at census tracts over counties.


```{r get-hierarchy}
nc_county <- file.path("../testdata/nc_hierarchy.gpkg")
nc_county <- sf::st_read(nc_county, layer = "county")

nc_tracts <- file.path("../testdata/nc_hierarchy.gpkg")
nc_tracts <- sf::st_read(nc_tracts, layer = "tracts")

nc_county <- sf::st_transform(nc_county, "EPSG:5070")
nc_tracts <- sf::st_transform(nc_tracts, "EPSG:5070")
nc_tracts$COUNTY <-
    substr(nc_tracts$GEOID, 1, 5)
```

## Single-thread processing

```{r}
system.time(
    nc_elev_tr_single <- chopin::extract_at(
        vector = nc_tracts,
        raster = srtm,
        id = "GEOID",
        mode = "polygon"
    )
)
```

## Multi-thread processing through hierarchy

```{r}
system.time(
    nc_elev_tr_distr <-
        chopin::par_hierarchy(
            regions = nc_county, # higher level geometry
            regions_id = "GEOID", # higher level unique id
            fun_dist = chopin::extract_at,
            vector = nc_tracts, # lower level geometry
            raster = srtm,
            id = "GEOID", # lower level unique id
            func = "mean"
        )
)

```

It is clearly shown that several thousands of features may not get benefits from parallel processing. However, this approach will be helpful when each geographic area is large and the raster data is too large to handle.



## Multi-thread processing over large rasters

In many cases users have parallelized over multiple files, i.e., large raster files. Leveraging memory-saving `terra`'s C++ pointers, users will want to use `par_multirasters`, where they are assumed to have the raster file paths to distribute. In standard vector-raster overlays, `distribute_process_multirasters` will help especially when users have multiple sizable raster files to extract values with moderately sized vectors.


```{r multirasters}
ncpath <- "../testdata/nc_hierarchy.gpkg"
nccnty <- terra::vect(ncpath, layer = "county")
ncelev <- terra::unwrap(readRDS("../testdata/nc_srtm15_otm.tif"))
terra::crs(ncelev) <- "EPSG:5070"
names(ncelev) <- c("srtm15")
tdir <- tempdir()
terra::writeRaster(ncelev, file.path(tdir, "test1.tif"), overwrite = TRUE)
terra::writeRaster(ncelev, file.path(tdir, "test2.tif"), overwrite = TRUE)
terra::writeRaster(ncelev, file.path(tdir, "test3.tif"), overwrite = TRUE)
terra::writeRaster(ncelev, file.path(tdir, "test4.tif"), overwrite = TRUE)
terra::writeRaster(ncelev, file.path(tdir, "test5.tif"), overwrite = TRUE)

testfiles <- list.files(tempdir(), pattern = "*.tif$", full.names = TRUE)
testfiles
```


```{r multirasters-processing}
res <- chopin::par_multirasters(
      filenames = testfiles,
      fun_dist = chopin::extract_at_poly,
      polys = nccnty,
      surf = ncelev,
      id = "GEOID",
      func = "mean"
    )

knitr::kable(head(res))
```

## Distributing sf/terra functions

Users also can pass generic terra functions to multiple threads.

Some considerations apply:
- If a function to calculate the nearest distance, edge cases may present especially when the target dataset are too sparse to be located in the padded calculation extent. For example, when users want to distribute `terra::nearest()` to calculate the nearest distance from ranch locations to the primary roads, some ranch locations might have no destination primary roads if the calculation grids are too finely defined.
- We strongly assume that users have unique identifiers in input data. The passed argument in `par_*` functions is expected to include `id` argument to designate the origin locations' unique identifiers.


### Example
- The example below shows how to distribute a `terra` function `nearest` is distributed over regular computational grids.


```{r generic-distribution}
pnts <- readRDS("../testdata/nc_random_point.rds")
pnts <- terra::vect(pnts)
rd1 <- terra::vect(
    file.path("../testdata/ncroads_first.gpkg"))

pnts <- terra::project(pnts, "EPSG:5070")
rd1 <- terra::project(rd1, "EPSG:5070")


nccompreg <-
    chopin::par_pad_grid(
                             input = pnts,
                             mode = "grid",
                             nx = 6L,
                             ny = 4L,
                             padding = 3e4L)
  
future::plan(future::multicore, workers = 6L)

system.time(
res <-
  chopin::par_grid(
                   grids = nccompreg,
                   fun_dist = terra::nearest,
                   x = pnts,
                   y = rd1)
)



system.time(
  restr <- terra::nearest(x = pnts, y = rd1)
)
knitr::kable(head(res))
knitr::kable(head(restr))
```

