---
title: "Creating the ``r params$package_name`` R package"
author: "Insang Song"
date: "2023-11-17"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "scomps" # <-- change this to your package name
  package_parent_dir: "." # <-- relative to this file's location
---

<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->

## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.0.5.11172023",
    Title = "Scalable R geospatial computation",
    Description = "A package for scalable geospatial computation for environmental health research",
    `Authors@R` = person(
      given = "Insang",
      family = "Song",
      email = "geoissong@gmail.com",
      role = c("aut", "cre"),
      comment = c(ORCID = "0000-0001-8732-3256")
      )
  )
)
#usethis::use_build_ignore("rds$", escape = FALSE)
usethis::use_build_ignore("/tools/*", escape = FALSE)
usethis::use_package("dplyr")
usethis::use_package("sf")
usethis::use_package("terra")
usethis::use_package("stars")
usethis::use_package("rlang")
usethis::use_package("testthat")
usethis::use_package("units")
usethis::use_package("methods")
usethis::use_package("progressr")
usethis::use_package("exactextractr")
usethis::use_package("future")
usethis::use_package("future.apply")
usethis::use_package("covr")
usethis::use_package("logr", "Suggests")
usethis::use_package("future.batchtools", "Suggests")
usethis::use_package("igraph", "Suggests")
usethis::use_package("withr", "Suggests")
# usethis::use_gpl3_license()
usethis::use_mit_license(copyright_holder = "I. Song")


# usethis::use_vignette("scomps_1_setting_distribution.rmd")
```
<!--
-->

```{r}
# parallelly::availableCores()
# plan(future.batchtools::batchtools_slurm)

```


### Test data generation
```{r generate-test-data, eval=FALSE, include=FALSE}
OPENTOPO_CREDENTIAL <- ""

pkgs <- c("sf", "terra", "dplyr", "spatstat.random", "elevatr")
invisible(sapply(pkgs, library, character.only = TRUE, quietly = TRUE))
elevatr::set_opentopo_key(OPENTOPO_CREDENTIAL)
sf::sf_use_s2(FALSE)
set.seed(300)
ncpath <- system.file("shape/nc.shp", package = "sf")
ncpoly <- sf::read_sf(ncpath) %>%
  sf::st_transform("EPSG:5070")

ncrandpoint <- sf::st_sample(type = "Thomas", x = ncpoly, size = 300, mu = 0.00005, scale = 16000, kappa = 0.00005) %>%
  mutate(pid = seq_len(nrow(.))) %>%
  select(-label)
sf::st_crs(ncrandpoint) <- "EPSG:5070"
saveRDS(ncrandpoint, "./tests/testdata/nc_random_point.rds")

ncrast <- elevatr::get_elev_raster(ncpoly, z = 9, src = "srtm15plus", prj = terra::crs("EPSG:5070"))
ncrastt <- terra::rast(ncrast)
ncrastw <- terra::wrap(ncrastt)
# terra::writeRaster(ncrastt, "./tests/testdata/nc_srtm15_otm.tif", gdal=c("COMPRESS=DEFLATE"), overwrite = TRUE)
saveRDS(ncrastw, "./tests/testdata/nc_srtm15_otm.rds", compress = "xz")

library(nhdplusTools)
huc08s <- get_huc(AOI = sf::st_union(ncpoly), buffer = 10000L, type = "huc08")
library(readxl)

ecors <- list.files(path = "/Users/songi2/Documents/Ecoregions/",
  pattern = "*.xlsx", full.names = TRUE) %>%
  .[-length(.)] %>%
  lapply(\(x) readxl::read_excel(x, sheet = 4)) %>%
  do.call(bind_rows, .)

huc08sadd <- left_join(huc08s, ecors, by = c("huc8" = "Hydrologic Unit Code 8-Digit (HUC8)")) %>%
  select(-1:-12, -globalid)
huc08sadd
saveRDS(huc08sadd, "./tests/testdata/huc08_nc.rds", compress = "xz")
```


### Vignettes 1

```{r}
litr::add_vignettes("../tools/vignettes-sources/v00_good_practice_parallelization.Rmd")
```

### Vignettes 2

```{r}
litr::add_vignettes("../tools/vignettes-sources/v01_generate_computational_grid.Rmd")
```


# Now to the package itself

### Create functions
```{r, send_to = "R/check.R"}
#' @title Return the package the input object is based on
#' @description Detect whether the input object is sf or Spat* object.
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @return A character object; one of 'terra' and 'sf'
#' @export
check_packbound <- function(input) {
  # cl_inobj = class(input)[1]
  stopifnot("Input should be one of sf or Spat* object.\n" = any(methods::is(input, "sf"), methods::is(input, "stars"), methods::is(input, "SpatVector"), methods::is(input, "SpatRaster")))
  if (methods::is(input, "SpatVector") || methods::is(input, "SpatRaster")) {
    return("terra")
  }
  return("sf")
}

check_datatype <- function(input) {
  stopifnot("Input should be one of sf or Spat* object.\n" = any(methods::is(input, "sf"), methods::is(input, "stars"), methods::is(input, "SpatVector"), methods::is(input, "SpatRaster")))
  if (any(methods::is(input, "SpatVector"), methods::is(input, "sf"))) {
    return("vector")
  }
  if (any(methods::is(input, "SpatRaster"), methods::is(input, "stars"))) {
    return("raster")
  }
}
```

```{r test-packbound}
testthat::test_that("What package does the input object belong?",
{
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
  bcsd_stars <- stars::read_stars(bcsd_path)

  packbound_stars <- check_packbound(bcsd_stars)
  sprast_bcsd <- terra::rast(bcsd_path)
  packbound_terra <- check_packbound(sprast_bcsd)

  testthat::expect_equal(packbound_stars, "sf")
  testthat::expect_equal(packbound_terra, "terra")
})


testthat::test_that("What package does the input object belong?",
{
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
  bcsd_stars <- stars::read_stars(bcsd_path)

  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)

  datatype_stars <- check_datatype(bcsd_stars)
  datatype_sf <- check_datatype(nc)

  testthat::expect_equal(datatype_stars, "raster")
  testthat::expect_equal(datatype_sf, "vector")
})
```

```{r, send_to = "R/switch_format.R"}
#' @title Switch spatial data class
#' @description Convert stars into SpatRaster and vice versa; sf into SpatVector and vice versa.
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @return Data converted to the other package class (if sf, terra; if terra, sf)
#' @export
switch_packbound <- function(input) {
  stopifnot("Input should be one of sf or Spat* object.\n" = any(methods::is(input, "sf"), methods::is(input, "stars"), methods::is(input, "SpatVector"), methods::is(input, "SpatRaster")))
  cls_input <- check_packbound(input)
  type_input <- check_datatype(input)

  switched <-
  switch(cls_input,
    sf = switch(type_input,
      vector = terra::vect(input),
      raster = terra::rast(input)
    ),
    terra = switch(type_input,
      vector = sf::st_as_sf(input),
      raster = stars::st_as_stars(input)))

  invisible(switched)
}
```


```{r test-format}

testthat::test_that("Format is well converted",
{
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
  bcsd_stars <- stars::read_stars(bcsd_path)
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)

  stars_bcsd_tr <- switch_packbound(bcsd_stars)
  sf_nc_tr <- switch_packbound(nc)

  testthat::expect_equal(check_packbound(stars_bcsd_tr), "terra")
  testthat::expect_equal(check_packbound(sf_nc_tr), "terra")

  stars_bcsd_trb <- switch_packbound(stars_bcsd_tr)
  sf_nc_trb <- switch_packbound(sf_nc_tr)

  testthat::expect_equal(check_packbound(stars_bcsd_trb), "sf")
  testthat::expect_equal(check_packbound(sf_nc_trb), "sf")

})


```

```{r, send_to = "R/check.R"}
#' @title check_crs2: Coordinate system checker
#' @description The input is checked whether its coordinate system is present. If not, it is reprojected to EPSG:5179.
#' @param input Input object one of sf or terra::Spat* object
#' @param crs_standard character(1). A standard definition of coordinate reference system. Default is "EPSG:4326" Consult [epsg.io](https://epsg.io) for details of other CRS.
#' @return A (reprojected) sf or SpatVector object.
#' @export
check_crs2 <- function(
  input,
  crs_standard = "EPSG:4326") {
  check_crs_sf <- function(input) {
    if (is.na(sf::st_crs(input))) {
      cat('Please check the coordinate system or its EPSG code of your input object.')
      return(NULL)
    }
    if (sf::st_crs(input)$epsg == crs_standard) {
      return(input)
    } 
    input_transformed <- sf::st_transform(input, sf::st_crs(crs_standard))
    return(input_transformed)
  }

  check_crs_terra <- function(input) {
    if (terra::crs(input, describe = TRUE)$code == crs_standard) {
      return(input)
    }
    input_transformed <- terra::project(input, terra::crs(crs_standard))
    return(input_transformed)
  }

  detected <- check_packbound(input)
  switch(detected,
    terra = check_crs_terra(input),
    sf = check_crs_sf(input))
}
```

```{r, send_to = "R/validate.R"}
#' Validate and repair input vector data
#' @description It tries repairing input vector data. Vector validity violation usually appears in polygon data with self-crossing or hole orders. This function will pass the input_vector object to sf::st_make_valid() (if input_vector is sf) or terra::makeValid() (if input_vector is SpatVector). May take some time depending on the geometry complexity.
#' @author Insang Song
#' @param input_vector One of sf or vect class. Target points of computation.
#' @return A repaired sf or SpatVector object depending on the class of input_vector.
#' @export
validate_and_repair_vectors <- function(input_vector) {
  detected <- check_packbound(input_vector)

  validated <- switch(detected,
    terra = terra::makeValid(input_vector),
    sf = sf::st_make_valid(input_vector))

  return(validated)
}

```


```{r test-validate}
testthat::test_that("vector validity check is cleared", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)

  testthat::expect_no_error(validate_and_repair_vectors(nc))

  nct <- terra::vect(nc)
  testthat::expect_no_error(validate_and_repair_vectors(nct))
})

```


```{r, send_to = "R/logging.R"}
#' Turn on logging
#' @author Insang Song
#' @param expr expression. Any function call to be logged.
#' @param dolog logical(1). Will the messages be logged.
#' @param logpath character(1). Log file path with the full log file name.
#' @return Nothing. It will export a log file in the specified path as logpath.
#' @export
initate_log <- function(
  expr,
  dolog = FALSE,
  logpath) {
  if (!dolog) {
    return(NULL)
  }
  logr::log_path(logpath)
  try(expr)
  logr::log_close()
  return(NULL)
}


```

```{r, send_to = "R/preprocessing.R"}
#' Setting the clipping extent
#' @description Return clipping extent with buffer radius. It assumes the input CRS is projected and linear unit is meters.
#' @author Insang Song
#' @param pnts One of sf or vect class. Target points of computation.
#' @param buffer_r numeric(1). Buffer radius. It is assumed in metres 
#' @return A terra::ext or sfc_POLYGON object of the computation extent.
#' @export
set_clip_extent <- function(
  pnts,
  buffer_r) {
  detected <- check_packbound(pnts)
  if (detected == "terra") {
    ext_input <- terra::ext(pnts)
    # Note that `+` operation on
    # terra::ext output accounts for the operand as it is.
    ext_input <- ext_input + (1.1 * buffer_r)
  }
  if (detected == "sf") {
    ext_input <- pnts |> sf::st_bbox()
    # Note that `+` operation on st_bbox output
    # simply adds the number; we add a vector here.
    ext_input <- ext_input + ((1.1 * c(-1, -1, 1, 1) * buffer_r))
    ext_input <- sf::st_as_sfc(ext_input)
  }
  return(ext_input)
}
```


```{r test-clip}
testthat::test_that("Clip extent is set properly", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("shape/nc.shp", package = "sf")
  suppressWarnings(nc <- sf::read_sf(ncpath) |>
    sf::st_transform("EPSG:5070") |>
    sf::st_centroid())

  radius <- 1e4L

  (nc_ext_sf <- set_clip_extent(nc, radius))

  nct <- terra::vect(nc)
  (nc_ext_terra <- set_clip_extent(nct, radius))

  (proper_xmin <- sf::st_bbox(nc)[1] - (1.1 * radius))

  testthat::expect_s3_class(nc_ext_sf, "sfc")
  testthat::expect_s4_class(nc_ext_terra, "SpatExtent")

  nc_ext_sf_1 <- sf::st_bbox(nc_ext_sf)[1]
  nc_ext_terra_1 <- nc_ext_terra[1]

  testthat::expect_equal(nc_ext_sf_1, proper_xmin)
  testthat::expect_equal(nc_ext_terra_1, proper_xmin)

})

```


```{r, send_to = "R/processing.R"}
#' Extent clipping
#' @description Clip input vector by the expected maximum extent of computation. 
#' @author Insang Song
#' @param pnts sf or SpatVector object
#' @param buffer_r numeric(1). buffer radius. this value will be automatically multiplied by 1.25
#' @param nqsegs integer(1). the number of points per a quarter circle; SOON TO BE DEPRECATED
#' @param target_input sf or SpatVector object to be clipped
#' @return A clipped sf or SpatVector object.
#' @export
clip_as_extent <- function(
  pnts,
  buffer_r,
  nqsegs = NULL,
  target_input) {
  if (any(sapply(list(pnts, buffer_r, target_input), is.null))) {
    stop("One or more required arguments are NULL. Please check.\n")
  }
  detected_pnts <- check_packbound(pnts)
  detected_target <- check_packbound(target_input)

  if (detected_pnts != detected_target) {
    warning("Inputs are not the same class.\n")
    target_input <- switch(detected_target,
      sf = terra::vect(target_input),
      terra = sf::st_as_sf(target_input))
  }

  ext_input <- set_clip_extent(pnts, buffer_r)
  cat("Clip target features with the input feature extent...\n")
  if (detected_pnts == "sf") {
    cae <- ext_input |>
      sf::st_intersection(x = target_input)
  }
  if (detected_pnts == "terra") {
    cae <- terra::intersect(target_input, ext_input)
  }

  return(cae)
}
```


```{r, send_to = "R/processing.R"}
#' @title clip_as_extent_ras: Clip input raster.
#' @description Clip input raster by the expected maximum extent of computation. 
#' @author Insang Song
#' @param pnts sf or SpatVector object
#' @param buffer_r numeric(1). buffer radius.
#' This value will be automatically multiplied by 1.25
#' @param ras SpatRaster object to be clipped
#' @param nqsegs integer(1). the number of points per a quarter circle
#' @export
clip_as_extent_ras <- function(
  pnts,
  buffer_r,
  ras,
  nqsegs = 180L
  ) {
  if (any(sapply(list(pnts, buffer_r, ras), is.null))) {
    stop("Any of required arguments are NULL. Please check.\n")
  }
  ext_input <- set_clip_extent(pnts, buffer_r) |>
    terra::vect()

  cae <- terra::crop(ras, ext_input, snap = "out")
  return(cae)
}
```


```{r test-clip-extent, eval=F}
testthat::test_that("Clip by extent works without errors", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  ncelev <- terra::unwrap(readRDS("../testdata/nc_srtm15_otm.rds"))
  terra::crs(ncelev) <- "EPSG:5070"
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  ncp <- readRDS("../testdata/nc_random_point.rds")
  ncp_terra <- terra::vect(ncp)

  testthat::expect_no_error(clip_as_extent_ras(ncp, 30000L, ncelev))
  testthat::expect_no_error(clip_as_extent_ras(ncp_terra, 30000L, ncelev))
})



```


```{r, send_to = "R/indexing.R"}
#' @title Create integer indices for grid
#' @description Returns a tibble object that includes
#'  x- and y- index by using two inputs ncutsx and ncutsy,
#'  which are x- and y-directional splits, respectively.
#' @author Insang Song
#' @param points_in sf object. 
#' @param ncutsx integer(1). The number of splits along x-axis.
#' @param ncutsy integer(1). The number of splits along y-axis.
#' @export
sp_indexing <- function(
  points_in,
  ncutsx,
  ncutsy) {
  # pts <- data.table(pnts)
  points_in <- points_in |>
    dplyr::mutate(or_id = seq(1, dim(points_in)[1]))

  range_x  <- range(points_in$x)
  # limits_x <- (range_x[1] + seq(0, ncutsx) * (range_x[2] - range_x[1]) / ncutsx)
  range_y  <- range(points_in$y)
  # limits_y <- (range_y[1] + seq(0, ncutsy) * (range_y[2] - range_y[1]) / ncutsy)

  points_in_cut <- points_in |>
    dplyr::mutate(xcut =  as.integer(cut(x, ncutsx, labels = seq(1, ncutsx))),
           ycut = as.integer(cut(y, ncutsy, labels = seq(1, ncutsy))))

  return(points_in_cut)
}
```

```{r, send_to = "R/preprocessing.R"}
#' Quick call for SpatRaster with a window
#' 
#' @param rasterpath character(1). Path to the raster file.
#' @param win Named integer vector (4) or terra::ext() results.
#' @return SpatRaster object.
#' @author Insang Song
#' @export 
rast_short <- function(rasterpath, win) {
  if (!(all(is.numeric(win), !is.null(attr(win, "names")), length(win) == 4) ||
        is(win, "SpatExtent"))) {
    stop("Argument win should be one of named numeric vector or SpatExtent object.\n")
  }
  if (is.numeric(win) && !all(grepl("(xmax|xmin|ymax|ymin)", names(win)))) {
    stop("Numeric win without names is detected. Set valid names for all win elements.\n")
  }
  invisible(terra::rast(rasterpath, win = win))
}

```


```{r test-rasterbound}
testthat::test_that("Raster is read properly with a window.", {
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")

  ext_numeric <- c(-84, -82, 34, 36) # unnamed
  testthat::expect_error(rast_short(bcsd_path, ext_numeric[1:3]))
  testthat::expect_error(rast_short(bcsd_path, ext_numeric))

  names(ext_numeric) <- c("xmin", "xmax", "ymin", "ymax")
  rastshort_num <- rast_short(bcsd_path, ext_numeric)
  testthat::expect_s4_class(rastshort_num, "SpatRaster")

  ext_terra <- terra::ext(ext_numeric)
  rastshort_terra <- rast_short(bcsd_path, ext_terra)
  testthat::expect_s4_class(rastshort_terra, "SpatRaster")

})


```


```{r}
#' Estimate computational demands from inputs (to be written)
#' 
#' @param inputs character vector of file paths
#' @param nx integer(1). 
#' @param ny integer(1). 
#' @param padding numeric(1). Extrusion factor 
#' @author Insang Song
#' @export 
estimate_demands <- function(
  inputs,
  nx, ny,
  padding
) {
  ## cpu 
  ## memory
  ## estimate maximum coverage
  ## clipped data size
  ## total distributed memory
  ## return a list of total demands 
  ## print summary of results
}

```


```{r, send_to = "R/interpret_computational_domain.R"}
#' Get a set of computational regions
#' 
#' @param input sf or Spat* object.
#' @param mode character(1). Mode of region construction. One of "grid" (simple grid regardless of the number of features in each grid), "density" (clustering-based varying grids), "grid_advanced" (merging adjacent grids with smaller number of features than grid_min_features). 
#' @param nx integer(1). The number of grids along x-axis.
#' @param ny integer(1). The number of grids along y-axis.
#' @param grid_min_features integer(1). A threshold to merging adjacent grids
#' @param padding numeric(1). A extrusion factor to make buffer to clip actual datasets. Depending on the length unit of the CRS of input.
#' @param unit character(1). The length unit for padding (optional). units::set_units is used for padding when sf object is used. See [units package vignette (web)](https://cran.r-project.org/web/packages/units/vignettes/measurement_units_in_R.html) for the list of acceptable unit forms.
#' @param ... arguments passed to the internal function
#' @return A set of polygons in the input class
#' @description TODO. Using input points, the bounding box is split to the predefined numbers of columns and rows. Each grid will be buffered by the radius.   
#' @author Insang Song 
#' @examples 
#' # data
#' library(sf)
#' ncpath <- system.file("shape/nc.shp", package = "sf")
#' nc <- read_sf(ncpath)
#' nc <- st_transform(nc, "EPSG:5070")
#' # run
#' # nc_comp_region <- get_computational_regions(nc, nx = 12, ny = 8)
#' 
#' @export
get_computational_regions <- function(
  input,
  mode = c("grid", "grid_advanced", "density"),
  nx = 10L,
  ny = 10L,
  grid_min_features = 30L,
  padding = NULL,
  unit = NULL,
  ...) {
  # stopifnot("Invalid input.\n" = !any(grepl("^(sf|Spat)", class(input))))
  
  stopifnot("Argument mode should be one of
    'grid', 'grid_advanced', or 'density'.\n" =
    mode %in% c("grid", "grid_advanced", "density"))
  stopifnot("Ensure that nx, ny, and grid_min_features are
    all integer.\n" = {
                       all(is.integer(nx),
                           is.integer(ny),
                           is.integer(grid_min_features))})
  stopifnot("padding should be numeric.
    We convert padding to numeric...\n" = {
                                           is.numeric(padding)})
  # valid unit compatible with units::set_units?
  switch(mode,
    grid = sp_index_grid(points_in = input, ncutsx = nx, ncutsy = ny),
    grid_advanced = grid_merge(
                               points_in = input,
                               sp_index_grid(input, nx, ny),
                               grid_min_features = grid_min_features),
    density = simpleError("density method is under development.\n")
  )

}

#' @title sp_index_grid: Generate grid polygons
#' @description Returns a sf object that includes x- and y- index
#'  by using two inputs ncutsx and ncutsy, which are x- and
#'  y-directional splits, respectively.
#' @author Insang Song
#' @param points_in sf or SpatVector object. Target points of computation.
#' @param ncutsx integer(1). The number of splits along x-axis.
#' @param ncutsy integer(1). The number of splits along y-axis.
#' @return A sf or SpatVector object of computation grids with
#'  unique grid id (CGRIDID).
#' @export
sp_index_grid <- function(
  points_in,
  ncutsx,
  ncutsy) {
  package_detected <- check_packbound(points_in)

  sp_index_grid_sf <- function(points_in, ncutsx, ncutsy) {
    grid1 <- sf::st_make_grid(points_in, n = c(ncutsx, ncutsy)) |>
      as.data.frame() |>
      sf::st_as_sf()
    grid1 <- grid1[points_in, ]
    return(grid1)
  }
  sp_index_grid_terra <- function(points_in, ncutsx, ncutsy) {
    grid1 <- terra::rast(points_in, nrows = ncutsy, ncols = ncutsx)
    grid1 <- terra::as.polygons(grid1)
    return(grid1)
  }
  grid_out <- switch(package_detected,
    sf = sp_index_grid_sf(points_in, ncutsx, ncutsy),
    terra = sp_index_grid_terra(points_in, ncutsx, ncutsy))

  grid_out$CGRIDID <- seq(1, nrow(x = grid_out))
  return(grid_out)

}


#' @title grid_merge: Merge grid polygons with given rules
#' @description Merge boundary-sharing (in "Rook" contiguity) grids with
#'  fewer target features than the threshold.
#'  This function strongly assumes that the input
#'  is returned from the sp_index_grid,
#'  which has 'CGRIDID' as the unique id field.
#' @author Insang Song
#' @param points_in sf or SpatVector object. Target points of computation.
#' @param grid_in sf or SpatVector object. The grid generated by sp_index_grid
#' @param grid_min_features integer(1). Threshold to merge adjacent grids.
#' @return A sf or SpatVector object of computation grids.
#' @examples
#' # library(sf)
#' # library(igraph)
#' # ligrary(dplyr)
#' # dg = sf::st_as_sfc(st_bbox(c(xmin = 0, ymin = 0, xmax = 8e5, ymax = 6e5)))
#' # sf::st_crs(dg) = 5070
#' # dgs = sf::st_as_sf(st_make_grid(dg, n = c(20, 15)))
#' # dgs$CGRIDID = seq(1, nrow(dgs))
#' #
#' # dg_sample = st_sample(dg, kappa = 5e-9, mu = 15, scale = 20000, type = "Thomas")
#' # sf::st_crs(dg_sample) = sf::st_crs(dg)
#' # dg_merged = grid_merge(sf::st_as_sf(sss), dgs, 100)
#' #### NOT RUN ####
#' @export
grid_merge <- function(points_in, grid_in, grid_min_features) {
  package_detected <- check_packbound(points_in)
  if (package_detected == "terra") {
    points_in <- sf::st_as_sf(points_in)
    grid_in <- sf::st_as_sf(grid_in)
  }

  n_points_in_grid <- lengths(sf::st_intersects(grid_in, points_in))
  grid_self <- sf::st_relate(grid_in, grid_in, pattern = "2********")
  grid_rook <- sf::st_relate(grid_in, grid_in, pattern = "F***1****")
  grid_rooks <- mapply(c, grid_self, grid_rook, SIMPLIFY = FALSE)
  grid_lt_threshold <- (n_points_in_grid < grid_min_features)
  stopifnot("Threshold is too low. Please try higher threshold.\n" = sum(grid_lt_threshold) != 0)
  grid_lt_threshold <- seq(1, nrow(grid_in))[grid_lt_threshold]

  # This part does not work as expected. Should investigate edge list and actual row index of the grid object; 
  identified <- lapply(grid_rooks, \(x) sort(x[which(x %in% grid_lt_threshold)]))
  identified <- identified[grid_lt_threshold]
  identified <- unique(identified)
  identified <- identified[sapply(identified, length) > 1]

  identified_graph <- lapply(identified, \(x) t(utils::combn(x, 2))) |>
    Reduce(f = rbind, x = _) |>
    unique() |>
    apply(X = _, 2, as.character) |>
    igraph::graph_from_edgelist(el = _, directed = 0) |>
    igraph::mst() |>
    igraph::components()
  # return(identified_graph)

  identified_graph_member <- identified_graph$membership

  merge_idx <- as.integer(names(identified_graph_member))
  merge_member <- split(merge_idx, identified_graph_member)
  merge_member_label <- unlist(lapply(merge_member, \(x) paste(x, collapse = "_")))
  merge_member_label <- merge_member_label[identified_graph_member]

  # sf object manipulation
  grid_out <- grid_in
  grid_out[["CGRIDID"]][merge_idx] <- merge_member_label
  # for (k in seq_along(merge_member_label)) {
  #   target_idx = merge_member_label[[k]]
  #   grid_out[["CGRIDID"]][target_idx] = paste("M_", paste(target_idx, collapse = "_"), sep = "")
  # }
  grid_out <- grid_out |>
    dplyr::group_by(!!rlang::sym("CGRIDID")) |>
    dplyr::summarize(n_merged = dplyr::n()) |>
    dplyr::ungroup() 

  ## polsby-popper test for shape compactness
  grid_merged <- grid_out[which(grid_out$n_merged > 1),]
  grid_merged_area <- as.numeric(sf::st_area(grid_merged))
  grid_merged_perimeter <- as.numeric(sf::st_length(sf::st_cast(grid_merged, "LINESTRING")))
  grid_merged_pptest <- (4 * pi * grid_merged_area) / (grid_merged_perimeter ^ 2)

  # pptest value is bounded [0,1]; 0.3 threshold is groundless at this moment, possibly will make it defined by users.
  if (max(unique(identified_graph_member)) > floor(0.1 * nrow(grid_in)) || any(grid_merged_pptest < 0.3)) {
    warning("The reduced computational regions have too complex shapes. Consider increasing thresholds or using the original grids.\n")
  }

  return(grid_out)

  # union unique sets into one
  # identified_relation = matrix(NA, length(identified), length(identified))
  # diag(identified_relation) = lengths(identified)

  # for (i in seq_len(length(identified))) {
  #   for (j in seq(i, length(identified))) {
  #     identified_relation[i, j] = length(intersect(identified[[i]], identified[[j]]))
  #     identified_relation[j, i] = identified_relation[i, j]
  #   }
  # }
  # # identified_relation = max(identified_relation) - identified_relation
  # return(as.dist(identified_relation))
}



```


```{r test-compregion}
testthat::test_that("Grid split is well done.", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")

  testthat::expect_no_error(get_computational_regions(nc, mode = "grid", padding = 3e4L))
  ncgrid <- get_computational_regions(nc, mode = "grid", padding = 3e4L)
  testthat::expect_s3_class(ncgrid, "sf")

  nctr <- terra::vect(nc)
  testthat::expect_no_error(get_computational_regions(nctr, mode = "grid", padding = 3e4L))
  ncgridtr <- get_computational_regions(nctr, mode = "grid", padding = 3e4L)
  testthat::expect_s4_class(ncgridtr, "SpatVector")

})

```



```{r, send_to = "R/check.R"}
#' Generate a rectangular polygon from extent
#' 
#' @param extent input extent. A numeric vector with xmin/xmax/ymin/ymax, sf::st_bbox() or terra::ext() outputs.
#' @param output_class character(1). Class of the output polygon. One of "sf" or "terra"
#' @param crs character(1). Coordinate reference system definition.
#' @author Insang Song
#' @export
extent_to_polygon <- function(
  extent,
  output_class = "terra",
  crs = "EPSG:4326") {
  if (!output_class %in% c("sf", "terra")) {
    stop("output_class should be one of 'sf' or 'terra'.\n")
  }
  if (methods::is(extent, "numeric")) {
    if (is.null(attr(extent, "names"))) {
      stop("Your extent is an unnamed numeric vector. Please define names xmin/xmax/ymin/ymax explicitly.\n")
    }
    extent <- switch(
      output_class,
      sf = sf::st_bbox(extent),
      terra = terra::ext(extent)
    )
  }

  extent_polygon <- switch(
    output_class,
    sf = sf::st_as_sf(sf::st_as_sfc(extent)),
    terra = terra::vect(extent)
  )

  extent_polygon <- switch(
    output_class,
    sf = sf::st_set_crs(extent_polygon, sf::st_crs(crs)),
    terra = terra::set.crs(extent_polygon, terra::crs(crs))
  )

  return(extent_polygon)

}

```

```{r test-extentpoly}
testthat::test_that("input extent is converted to a polygon", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  mainland_vec <- c(xmin = -128, xmax = -62, ymin = 25, ymax = 52)
  mainland_box <- extent_to_polygon(mainland_vec, output_class = "sf")
  mainland_box_t <- extent_to_polygon(mainland_vec, output_class = "terra")
  mainland_vec_un <- unname(mainland_vec)
  
  testthat::expect_s3_class(mainland_box, "sf")
  # terra Spat* objects are s4 class...
  testthat::expect_s4_class(mainland_box_t, "SpatVector")
  testthat::expect_error(
    extent_to_polygon(mainland_vec_un, output_class = "sf")
  )
})

```



```{r, send_to = "R/check.R"}
#' Check if the data extent is inside the reference bounding box
#'
#' @description One of the most common errors in
#'  spatial computation is rooted in
#'  the entirely or partly incomparable spatial extents of input datasets.
#'  This function returns whether your data is inside
#'  the target computational extent.
#'  It is assumed that you know and have the exact computational region.
#'  This function will return TRUE if the reference region
#'  completely contains your data's extent and FALSE otherwise.
#' @param data_query sf*/stars/SpatVector/SpatRaster object.
#' @param reference sf*/stars/SpatVector/SpatRaster object or
#'  a named numeric vector with four names (xmin, ymin, xmax, and ymax).
#' @param reference_crs Well-known-text-formatted or
#'  EPSG code of the reference's coordinate system.
#'  Only required when a named numeric vector is passed to reference.
#' @return TRUE (the queried data extent is completely within
#'  the reference bounding box) or FALSE 
#' @author Insang Song \email{geoissong@@gmail.com}
#'
#' @export
check_bbox <- function(
  data_query,
  reference,
  reference_crs = NULL
) {
  if (is.numeric(reference) && is.null(reference_crs)) {
    stop("CRS should be entered when the reference extent is a vector.\n")
  }
  if (is.numeric(reference) && !is.null(reference_crs)) {
    reference <- sf::st_as_sfc(sf::st_bbox(reference), crs = reference_crs)
  }
  query_crs <- check_crs(data_query)

  ref_crs <- check_crs(reference)
  if (is.null(reference_crs)) {
    reference <-
      sf::st_as_sfc(
        sf::st_bbox(reference),
        crs = ref_crs
      )
  }
  if (is.na(query_crs) || is.null(query_crs)) {
    stop("The dataset you queried has no CRS.
     Please make sure your dataset has the correct CRS.\n")
  }
  data_query_bb <-
    sf::st_as_sfc(sf::st_bbox(data_query),
                  crs = sf::st_crs(data_query))

  query_matched <- sf::st_transform(data_query_bb, sf::st_crs(ref_crs))
  check_result <- as.logical(unlist(sf::st_within(query_matched, reference)))
  return(check_result)
}


```

```{r test-bbox, eval=FALSE}
testthat::test_that("Check bbox abides.", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  ncp <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")

  testthat::expect_no_error(check_bbox(ncp, nc))
  res <- check_bbox(ncp, nc)
  testthat::expect_equal(res, TRUE)
})

```

```{r, include=FALSE}
#
#
#' Check if the data extent is inside the reference bounding box
#' 
#' @description One of the most common errors in spatial computation is rooted in the entirely or partly incomparable spatial extents of input datasets. This function returns whether your data is inside the target computational extent. It is assumed that you know and have the exact computational region. This function will return TRUE if the reference region completely contains your data's extent and FALSE otherwise.
#' @param data_query sf*/stars/SpatVector/SpatRaster object.
#' @param reference sf*/stars/SpatVector/SpatRaster object or a named numeric vector with four names (xmin, ymin, xmax, and ymax).
#' @param reference_crs Well-known-text-formatted or EPSG code of the reference's coordinate system. Only required when a named numeric vector is passed to reference. 
#' @return TRUE (the queried data extent is completely within the reference bounding box) or FALSE 
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export


```

```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with generic polygons
#' 
#' @description For simplicity, it is assumed that the coordinate systems of the points and the raster are the same. Kernel function is not yet implemented. 
#' @param polys sf/SpatVector object. Polygons.
#' @param surf stars/SpatRaster object. A raster of whatnot a summary will be calculated
#' @param id character(1). Unique identifier of each point.
#' @param func a function taking one argument. For example, function(x) mean(x, na.rm = TRUE) or \(x) mode(x, na.rm = TRUE)
#' @param na.rm logical(1). NA values are omitted when summary is calculated.
#' @return a data.frame object with function value
#' @author Insang Song \email{geoissong@@gmail.com}
#' @importFrom rlang sym
#' @importFrom dplyr across
#' @export
extract_with_polygons <- function(
    polys,
    surf,
    id,
    func = mean,
    na.rm = TRUE
    ) {
  # type check
  stopifnot("Check class of the input points.\n" = any(methods::is(polys, "sf"), methods::is(polys, "SpatVector")))
  stopifnot("Check class of the input raster.\n" = any(methods::is(surf, "stars"), methods::is(surf, "SpatRaster")))
  stopifnot(is.character(id))

  cls_polys <- check_packbound(polys)
  cls_surf <- check_packbound(surf)

  if (cls_polys != cls_surf) {
    polys <- switch_packbound(polys)
  }

  extract_with_polygons_sf <- function(polys, surf, id, func) {
    extracted <- stars::st_extract(x = surf, at = polys, FUN = func)
    # extracted = extracted |>
    #   group_by(!!sym(id)) |>
    #   summarize(across(-!!sym(id), ~func)) |>
    #   ungroup()
    return(extracted)
  }

  extract_with_polygons_terra <- function(polys, surf, id, func) {
    extracted <- terra::extract(surf, polys)
    extracted <- extracted |>
      dplyr::group_by(!!rlang::sym(id)) |>
      dplyr::summarize(dplyr::across(-!!rlang::sym(id), ~func)) |>
      dplyr::ungroup()
    return(extracted)
  }

  extracted_poly <- switch(
    cls_surf,
    sf = extract_with_polygons_sf(
      polys = polys,
      surf = surf,
      id = id,
      func = func),
    terra = extract_with_polygons_terra(
      polys = polys,
      surf = surf,
      id = id,
      func = func)
  )
  return(extracted_poly)
}

```

```{r, send_to = "R/processing.R"}
#' Extract raster values with point buffers or polygons
#' 
#' @param raster SpatRaster object. 
#' @param vector SpatVector object.
#' @param id character(1). Unique identifier of each point.
#' @param func function taking one numeric vector argument.
#' @param mode one of "polygon" (generic polygons to extract raster values with) or "buffer" (point with buffer radius)
#' @param ... various. Passed to extract_with_buffer. See \code{?extract_with_buffer} for details.
#' @return A data.frame object with summarized raster values with respect to the mode (polygon or buffer) and the function.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @export
extract_with <- function(
  raster, 
  vector, 
  id, 
  func = mean, 
  mode = c("polygon", "buffer"),
  ...) {

  match.arg(mode)
  # if (!mode %in% c("polygon", "buffer")) {
  #   stop("Argument 'mode' should be one of 'polygon' or 'buffer'.\n")
  # }
  stopifnot(is.character(id))
  stopifnot(id %in% names(vector))

  extracted <- 
    switch(mode,
      polygon = extract_with_polygons(vector, raster, id, func, ...),
      buffer = extract_with_buffer(vector, raster, id = id, func = func, ...))
  return(extracted)
}

```

```{r, send_to = "R/check.R"}
#' Check Coordinate Reference System
#' @param x sf/stars/SpatVector/SpatRaster object.
#' @return A st_crs or crs object.
#' @description It returns st_crs object from sf/Spat* objects.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' # data
#' library(sf)
#' ncpath = system.file("shape/nc.shp", package = "sf")
#' nc = read_sf(ncpath)
#' check_crs(nc)
#' 
#' @export 
check_crs <- function(x) {
    stopifnot("Input is invalid.\n" = (methods::is(x, "sf") || methods::is(x, "stars") || methods::is(x, "SpatVector") || methods::is(x, "SpatRaster")))
    stopifnot(
      "No CRS is defined in the input. Please consult the metadata or the data source.\n" =
      !is.na(sf::st_crs(x)) || !is.na(terra::crs(x)))

  if (methods::is(x, "sf") || methods::is(x, "stars")) {
    crs_wkt <- sf::st_crs(x)
  } else {
    crs_wkt <- terra::crs(x)
  }

  return(crs_wkt)
}
```


```{r test-check_crs}
testthat::test_that("check_crs is working as expected", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  ncpath <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(ncpath)
  nct <- terra::vect(nc)
  crs_checked1 <- check_crs(nc)
  dummy <- character(0)
  crs_checked2 <- check_crs(nct)

  testthat::expect_equal(crs_checked1, sf::st_crs(nc))
  testthat::expect_equal(crs_checked2, terra::crs(nct))
  testthat::expect_error(check_crs(dummy))

})

```

```{r, send_to = "R/check.R"}
#' Check if the boundary of the vector/raster object is inside the reference
#' @param input_object sf/stars/SpatVector/SpatRaster object.
#' @param reference sf/stars/SpatVector/SpatRaster object.
#' @return logical
#' @author Insang Song \email{geoissong@@gmail.com}
#' @importFrom methods is
#' @export 
check_within_reference <- function(input_object, reference) {
  stopifnot("Input is invalid.\n" = (methods::is(input_object, "sf") || methods::is(input_object, "stars") || methods::is(input_object, "SpatVector") || methods::is(input_object, "SpatRaster")))
  stopifnot("Reference is invalid.\n" = (methods::is(input_object, "sf") || methods::is(input_object, "stars") || methods::is(input_object, "SpatVector") || methods::is(input_object, "SpatRaster")))

  bbox_input <- input_object |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  bbox_reference <- reference |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  iswithin <- sf::st_covered_by(bbox_input, bbox_reference)
  iswithin <- length(iswithin[[1]])
  iswithin <- (iswithin == 1)
  invisible(iswithin)
}


```

```{r}
testthat::test_that("nc data is within the mainland US", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  ncpath <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(ncpath)
  nc <- sf::st_transform(nc, "EPSG:4326")
  mainland_vec <- c(xmin = -128, xmax = -62, ymin = 25, ymax = 52)
  mainland_box <- extent_to_polygon(mainland_vec, output_class = "sf")
  within_res <- check_within_reference(nc, mainland_box)
  testthat::expect_equal(within_res, TRUE)
})

```

```{r, send_to = "R/processing.R"}
#' Calculate SEDC covariates
#' @param point_from SpatVector object. Locations where the sum of SEDCs are calculated.
#' @param point_to SpatVector object. Locations where each SEDC is calculated.
#' @param id character(1). Name of the unique id field in point_to.
#' @param sedc_bandwidth numeric(1).
#' Distance at which the source concentration is reduced to
#'  exp(-3) (approximately -95 %)
#' @param threshold numeric(1). For computational efficiency,
#'  the nearest points in threshold will be selected.
#'  Default is \code{2 * sedc_bandwidth}.
#' @param target_fields character(varying). Field names in characters.
#' @note sf implementation is pending. Only available for terra.
#' Currently the function internally convert sf objects to terra.
#' @author Insang Song
#' @export
calculate_sedc <-
  function(
    point_from,
    point_to,
    id,
    sedc_bandwidth,
    threshold,
    target_fields) {
  # define sources, set SEDC exponential decay range
  len_point_from <- seq_len(nrow(point_from))
  len_point_to <- seq_len(nrow(point_to))

    pkginfo_from <- check_packbound(point_from)
    pkginfo_to <- check_packbound(point_to)

    if (any(pkginfo_from == "sf", pkginfo_to == "sf")) {
      point_from <- switch_packbound(point_from)
      point_to <- switch_packbound(point_to)
    }
    point_from$from_id <- len_point_from
    # select egrid_v only if closer than 3e5 meters from each aqs
    point_from_buf <-
      terra::buffer(
                    point_from_buf,
                    threshold = threshold,
                    quadsegs = 90)
    point_to <- point_to[point_from_buf, ]
    point_to$to_id <- len_point_to

    # near features with distance argument: only returns integer indices
    near_from_to <- terra::nearby(point_from, point_to, distance = threshold)
    # attaching actual distance
    dist_near_to <- terra::distance(point_from, point_to)
    dist_near_to_df <- as.vector(dist_near_to)
    # adding integer indices
    dist_near_to_tdf <-
      expand.grid(
                  from_id = len_point_from,
                  to_id = len_point_to)
    dist_near_to_df <- cbind(dist_near_to_tdf, dist = dist_near_to_df)

    # summary
    near_from_to <- near_from_to |>
      dplyr::as_tibble() |>
      dplyr::left_join(data.frame(point_from)) |>
      dplyr::left_join(data.frame(point_to)) |>
      dplyr::left_join(dist_near_to_df) |>
      # per the definition in
      # https://mserre.sph.unc.edu/BMElab_web/SEDCtutorial/index.html
      # exp(-3) is about 0.05
      dplyr::mutate(w_sedc = exp((-3 * dist) / sedc_bandwidth)) |>
      dplyr::group_by(!!rlang::sym(id)) |>
      dplyr::summarize(
        dplyr::across(
                      dplyr::all_of(target_fields),
                      list(sedc = ~sum(w_sedc * ., na.rm = TRUE)))
      ) |>
      dplyr::ungroup()

    invisible(near_from_to)
}

```

```{r, send_to = "R/processing.R"}
#' Computing area weighted covariates using two polygon sf or SpatVector objects
#' @param poly_in A sf/SpatVector object at weighted means will be calculated.
#' @param poly_weight A sf/SpatVector object from
#'  which weighted means will be calculated.
#' @param id_poly_in character(1).
#'  The unique identifier of each polygon in poly_in
#' @return A data.frame with all numeric fields of area-weighted means.
#' @description When poly_in and poly_weight are different classes,
#'  poly_weight will be converted to the class of poly_in.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples 
#' # package
#' library(sf)
#'
#' # run
#' nc <- sf::st_read(system.file("shape/nc.shp", package="sf"))
#' nc <- sf::st_transform(nc, 5070)
#' pp <- sf::st_sample(nc, size = 300)
#' pp <- sf::st_as_sf(pp)
#' pp[["id"]] <- seq(1, nrow(pp))
#' sf::st_crs(pp) <- "EPSG:5070"
#' ppb <- sf::st_buffer(pp, nQuadSegs=180, dist = units::set_units(20, 'km'))
#'
#' system.time({ppb_nc_aw <- aw_covariates(ppb, nc, 'id')})
#' summary(ppb_nc_aw)
#' #### Example of aw_covariates ends ####
#' @export
aw_covariates <- function(
  poly_in, 
  poly_weight, 
  id_poly_in = "ID") {
  stopifnot("Inputs have invalid classes.\n" = 
    methods::is(poly_in, "sf") || methods::is(poly_weight, "sf") || methods::is(poly_in, "SpatVector") || methods::is(poly_weight, "SpatVector"))
  #check_crs()
  ## distinguish numeric and nonnumeric columns
  index_numeric <- grep("(integer|numeric)", unlist(sapply(poly_weight, class)))

  aw_covariates_terra <- function(
    poly_in, 
    poly_weight, 
    id_poly_in = id_poly_in) {
      poly_intersected <- terra::intersect(poly_in, poly_weight)
      poly_intersected[["area_segment_"]] <- terra::expanse(poly_intersected)
      poly_intersected <- data.frame(poly_intersected) |>
        dplyr::group_by(!!rlang::sym(id_poly_in)) |>
        dplyr::summarize(dplyr::across(dplyr::where(is.numeric),
          ~stats::weighted.mean(., w = area_segment_))) |>
        dplyr::ungroup()
      return(poly_intersected)
  }

  class_poly_in <- check_packbound(poly_in)
  class_poly_weight <- check_packbound(poly_weight)

  if (class_poly_in != class_poly_weight) {
    poly_weight <- switch_packbound(poly_weight)
  }

  switch(class_poly_in,
    sf = suppressWarnings(sf::st_interpolate_aw(poly_weight[, index_numeric],
      poly_in, extensive = FALSE)),
    terra = aw_covariates_terra(poly_in, poly_weight[, index_numeric],
      id_poly_in = id_poly_in))
    
}

# ncbuf = terra::intersect(vect(ppb), vect(nc))
# ncbuf_a = ncbuf
# ncbuf_a$segarea = expanse(ncbuf_a)
# ncbuf_k = data.frame(ncbuf_a) |>
#   dplyr::group_by(id) |>
#   dplyr::summarize(across(is.numeric,
#                ~weighted.mean(., w = segarea))) |>
#   dplyr::ungroup()

#ncbufagg = terra::aggregate(ncbuf, by = 'id', fun = weighted.mean, w = ncbuf_a$segarea)

```


```{r aw-test}

testthat::test_that("aw_covariates works as expected.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("units")
  withr::local_package("dplyr")
  withr::local_package("testthat")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- sf::st_read(system.file("shape/nc.shp", package="sf"))
  nc <- sf::st_transform(nc, 5070)
  pp <- sf::st_sample(nc, size = 300)
  pp <- sf::st_as_sf(pp)
  pp[["id"]] <- seq(1, nrow(pp))
  sf::st_crs(pp) <- "EPSG:5070"
  ppb <- sf::st_buffer(pp, nQuadSegs=180, dist = units::set_units(20, 'km'))

  system.time({ppb_nc_aw <- aw_covariates(ppb, nc, 'id')})
  expect_s3_class(ppb_nc_aw, "sf")

  # terra
  ppb_t <- terra::vect(ppb)
  nc_t <- terra::vect(nc)
  system.time({ppb_nc_aw <- aw_covariates(ppb_t, nc_t, 'id')})
  expect_s3_class(ppb_nc_aw, "data.frame")

  # auto convert formats
  system.time({ppb_nc_aw <- aw_covariates(ppb_t, nc, 'id')})
  expect_s3_class(ppb_nc_aw, "data.frame")

})



```

```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with points and a buffer radius (to be written)
#' 
#' @description For simplicity, it is assumed that the coordinate systems of the points and the raster are the same. Kernel function is not yet implemented. 
#' @param points SpatVector object. Coordinates where buffers will be generated
#' @param surf SpatRaster object. A raster of whatnot a summary will be calculated
#' @param radius numeric(1). Buffer radius. here we assume circular buffers only
#' @param id character(1). Unique identifier of each point.
#' @param qsegs integer(1). Number of vertices at a quarter of a circle. Default is 90.
#' @param func a function taking a numeric vector argument.
#' @param kernel character(1). Name of a kernel function (yet to be implemented)
#' @param bandwidth numeric(1). Kernel bandwidth.
#' @param grid_ref SpatVector object. A unit grid polygon that is used to get a subset inside the polygon
#' @return a data.frame object with mean value
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export
extract_with_buffer <- function(
    points,
    surf,
    radius,
    id,
    qsegs = 90L,
    func = mean,
    kernel = NULL,
    bandwidth = NULL,
    grid_ref = NULL
    ) {
  # type check
  stopifnot("Check class of the input points.\n" = methods::is(points, "SpatVector"))
  stopifnot("Check class of the input radius.\n" = is.numeric(radius))
  stopifnot(is.character(id))
  stopifnot(is.numeric(qsegs))

  if (!is.null(grid_ref)) {
    points <- points[grid_ref, ]
  }

  if (!is.null(kernel)) {
    extracted <- extract_with_buffer_kernel(points = points,
                                    surf = surf,
                                    radius = radius,
                                    id = id,
                                    func = func,
                                    qsegs = qsegs,
                                    kernel = kernel,
                                    bandwidth = bandwidth)
    return(extracted)
  }

  extracted <- extract_with_buffer_flat(points = points,
                                surf = surf,
                                radius = radius,
                                id = id,
                                func = func,
                                qsegs = qsegs)
  return(extracted)

}

# Subfunction: extract with buffers (flat weight; simple mean)
extract_with_buffer_flat <- function(
  points,
  surf,
  radius,
  id,
  qsegs,
  func = mean,
  kernel = NULL,
  bandwidth = NULL
  ) {
  # generate buffers
  bufs <- terra::buffer(points, width = radius, quadsegs = qsegs)
  # crop raster
  bufs_extent <- terra::ext(bufs)
  surf_cropped <- terra::crop(surf, bufs_extent)
  name_surf_val <- names(surf)
  # extract raster values
  surf_at_bufs <- terra::extract(surf_cropped, bufs)
  surf_at_bufs_summary <-
    surf_at_bufs |>
      dplyr::group_by(ID) |>
      dplyr::summarize(dplyr::across(dplyr::all_of(name_surf_val), ~mean(., na.rm = TRUE))) |> 
      dplyr::ungroup()
  return(surf_at_bufs_summary)
}


# Subfunction: extract with buffers (kernel weight; weighted mean)
extract_with_buffer_kernel <- function(
  points,
  surf,
  radius,
  id,
  qsegs,
  func = mean,
  kernel,
  bandwidth
) {
  # generate buffers
  bufs <- terra::buffer(points, width = radius, quadsegs = qsegs)
  # crop raster
  bufs_extent <- terra::ext(bufs)
  surf_cropped <- terra::crop(surf, bufs_extent)
  name_surf_val <- names(surf)

  # TODO: kernel implementation


  # extract raster values
  surf_at_bufs <- terra::extract(surf_cropped, bufs)
  surf_at_bufs_summary <-
    surf_at_bufs |>
      dplyr::group_by(ID) |>
      dplyr::summarize(
        dplyr::across(dplyr::all_of(name_surf_val), ~mean, na.rm=T)
      ) |> 
      dplyr::ungroup()
  return(surf_at_bufs_summary)
}

```


```{r, send_to = "R/scale_process.R"}
#' @title Process a given function in the entire or partial computational grids
#' 
#' @description Currently only accepting \link[future]{multicore} setting (single node, single process, and multiple threads). For details of the terminology in \code{future} package, refer to \link[future]{plan}. This function assumes that users have one raster file and a sizable and spatially distributed target locations. Each thread will process ceiling(|Ng|/|Nt|) grids where |Ng| denotes the number of grids and |Nt| denotes the number of threads.
#' @param grids sf/SpatVector object. Computational grids. It takes a strict assumption that the grid input is an output of \code{get_computational_regions}
#' @param grid_target_id character(1) or numeric(2). Default is NULL. If NULL, all grid_ids are used. \code{"id_from:id_to"} format or \code{c(unique(grid_id)[id_from], unique(grid_id)[id_to])}
#' @param fun function supported in scomps.
#' @param ... Arguments passed to the argument \code{fun}.
#' @return a data.frame object with computation results. For entries of the results, consult the function used in \code{fun} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @examples 
#' library(future)
#' plan(multicore, workers = 4)
#' # Does not run ...
#' # distribute_process_grid()
#' @import future
#' @export
distribute_process_grid <-
  function(
      grids,
      grid_target_id = NULL,
      fun,
      ...) {
    if (is.character(grid_target_id) && !grepl(":", grid_target_id)) {
      stop("Character grid_target_id should be in a form of 'startid:endid'.\n")
    }
    if (is.numeric(grid_target_id) && length(grid_target_id) != 2) {
      stop("Numeric grid_target_id should be in a form of c(startid, endid).\n")
    }
    # subset using grids and grid_id
    if (is.null(grid_target_id)) {
      grid_target_ids <- unlist(grids[["CGRIDID"]])
    }
    if (is.character(grid_target_id)) {
      grid_id_parsed <- strsplit(grid_target_id, ":", fixed = TRUE)[[1]]
      grid_target_ids <- c(which(unique(grids[["CGRIDID"]]) == grid_id_parsed[1]),
                      which(unique(grids[["CGRIDID"]]) == grid_id_parsed[2]))
    }
    if (is.numeric(grid_target_id)) {
      grid_target_ids <- unique(grids[["CGRIDID"]])[grid_target_id]
    }
    par_fun <- list(...)
    
    grids_target <- grids[grid_target_ids %in% unlist(grids[["CGRIDID"]]),]
    grids_target_list <- split(grids_target, unlist(grids_target[["CGRIDID"]]))

    results_distributed <- future.apply::future_lapply(
      grids_target_list,
      \(x) {
        sf::sf_use_s2(FALSE)
        
        run_result <- tryCatch({
          res <- fun(..., grid_ref = x)
          cat(sprintf("Your input function %s was 
          successfully run at CGRIDID: %s\n",
            paste0(quote(fun)), as.character(unlist(x[["CGRIDID"]]))))
          
          return(res)
        },
        error = function(e) return(data.frame(ID = NA)))
        
        return(run_result)
      },
      future.seed = TRUE,
      future.packages = c("terra", "sf", "dplyr", "scomps", "future"))
    results_distributed <- do.call(dplyr::bind_rows, results_distributed)
    results_distributed <- results_distributed[!is.na(results_distributed[["ID"]]),]

    # post-processing
    detected_id <- grep("^id", names(par_fun), value = TRUE)
    detected_point <- grep("^(points|poly)", names(par_fun), value = TRUE)
    names(results_distributed)[1] <- par_fun[[detected_id]]
    results_distributed[[par_fun[[detected_id]]]] <-
      unlist(par_fun[[detected_point]][[par_fun[[detected_id]]]])
    
    return(results_distributed)
}


#' @title Process a given function using a hierarchy in input data
#' 
#' @description "Hierarchy" refers to a system,
#'  which divides the entire study region into multiple subregions.
#'  It is oftentimes reflected in an area code system
#'  (e.g., FIPS for US Census geographies, HUC-4, -6, -8, etc.).
#'  Currently only accepting \link[future]{multicore} setting
#'  (single node, single process, and multiple threads).
#'  For details of the terminology in \code{future} package,
#'  refer to \link[future]{plan}.
#'  This function assumes that users have one raster file and
#'  a sizable and spatially distributed target locations.
#'  Each thread will process ceiling(|Ng|/|Nt|) grids where
#'  |Ng| denotes the number of grids and |Nt| denotes
#'  the number of threads. Please be advised that
#'  accessing the same file simultaneously with
#'  multiple processes may result in errors.
#' @param regions sf/SpatVector object.
#'  Computational regions. Only polygons are accepted.
#' @param split_level character(nrow(regions)) or character(1).
#'  The regions will be split by the common level value.
#'  The level should be higher than the original data level.
#'  A field name with the higher level information is also accepted.
#' @param fun function supported in scomps.
#' @param ... Arguments passed to the argument \code{fun}.
#' @return a data.frame object with computation results.
#'  For entries of the results, consult the function used in
#'  \code{fun} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#'
#' @examples
#' library(future)
#' plan(multicore, workers = 4)
#' # Does not run ...
#' # distribute_process_hierarchy()
#' @import future
#' @import future.apply
#' @import progressr
#' @export
distribute_process_hierarchy <- function(
  regions,
  split_level = NULL,
  fun,
  ...) {
  par_fun <- list(...)

  if (!any(length(split_level) == 1, length(split_level) == nrow(regions))) {
    stop("The length of split_level is not valid.")
  }
  split_level <- ifelse(length(split_level) == nrow(regions),
    split_level,
    unlist(regions[[split_level]]))

  # pgrs <- progressr::progressor(along = seq_len(split_level))
  regions_list <- split(regions, split_level)

  results_distributed <-
    future_lapply(
                  regions_list,
                  \(x) {
                    sf::sf_use_s2(FALSE)
                    run_result <-
                      tryCatch(
                               {
                                 res <- fun(..., grid_ref = x)
                                 return(res)
                               },
                               error =
                               function(e) {
                                 return(data.frame(ID = NA))
                               })
                    return(run_result)
                  },
                  future.seed = TRUE,
                  future.packages = c("terra", "sf", "dplyr",
                                      "scomps", "future"))
  results_distributed <- do.call(dplyr::bind_rows, results_distributed)
  results_distributed <-
    results_distributed[!is.na(results_distributed[["ID"]]), ]

  # post-processing
  detected_id <- grep("^id", names(par_fun), value = TRUE)
  detected_point <- grep("^(points|poly)", names(par_fun), value = TRUE)
  names(results_distributed)[1] <- par_fun[[detected_id]]
  results_distributed[[par_fun[[detected_id]]]] <-
    unlist(par_fun[[detected_point]][[par_fun[[detected_id]]]])

  return(results_distributed)
}




#' @title Process a given function over multiple large rasters
#' 
#' @description Large raster files usually exceed the memory capacity in size.
#'  Cropping a large raster into a small subset even consumes
#'  a lot of memory and adds processing time.
#'  This function leverages terra SpatRaster proxy
#'  to distribute computation jobs over multiple cores.
#'  It is assumed that users have multiple large raster files
#'  in their disk, then each file path is assigned to a thread.
#'  Each thread will directly read raster values from
#'  the disk using C++ pointers that operate in terra functions.
#'  For use, it is strongly recommended to use vector data with
#'  small and confined spatial extent for computation to avoid
#'  out-of-memory error. For this, users may need
#'  to make subsets of input vector objects in advance.
#' @param filenames character(n). A vector or list of
#'  full file paths of raster files. n is the total number of raster files.
#' @param fun function supported in scomps.
#' @param ... Arguments passed to the argument \code{fun}.
#' @return a data.frame object with computation results.
#'  For entries of the results, consult the function used in \code{fun} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @examples 
#' library(future)
#' plan(multicore, workers = 4)
#' # Does not run ...
#' # distribute_process_multirasters()
#' @import future
#' @import future.apply
#' @import progressr
#' @export
distribute_process_multirasters <- function(
  filenames,
  fun,
  ...) {
  par_fun <- list(...)

  if (any(sapply(filenames, \(x) !file.exists(x)))) {
    stop("One or many of files do not exist in provided file paths. Check the paths again.\n")
  }

  file_list <- split(filenames, filenames)
  results_distributed <-
    future_lapply(
                  file_list,
                  \(x) {
                    sf::sf_use_s2(FALSE)

                    run_result <-
                      tryCatch({
                        res <- fun(...)
                        return(res)
                      },
                      error = function(e) return(data.frame(ID = NA)))
                    return(run_result)
                  },
                  future.seed = TRUE,
                  future.packages =
                  c("terra", "sf", "dplyr", "scomps", "future"))
  results_distributed <- do.call(dplyr::bind_rows, results_distributed)
  results_distributed <-
    results_distributed[!is.na(results_distributed[["ID"]]), ]

  # post-processing
  detected_id <- grep("^id", names(par_fun), value = TRUE)
  detected_point <- grep("^(points|poly)", names(par_fun), value = TRUE)
  names(results_distributed)[1] <- par_fun[[detected_id]]
  results_distributed[[par_fun[[detected_id]]]] <-
    unlist(par_fun[[detected_point]][[par_fun[[detected_id]]]])

  return(results_distributed)
}


```



```{r test-distribute, eval=FALSE}
testthat::test_that("Processes are properly spawned and compute", {
  withr::local_package("terra")
  withr::local_package("sf")
  withr::local_package("future")
  withr::local_package("dplyr")
  withr::local_package("progressr")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <- readRDS("../testdata/nc_random_point.rds")
  ncpnts <- terra::vect(ncpnts)
  ncelev <- terra::unwrap(readRDS("../testdata/nc_srtm15_otm.rds"))
  terra::crs(ncelev) <- "EPSG:5070"

  nccompreg <-
    get_computational_regions(
      input = ncpoly,
      mode = 'grid',
      nx = 6L,
      ny = 4L,
      padding = 3e4L)
  res <-
    suppressWarnings(
      distribute_process_grid(
                              grids = nccompreg,
                              grid_target_id = NULL,
                              fun = extract_with_buffer,
                              points = ncpnts,
                              qsegs = 90L,
                              surf = ncelev,
                              radius = 5e3L,
                              id = "pid")
    )
  testthat::expect_s4_class(nccompreg, "SpatVector")
  testthat::expect_s3_class(res, "data.frame")
  testthat::expect_equal(!any(is.na(unlist(res))), TRUE)
})


```

```{r, eval = FALSE, include = FALSE}
  # future.apply::future_lapply(
  #   nccompreg %>% split(., .$CGRIDID),
  #   \(x) {
  #     sf::sf_use_s2(FALSE)
      
  #     run_result <- tryCatch({
  #       kk <- scomps::extract_with_buffer(ncpnts, ncelev, 30000L, "pid", grid_ref = x)
  #       #fun(...)
  #       #print(xx)
  #       cat(sprintf("Your input function %s was successfully run at CGRIDID: %s\n",
  #         paste0(quote(fun)), as.character(unlist(x[["CGRIDID"]]))))
  #       return(kk)
  #     },
  #     error = function(e) return(data.frame(ID = NA)))
  #     return(run_result)
  #   },
  #   future.seed = TRUE,
  #   future.packages = c("terra", "sf", "dplyr", "scomps", "future"))

  # scomps::extract_with_buffer(ncpnts, ncelev, 30000L, "pid", grid_ref = nccompreg %>% split(., .$CGRIDID) %>% .[[5]])
```

## Documenting the package and building

We finish by running commands that will document, build, and install the package.  It may also be a good idea to check the package from within this file.

```{r run-devtools}
litr::document()
# devtools::document(".")
devtools::test()
# devtools::build(path = "./tools/tarballs")
devtools::build(path = ".")
devtools::install(dependencies = FALSE, build_vignettes = TRUE, quick = TRUE)
# litr::document() # <-- use instead of devtools::document()
# devtools::check(document = FALSE)

```

```{r}
print(getwd())

```

```{r post-hoc-cleaning, echo = F}
if (!dir.exists(getwd())) {
  dir.create(getwd())
}


gitpath = gsub("/scomps", "", getwd())
# packdir <- paste0(getwd(), "/scomps")

# if (!dir.exists(paste0(getwd(), "/scomps"))) {
#   dir.create(paste0(getwd(), "/scomps"))
# }
system("unalias cp")
system(paste0("cp -r ", getwd(), "/* ", gitpath))

Sys.sleep(1)

system(paste0("rm -r ", getwd()))

```