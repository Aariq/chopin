---
title: "Creating the ``r params$package_name`` R package"
author: "Insang Song"
date: "2023-09-03"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "scomps" # <-- change this to your package name
  package_parent_dir: "." # <-- relative to this file's location
---

<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->

## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.0.2.10032023",
    Title = "Scalable R geospatial computation",
    Description = "A package for scalable geospatial computation for environmental health research",
    `Authors@R` = person(
      given = "Insang",
      family = "Song",
      email = "geoissong@gmail.com",
      role = c("aut", "cre"),
      comment = c(ORCID = "0000-0001-8732-3256")
      )
  )
)
usethis::use_build_ignore("rds$", escape = FALSE)
usethis::use_package("dplyr") # Default is "Imports"
usethis::use_package("sf") # Default is "Imports"
# usethis::use_package("stars") # Default is "Imports"
usethis::use_package("terra") # Default is "Imports"
usethis::use_package("stars")
usethis::use_package("rlang") # Default is "Imports"
usethis::use_package("testthat")
usethis::use_package("logr", "Suggests") # Default is "Imports"
usethis::use_package("future") # Default is "Imports"
usethis::use_package("future.apply") # Default is "Imports"
usethis::use_package("igraph", "Suggests") # Default is "Imports"
usethis::use_package("withr", "Suggests")
usethis::use_package("covr")
usethis::use_package("future.batchtools", "Suggests") # Default is "Imports"
# usethis::use_gpl3_license()


# usethis::use_vignette("scomps_1_setting_distribution.rmd")
```
<!--
# usethis::use_mit_license(copyright_holder = "F. Last")
-->

```{r}
# parallelly::availableCores()
# plan(future.batchtools::batchtools_slurm)

```


### Vignettes 1

```{r}
litr::add_vignettes("../tools/vignettes-sources/00_good_practice_parallelization.Rmd")
```

### Vignettes 2

```{r}
litr::add_vignettes("../tools/vignettes-sources/01_generate_computational_grid.Rmd")
```


# Now to the package itself

### Create functions
```{r, send_to = "R/check.R"}
#' @title Return the package the input object is based on
#' @description Detect whether the input object is sf or Spat* object.
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @return A character object; one of 'terra' and 'sf'
#' @export
check_packbound <- function(input) {
  # cl_inobj = class(input)[1]
  stopifnot("Input should be one of sf or Spat* object.\n" = any(is(input, "sf"), is(input, "stars"), is(input, "SpatVector"), is(input, "SpatRaster")))
  if (is(input, "SpatVector") || is(input, "SpatRaster")) {
    return("terra")
  }
  return("sf")
}

check_datatype <- function(input) {
  stopifnot("Input should be one of sf or Spat* object.\n" = any(is(input, "sf"), is(input, "stars"), is(input, "SpatVector"), is(input, "SpatRaster")))
  if (any(is(input, "SpatVector"), is(input, "sf"))) {
    return("vector")
  }
  if (any(is(input, "SpatRaster"), is(input, "stars"))) {
    return("raster")
  }
}
```

```{r}
testthat::test_that("What package does the input object belong?",
{
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))
    bcsd_path = system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars = stars::read_stars(bcsd_path)

    packbound_stars = check_packbound(bcsd_stars)
    sprast_bcsd = terra::rast(bcsd_path)
    packbound_terra = check_packbound(sprast_bcsd)

    testthat::expect_equal(packbound_stars, "sf")
    testthat::expect_equal(packbound_terra, "terra")
})


testthat::test_that("What package does the input object belong?",
{
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))
    bcsd_path = system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars = stars::read_stars(bcsd_path)

    nc = system.file(package = "sf", "shape/nc.shp")
    nc = sf::read_sf(nc)

    datatype_stars = check_datatype(bcsd_stars)
    datatype_sf = check_datatype(nc)

    testthat::expect_equal(datatype_stars, "raster")
    testthat::expect_equal(datatype_sf, "vector")
})
```

```{r, send_to = "R/switch_format.R"}
#' @title Switch spatial data class
#' @description Convert stars into SpatRaster and vice versa; sf into SpatVector and vice versa.
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @return Data converted to the other package class (if sf, terra; if terra, sf)
#' @export
switch_packbound <- function(input) {
  stopifnot("Input should be one of sf or Spat* object.\n" = any(is(input, "sf"), is(input, "stars"), is(input, "SpatVector"), is(input, "SpatRaster")))
  cls_input = check_packbound(input)
  type_input = check_datatype(input)

  switched = 
  switch(cls_input,
    sf = switch(type_input,
      vector = terra::vect(input),
      raster = terra::rast(input)
    ),
    terra = switch(type_input,
      vector = sf::st_as_sf(input),
      raster = stars::st_as_stars(input)))

  invisible(switched)
}
```


```{r}

testthat::test_that("Format is well converted",
{
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))

    # starts from sf/stars
    bcsd_path = system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars = stars::read_stars(bcsd_path)
    nc = system.file(package = "sf", "shape/nc.shp")
    nc = sf::read_sf(nc)

    stars_bcsd_tr = switch_packbound(bcsd_stars)
    sf_nc_tr = switch_packbound(nc)

    testthat::expect_equal(check_packbound(stars_bcsd_tr), "terra")
    testthat::expect_equal(check_packbound(sf_nc_tr), "terra")

    stars_bcsd_trb = switch_packbound(stars_bcsd_tr)
    sf_nc_trb = switch_packbound(sf_nc_tr)

    testthat::expect_equal(check_packbound(stars_bcsd_trb), "sf")
    testthat::expect_equal(check_packbound(sf_nc_trb), "sf")

})


```

```{r, send_to = "R/check.R"}
#' @title check_crs2: Coordinate system checker
#' @description The input is checked whether its coordinate system is present. If not, it is reprojected to EPSG:5179.
#' @param input Input object one of sf or terra::Spat* object
#' @return A (reprojected) sf or SpatVector object.
#' @export
check_crs2 <- function(input, crs_standard = "EPSG:4326") {
  check_crs.sf <- function(input){
    if (is.na(st_crs(input))){cat('Please check the coordinate system or its EPSG code of your input object.'); return(NULL)}
    if (sf::st_crs(input)$epsg == crs_standard ) {
      return(input)
    } 
    input_transformed <- sf::st_transform(input, sf::st_crs(crs_standard))
    return(input_transformed)
  }

  check_crs.terra <- function(input) {
    if (terra::crs(input, describe = TRUE)$code == crs_standard) {
      return(input)
    }
    input_transformed = terra::project(input, terra::crs(crs_standard))
    return(input_transformed)
  }
    detected = check_packbound(input)
    switch(detected,
          terra = check_crs.terra(input),
          sf = check_crs.sf(input))
  }
```

```{r, send_to = "R/validate.R"}
#' Validate and repair input vector data
#' @description It tries repairing input vector data. Vector validity violation usually appears in polygon data with self-crossing or hole orders. This function will pass the input_vector object to sf::st_make_valid() (if input_vector is sf) or terra::makeValid() (if input_vector is SpatVector). May take some time depending on the geometry complexity.
#' @author Insang Song
#' @param input_vector One of sf or vect class. Target points of computation.
#' @return A repaired sf or SpatVector object depending on the class of input_vector.
#' @export
validate_and_repair_vectors <- function(input_vector) {
  detected = check_packbound(input_vector)

  validated = switch(detected,
    terra = terra::makeValid(input_vector),
    sf = sf::st_make_valid(input_vector))

  return(validated)
}

```


```{r, send_to = "R/logging.R"}
#' Turn on logging
#' @author Insang Song
#' @param expr expression. Any function call to be logged.
#' @param dolog logical(1). Will the messages be logged.
#' @param logpath character(1). Log file path with the full log file name.
#' @return Nothing. It will export a log file in the specified path as logpath.
#' @export
initate_log <- function(expr, dolog = FALSE, logpath) {
  if (!dolog) {
    return(NULL)
  }
  logr::log_path(logpath)
  try(expr)
  logr::log_close()
  return(NULL)
}


```

```{r, send_to = "R/preprocessing.R"}
#' Setting the clipping extent
#' @description Return clipping extent with buffer radius. It assumes the input CRS is projected and linear unit is meters.
#' @author Insang Song
#' @param pnts One of sf or vect class. Target points of computation.
#' @param buffer_r numeric(1). Buffer radius. It is assumed in metres 
#' @return A terra::ext or sfc_POLYGON object of the computation extent.
#' @export
set_clip_extent <- function(pnts, buffer_r) {
  detected = check_packbound(pnts)
  if (detected == "terra") {
    ext_input = terra::ext(pnts)
    # Note that `+` operation on terra::ext output accounts for the operand as it is.
    ext_input = ext_input + (1.1 * buffer_r + 30)
  }
  if (detected == "sf") {
    ext_input <- pnts |> sf::st_bbox()
    # Note that `+` operation on st_bbox output simply adds the number; we add a vector here.
    ext_input <- ext_input + ((1.1 * c(-1, -1, 1, 1) * buffer_r) + 30)
    ext_input <- sf::st_as_sfc(ext_input)
  }
  return(ext_input)
}
```


```{r, send_to = "R/processing.R"}
#' Extent clipping
#' @description Clip input vector by the expected maximum extent of computation. 
#' @author Insang Song
#' @param pnts sf or SpatVector object
#' @param buffer_r numeric(1). buffer radius. this value will be automatically multiplied by 1.25
#' @param nqsegs integer(1). the number of points per a quarter circle; SOON TO BE DEPRECATED
#' @param target_input sf or SpatVector object to be clipped
#' @return A clipped sf or SpatVector object.
#' @export
clip_as_extent <- function(pnts, buffer_r, nqsegs=NULL, target_input){
  if (any(sapply(list(pnts, buffer_r, target_input), is.null))) {
    stop("One or more required arguments are NULL. Please check.\n")
  }
  detected_pnts = check_packbound(pnts)
  detected_target = check_packbound(target_input)

  if (detected_pnts != detected_target) {
    warning("Inputs are not the same class.\n")
    target_input = switch(detected_target,
        sf = terra::vect(target_input),
        terra = sf::st_as_sf(target_input))
  }
  
  ext_input = set_clip_extent(pnts, buffer_r)
  cat("Clip target features with the input feature extent...\n")
  if (detected_pnts == "sf") {
    cae = ext_input |>
      sf::st_intersection(x = target_input)
  }
  if (detected_pnts == "terra") {
    cae = terra::intersect(target_input, ext_input)
  }
   
  return(cae)
}
```


```{r, send_to = "R/processing.R"}
#' @title clip_as_extent_ras: Clip input raster.
#' @description Clip input raster by the expected maximum extent of computation. 
#' @author Insang Song
#' @param pnts sf or SpatVector object
#' @param buffer_r numeric(1). buffer radius. this value will be automatically multiplied by 1.25
#' @param nqsegs integer(1). the number of points per a quarter circle
#' @param ras SpatRaster object to be clipped
#' @export
clip_as_extent_ras <- function(pnts, buffer_r, nqsegs = 180, ras){
  if (any(sapply(list(pnts, buffer_r, ras), is.null))) {
    stop("Any of required arguments are NULL. Please check.\n")
  }
  ext_input = set_clip_extent(pnts, buffer_r) |>
    terra::ext()

  cae <- terra::crop(ras, ext_input, snap = 'out')
  return(cae)
}
```


```{r, send_to = "R/processing.R"}
#' @title clip_as_extent_ras2: Clip input raster (version 2).
#' @description Clip input raster by the expected maximum extent of computation. 
#' @author Insang Song
#' @param points_in sf or SpatVector object
#' @param buffer_r numeric(1). buffer radius. this value will be automatically multiplied by 1.25
#' @param nqsegs integer(1). the number of points per a quarter circle
#' @param ras SpatRaster object to be clipped
#' @export
clip_as_extent_ras2 <- function(points_in, buffer_r, nqsegs=180, ras){
  if (any(sapply(list(points_in, buffer_r, ras), is.null))) {
    stop("Any of required arguments are NULL. Please check.\n")
  }
  ext_input = set_clip_extent(points_in, buffer_r) |>
    terra::ext()

  cae <- terra::crop(ras, ext_input, snap = 'out')
  return(cae)
}
```


```{r, send_to = "R/indexing.R"}
#' @title Create integer indices for grid
#' @description Returns a tibble object that includes x- and y- index by using two inputs ncutsx and ncutsy, which are x- and y-directional splits, respectively.
#' @author Insang Song
#' @param points_in sf object. 
#' @param ncutsx integer(1). The number of splits along x-axis.
#' @param ncutsy integer(1). The number of splits along y-axis.
#' @export
sp_indexing <- function(points_in, ncutsx, ncutsy){
  # pts <- data.table(pnts)
  points_in <- points_in |>
    mutate(or_id = seq(1, dim(points_in)[1]))
  
  range_x  <- range(points_in$x)
  limits_x <- (range_x[1] + seq(0, ncutsx) * (range_x[2] - range_x[1]) / ncutsx)
  range_y  <- range(points_in$y)
  limits_y <- (range_y[1] + seq(0, ncutsy) * (range_y[2] - range_y[1]) / ncutsy)
  
  points_in_cut <- points_in |>
    mutate(xcut =  as.integer(cut(x, ncutsx, labels = seq(1, ncutsx))),
           ycut = as.integer(cut(y, ncutsy, labels = seq(1, ncutsy))))
  
  return(points_in_cut)
}
```

```{r, send_to = "R/preprocessing.R"}
#' Quick call for SpatRaster with a window
#' 
#' @param rasterpath character(1). Path to the raster file.
#' @param win Named integer vector (4) or terra::ext() results.
#' @param author Insang Song 
#' @export 
rast_short <- function(rasterpath, win) {
  terra::rast(rasterpath, win = win)
}

```



```{r}
#' Estimate computational demands from inputs (to be written)
#' 
#' @param inputs a list of sf/Spat* objects or file paths
#' @param nx integer(1). 
#' @param ny integer(1). 
#' @param padding numeric(1). Extrusion factor 
#' @export 
estimate_demands <- function(
  inputs,
  nx, ny,
  padding
) {
  ## cpu 
  ## memory
  ## estimate maximum coverage
  ## clipped data size
  ## total distributed memory
  ## return a list of total demands 
  ## print summary of results
}

```


```{r, send_to = "R/interpret_computational_domain.R"}
#' Get a set of computational regions
#' 
#' @param input sf or Spat* object.
#' @param mode character(1). Mode of region construction. One of "grid" (simple grid regardless of the number of features in each grid), "density" (clustering-based varying grids), "grid_advanced" (merging adjacent grids with smaller number of features than grid_min_features). 
#' @param nx integer(1). The number of grids along x-axis.
#' @param ny integer(1). The number of grids along y-axis.
#' @param grid_min_features integer(1). A threshold to merging adjacent grids
#' @param padding numeric(1). A extrusion factor to make buffer to clip actual datasets. Depending on the length unit of the CRS of input.
#' @param unit character(1). The length unit for padding (optional). units::set_units is used for padding when sf object is used. See \link{units package vignette (web)}{https://cran.r-project.org/web/packages/units/vignettes/measurement_units_in_R.html} for the list of acceptable unit forms.
#' @return A set of polygons in the input class
#' @description TODO. Using input points, the bounding box is split to the predefined numbers of columns and rows. Each grid will be buffered by the radius.   
#' @author Insang Song 
#' @examples 
#' # data
#' 
#' # run
#' get_computational_regions()
#' 
#' @export 
get_computational_regions <- function(input, mode = "grid", nx = 10, ny = 10, grid_min_features = 30, padding = NULL, unit = NULL, ...) {
  # type check
  package_detected = check_packbound(input)
  # stopifnot("Invalid input.\n" = !any(grepl("^(sf|Spat)", class(input))))
  stopifnot("Argument mode should be one of 'grid', 'grid_advanced', or 'density'.\n" = !mode %in% c("grid", "grid_advanced", "density"))
  stopifnot("Ensure that nx, ny, and grid_min_features are all integer.\n" = all(is.integer(nx), is.integer(y), is.integer(grid_min_features)))
  stopifnot("padding should be numeric. We convert padding to numeric...\n" = !is.numeric(padding))
  # valid unit compatible with units::set_units?

    # if (detected_pnts == "sf") {
    # }
    # if (detected_pnts == "terra") {
    #   grid1$ID = seq(1, nrow(grid1))
    # }
  }

#' @title sp_index_grid: Generate grid polygons
#' @description Returns a sf object that includes x- and y- index by using two inputs ncutsx and ncutsy, which are x- and y-directional splits, respectively.
#' @author Insang Song
#' @param points_in sf or SpatVector object. Target points of computation.
#' @param ncutsx integer(1). The number of splits along x-axis.
#' @param ncutsy integer(1). The number of splits along y-axis.
#' @return A sf or SpatVector object of computation grids with unique grid id (CGRIDID).
#' @export
sp_index_grid <- function(points_in, ncutsx, ncutsy){
  package_detected = check_packbound(points_in)

  sp_index_grid.sf = function(points_in, ncutsx, ncutsy) {
    grid1 <- sf::st_make_grid(points_in, n = c(ncutsx, ncutsy)) |> 
      as.data.frame() |> 
      st_as_sf()
    grid1 <- grid1[points_in, ]
    return(grid1)
  }
  sp_index_grid.terra = function(points_in, ncutsx, ncutsy) {
    grid1 <- terra::rast(points_in, nrows = ncutsy, ncols = ncutsx)
    grid1 <- terra::as.polygons(grid1)
    return(grid1)
  }
  grid_out = switch(package_detected,
        sf = sp_index_grid.sf(points_in, ncutsx, ncutsy),
        terra = sp_index_grid.terra(points_in, ncutsx, ncutsy))
    
  grid_out$CGRIDID = seq(1, nrow(x = grid_out)) 
  return(grid_out)

}


#' @title grid_merge: Merge grid polygons with given rules
#' @description Merge boundary-sharing (in "Rook" contiguity) grids with fewer target features than the threshold. This function strongly assumes that the input is returned from the sp_index_grid, which has 'CGRIDID' as the unique id field.
#' @author Insang Song
#' @param points_in sf or SpatVector object. Target points of computation.
#' @param grid_in sf or SpatVector object. The grid generated by sp_index_grid
#' @param grid_min_features integer(1). Threshold to merge adjacent grids.
#' @return A sf or SpatVector object of computation grids.
#' @examples
#' # library(sf)
#' # library(igraph)
#' # ligrary(dplyr)
#' # dg = st_as_sfc(st_bbox(c(xmin = 0, ymin = 0, xmax = 8e5, ymax = 6e5)))
#' # st_crs(dg) = 5070
#' # dgs = st_as_sf(st_make_grid(dg, n = c(20, 15)))
#' # dgs$CGRIDID = seq(1, nrow(dgs))
#' #
#' # dg_sample = st_sample(dg, kappa = 5e-9, mu = 15, scale = 20000, type = "Thomas")
#' # st_crs(dg_sample) = st_crs(dg)
#' # dg_merged = grid_merge(st_as_sf(sss), dgs, 100)
#' #### NOT RUN ####
#' @export
grid_merge <- function(points_in, grid_in, grid_min_features){
  package_detected = check_packbound(points_in)
  if (package_detected == "terra") {
    points_in = sf::st_as_sf(points_in)
    grid_in = sf::st_as_sf(grid_in)
  }

  n_points_in_grid = lengths(sf::st_intersects(grid_in, points_in))
  grid_self = sf::st_relate(grid_in, grid_in, pattern = "2********")
  grid_rook = sf::st_relate(grid_in, grid_in, pattern = "F***1****")
  grid_rooks = mapply(c, grid_self, grid_rook, SIMPLIFY = FALSE)
  grid_lt_threshold = (n_points_in_grid < grid_min_features)
  stopifnot("Threshold is too low. Please try higher threshold.\n" = sum(grid_lt_threshold) != 0)
  grid_lt_threshold = seq(1, nrow(grid_in))[grid_lt_threshold]

  # This part does not work as expected. Should investigate edge list and actual row index of the grid object; 
  identified = lapply(grid_rooks, \(x) sort(x[which(x %in% grid_lt_threshold)]))
  identified = identified[grid_lt_threshold]
  identified = unique(identified)
  identified = identified[sapply(identified, length) > 1]

  identified_graph = lapply(identified, \(x) t(combn(x, 2))) |>
    Reduce(f = rbind, x = _) |>
    unique() |>
    apply(X = _, 2, as.character) |>
    igraph::graph_from_edgelist(el = _, directed = 0) |>
    igraph::mst() |>
    igraph::components()
  # return(identified_graph)

  identified_graph_member = identified_graph$membership

  merge_idx = as.integer(names(identified_graph_member))
  merge_member = split(merge_idx, identified_graph_member)
  merge_member_label = unlist(lapply(merge_member, \(x) paste(x, collapse = "_")))
  merge_member_label = merge_member_label[identified_graph_member]

  # sf object manipulation
  grid_out = grid_in
  grid_out[["CGRIDID"]][merge_idx] = merge_member_label
  # for (k in seq_along(merge_member_label)) {
  #   target_idx = merge_member_label[[k]]
  #   grid_out[["CGRIDID"]][target_idx] = paste("M_", paste(target_idx, collapse = "_"), sep = "")
  # }
  grid_out = grid_out |>
    dplyr::group_by(CGRIDID) |>
    dplyr::summarize(n_merged = n()) |>
    dplyr::ungroup() 

  ## polsby-popper test for shape compactness
  grid_merged = grid_out[which(grid_out$n_merged > 1),]
  grid_merged_area = as.numeric(sf::st_area(grid_merged))
  grid_merged_perimeter = as.numeric(sf::st_length(sf::st_cast(grid_merged, "LINESTRING")))
  grid_merged_pptest = (4 * pi * grid_merged_area) / (grid_merged_perimeter ^ 2)

  # pptest value is bounded [0,1]; 0.3 threshold is groundless at this moment, possibly will make it defined by users.
  if (max(unique(identified_graph_member)) > floor(0.1 * nrow(grid_in)) || any(grid_merged_pptest < 0.3)) {
    warning("The reduced computational regions have too complex shapes. Consider increasing thresholds or using the original grids.\n")
  }

  return(grid_out)

  # union unique sets into one
  # identified_relation = matrix(NA, length(identified), length(identified))
  # diag(identified_relation) = lengths(identified)

  # for (i in seq_len(length(identified))) {
  #   for (j in seq(i, length(identified))) {
  #     identified_relation[i, j] = length(intersect(identified[[i]], identified[[j]]))
  #     identified_relation[j, i] = identified_relation[i, j]
  #   }
  # }
  # # identified_relation = max(identified_relation) - identified_relation
  # return(as.dist(identified_relation))
}



```



```{r, send_to = "R/check.R"}
#' Check if the data extent is inside the reference bounding box
#' 
#' @description One of the most common errors in spatial computation is rooted in the entirely or partly incomparable spatial extents of input datasets. This function returns whether your data is inside the target computational extent. It is assumed that you know and have the exact computational region. This function will return TRUE if the reference region completely contains your data's extent and FALSE otherwise.
#' @param data_query sf*/stars/SpatVector/SpatRaster object.
#' @param reference sf*/stars/SpatVector/SpatRaster object or a named numeric vector with four names (xmin, ymin, xmax, and ymax).
#' @param reference_crs Well-known-text-formatted or EPSG code of the reference's coordinate system. Only required when a named numeric vector is passed to reference. 
#' @return TRUE (the queried data extent is completely within the reference bounding box) or FALSE 
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export
check_bbox <- function(
  data_query, reference, reference_crs = NULL
) {
  if (is.numeric(reference) && is.null(reference_crs)) {
    stop("CRS should be entered when the reference extent is a vector.\n")
  }
  if (is.numeric(reference) && !is.null(reference_crs)) {
    reference = sf::st_as_sfc(sf::st_bbox(reference), crs = reference_crs)
  }
  query_crs = check_crs(data_query)
  ref_crs = check_crs(reference)
  if (is.na(query_crs) || is.null(query_crs)) {
    stop("The dataset you queried has no CRS. Please make sure your dataset has the correct CRS.\n")
  }

  # ...

  check_result
  return(check_result)
}


```


```{r}
#' Check if the data extent is inside the reference bounding box
#' 
#' @description One of the most common errors in spatial computation is rooted in the entirely or partly incomparable spatial extents of input datasets. This function returns whether your data is inside the target computational extent. It is assumed that you know and have the exact computational region. This function will return TRUE if the reference region completely contains your data's extent and FALSE otherwise.
#' @param data_query sf*/stars/SpatVector/SpatRaster object.
#' @param reference sf*/stars/SpatVector/SpatRaster object or a named numeric vector with four names (xmin, ymin, xmax, and ymax).
#' @param reference_crs Well-known-text-formatted or EPSG code of the reference's coordinate system. Only required when a named numeric vector is passed to reference. 
#' @return TRUE (the queried data extent is completely within the reference bounding box) or FALSE 
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export


```

```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with generic polygons
#' 
#' @description For simplicity, it is assumed that the coordinate systems of the points and the raster are the same. Kernel function is not yet implemented. 
#' @param polys sf/SpatVector object. Polygons.
#' @param surf stars/SpatRaster object. A raster of whatnot a summary will be calculated
#' @param id character(1). Unique identifier of each point.
#' @param func a function taking one argument. For example, function(x) mean(x, na.rm = TRUE) or \(x) mode(x, na.rm = TRUE)
#' @param na.rm logical(1). NA values are omitted when summary is calculated.
#' @return a data.frame object with function value
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export
extract_with_polygons <- function(
    polys, surf, id, func = mean, na.rm = TRUE
    ) {
    # type check
    stopifnot("Check class of the input points.\n" = any(is(polys, "sf"), is(polys, "SpatVector")))
    stopifnot("Check class of the input raster.\n" = any(is(surf, "stars"), is(surf, "SpatRaster")))
    stopifnot(is.character(id))

    cls_polys = check_packbound(polys)
    cls_surf = check_packbound(surf)

    if (cls_polys != cls_surf) {
      polys = switch_packbound(polys)
    }

    extract_with_polygons.sf = function(polys, surf, id, func) {
        extracted = stars::st_extract(x = surf, at = polys, FUN = func)
        # extracted = extracted |>
        #   group_by(!!sym(id)) |>
        #   summarize(across(-!!sym(id), ~func)) |>
        #   ungroup()
        return(extracted)
    }

    extract_with_polygons.terra = function(polys, surf, id, func) {
        extracted = terra::extract(surf, polys)
        extracted = extracted |>
          group_by(!!sym(id)) |>
          summarize(across(-!!sym(id), ~func)) |>
          ungroup()
        return(extracted)
    }

    extracted_poly = switch(
        cls_surf,
        sf = extract_with_polygons.sf(polys = polys, surf = surf, id = id, func = func),
        terra = extract_with_polygons.terra(polys = polys, surf = surf, id = id, func = func)
    )
    return(extracted_poly)
}

```

```{r, send_to = "R/processing.R"}
#' Extract raster values with point buffers or polygons
#' 
#' @param raster SpatRaster object. 
#' @param vector SpatVector object.
#' @param id character(1). Unique identifier of each point.
#' @param func function taking one numeric vector argument.
#' @param mode one of "polygon" (generic polygons to extract raster values with) or "buffer" (point with buffer radius)
#' @param ... various. Passed to extract_with_buffer. See \code{?extract_with_buffer} for details.
#' @return 
#' @author Insang Song \email{geoissong@@gmail.com}
#' @export
extract_with <- function(raster, vector, id, func = mean, mode = "polygon", ...) {
    if (!mode %in% c("polygon", "buffer")) {
      stop("Argument 'mode' should be one of 'polygon' or 'buffer'.\n")
    }
    stopifnot(is.character(id))
    stopifnot(id %in% names(vector))

    extracted = 
      switch(mode,
        polygon = extract_with_polygons(vector, raster, id, func),
        buffer = extract_with_buffer(vector, raster, id = id, func = func, ...))
    return(extracted)
}

```

```{r, send_to = "R/check.R"}
#' Check Coordinate Reference System
#' @param x sf/stars/SpatVector/SpatRaster object.
#' @return A st_crs or crs object.
#' @description 
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples 
#' # data
#' library(sf)
#' ncpath = system.file("shape/nc.shp", package = "sf")
#' nc = read_sf(ncpath)
#' check_crs(nc)
#' 
#' @export 
check_crs <- function(x) {
    stopifnot("Input is invalid.\n" = (is(x, "sf") || is(x, "stars") || is(x, "SpatVector") || is(x, "SpatRaster")))
    
    if (is(x, "sf") || is(x, "stars")) {
        crs_wkt = sf::st_crs(x)
    } else {
        crs_wkt = terra::crs(x)
    }

    stopifnot("No CRS is defined in the input. Please consult the metadata or the data source.\n" = !is.na(crs_wkt) || crs_wkt != "")
    return(crs_wkt)
}
```


```{r, send_to = "R/check.R"}
#' Check if the boundary of the vector/raster object is inside the reference
#' @param input_object sf/stars/SpatVector/SpatRaster object.
#' @param reference sf/stars/SpatVector/SpatRaster object.
#' @return logical
#' @author Insang Song \email{geoissong@@gmail.com}
#' @export 
check_within_reference <- function(input_object, reference) {
    stopifnot("Input is invalid.\n" = (is(x, "sf") || is(x, "stars") || is(x, "SpatVector") || is(x, "SpatRaster")))
    stopifnot("Reference is invalid.\n" = (is(x, "sf") || is(x, "stars") || is(x, "SpatVector") || is(x, "SpatRaster")))

  bbox_input <- input_object
    sf::st_bbox() |>
    sf::st_as_sfc()
  
  bbox_reference = reference |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  iswithin = sf::st_covered_by(bbox_input, bbox_reference)
  iswithin = length(iswithin[[1]])
  iswithin = (iswithin == 1)
  invisible(iswithin)
}


```


```{r, send_to = "R/processing.R"}
#' Calculate SEDC covariates
#' @param point_from SpatVector object. Locations where the sum of SEDCs are calculated.
#' @param point_to SpatVector object. Locations where each SEDC is calculated.
#' @param sdec_bandwidth numeric(1). Distance at which the source concentration is reduced to exp(-3) (approximately 95 %)  
#' @param threshold numeric(1). For computational efficiency, the nearest points in threshold will be selected
#' @param target_fields character(varying). Field names in characters.
#' @description NOTE: sf implementation is pending. Only available for terra.
#' @author Insang Song
#' @export
calculate_sedc <- function(point_from, point_to, id, sedc_bandwidth, threshold, target_fields) {
  # define sources, set SEDC exponential decay range
  len_point_from = seq_len(nrow(point_from))
  len_point_to = seq_len(nrow(point_to))

  point_from$from_id = len_point_from
  # select egrid_v only if closer than 3e5 meters from each aqs
  point_from_buf = terra::buffer(point_from_buf, threshold = threshold, quadsegs = 90)
  point_to = point_to[point_from_buf,]
  point_to$to_id = len_point_to

  # near features with distance argument: only returns integer indices
  near_from_to = terra::nearby(point_from, point_to, distance = threshold)
  # attaching actual distance
  dist_near_to = terra::distance(point_from, point_to)
  dist_near_to_df = as.vector(dist_near_to)
  # adding integer indices
  dist_near_to_tdf = expand.grid(from_id = len_point_from, to_id = len_point_to)
  dist_near_to_df = cbind(dist_near_to_tdf, dist = dist_near_to_df)

  # summary
  near_from_to = near_from_to |>
    as_tibble() |>
    left_join(data.frame(point_from)) |>
    left_join(data.frame(point_to)) |>
    left_join(dist_near_to_df) |>
    # per the definition in https://mserre.sph.unc.edu/BMElab_web/SEDCtutorial/index.html
    # exp(-3) is about 0.05
    mutate(w_sedc = exp((-3 * dist) / sedc_bandwidth)) |>
    group_by(!!sym(id)) |>
    summarize(across(all_of(target_fields), list(sedc = ~sum(w_sedc * ., na.rm = TRUE)))) |>
    ungroup()

  invisible(near_from_to)
  
}

```

```{r, send_to = "R/processing.R"}
#' Computing area weighted covariates using two polygon sf or SpatVector objects
#' @param poly_in A sf/SpatVector object at weighted means will be calculated.
#' @param poly_weight A sf/SpatVector object from which weighted means will be calculated.
#' @param id_poly_in character(1). The unique identifier of each polygon in poly_in
#' @return A data.frame with all numeric fields of area-weighted means.
#' @description When poly_in and poly_weight are different classes, poly_weight will be converted to the class of poly_in. 
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples 
#' # package
#' library(sf)
#' 
#' # run
#' nc = st_read(system.file("shape/nc.shp", package="sf"))
#' nc = st_transform(nc, 5070)
#' pp = st_sample(nc, size = 300)
#' pp = st_as_sf(pp)
#' pp[["id"]] = seq(1, nrow(pp))
#' st_crs(pp) = "EPSG:5070"
#' ppb = st_buffer(pp, nQuadSegs=180, dist = units::set_units(20, 'km'))
#' 
#' system.time({ppb_nc_aw = aw_covariates(ppb, nc, 'id')})
#' summary(ppb_nc_aw)
#' #### Example of aw_covariates ends ####
#' @export
aw_covariates <- function(poly_in, poly_weight, id_poly_in = "ID") {
    stopifnot("Inputs have invalid classes.\n" = 
      is(poly_in, "sf") || is(poly_weight, "sf") || is(poly_in, "SpatVector") || is(poly_weight, "SpatVector"))
    #check_crs()

    ## distinguish numeric and nonnumeric columns
    index_numeric = grep("(integer|numeric)", unlist(sapply(poly_weight, class)))
    
    aw_covariates.terra = function(poly_in, poly_weight, id_poly_in = id_poly_in) {
        
        poly_intersected = terra::intersect(poly_in, poly_weight)
        poly_intersected[["area_segment_"]] = terra::expanse(poly_intersected)
        poly_intersected = data.frame(poly_intersected) |>
            dplyr::group_by(!!rlang::sym(id_poly_in)) |>
            dplyr::summarize(across(is.numeric,
                        ~weighted.mean(., w = area_segment_))) |>
            dplyr::ungroup()
        return(poly_intersected)
    }

    class_poly_in = check_packbound(poly_in)
    class_poly_weight = check_packbound(poly_weight)

    if (class_poly_in != class_poly_weight) {
      class_poly_weight = switch_packbound(class_poly_weight)
    }
    
    switch(class_poly_in,
        sf = sf::st_interpolate_aw(poly_weight[,index_numeric], poly_in, extensive = FALSE),
        terra = aw_covariates.terra(poly_in, poly_weight[,index_numeric], id_poly_in = id_poly_in))
    
}

# ncbuf = terra::intersect(vect(ppb), vect(nc))
# ncbuf_a = ncbuf
# ncbuf_a$segarea = expanse(ncbuf_a)
# ncbuf_k = data.frame(ncbuf_a) |>
#   dplyr::group_by(id) |>
#   dplyr::summarize(across(is.numeric,
#                ~weighted.mean(., w = segarea))) |>
#   dplyr::ungroup()

#ncbufagg = terra::aggregate(ncbuf, by = 'id', fun = weighted.mean, w = ncbuf_a$segarea)

```

```{r, send_to = "R/processing.R"}
#' Subfunction: extract with buffers (flat weight; simple mean)
#' 
#' @export 
extract_with_buffer.flat <- function(
        points, surf, radius, id, qsegs, func = mean, kernel = NULL, bandwidth = NULL
    ) {
    # generate buffers
    bufs = terra::buffer(points, width = radius, quadsegs = qsegs)
    # crop raster
    bufs_extent = terra::ext(bufs)
    surf_cropped = terra::crop(surf, bufs_extent)
    name_surf_val = names(surf)
    # extract raster values
    surf_at_bufs = terra::extract(surf_cropped, bufs)
    surf_at_bufs_summary = 
        surf_at_bufs |> 
            group_by(ID) |> 
            summarize(across(all_of(name_surf_val), ~mean, na.rm=T)) |> 
            ungroup()
    return(surf_at_bufs_summary)
}
```

```{r, send_to = "R/processing.R"}
#' Subfunction: extract with buffers (kernel weight; weighted mean)
#'
#' @export 
extract_with_buffer.kernel <- function(
        points, surf, radius, id, qsegs, func = mean, kernel, bandwidth
    ) {
        # generate buffers
        bufs = terra::buffer(points, width = radius, quadsegs = qsegs)
        # crop raster
        bufs_extent = terra::ext(bufs)
        surf_cropped = terra::crop(surf, bufs_extent)
        name_surf_val = names(surf)

        # TODO: kernel implementation


        # extract raster values
        surf_at_bufs = terra::extract(surf_cropped, bufs)
        surf_at_bufs_summary = 
            surf_at_bufs |> 
                group_by(ID) |> 
                summarize(across(all_of(name_surf_val), ~mean, na.rm=T)) |> 
                ungroup()
        return(surf_at_bufs_summary)
}
```


```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with points and a buffer radius (to be written)
#' 
#' @description For simplicity, it is assumed that the coordinate systems of the points and the raster are the same. Kernel function is not yet implemented. 
#' @param points SpatVector object. Coordinates where buffers will be generated
#' @param surf SpatRaster object. A raster of whatnot a summary will be calculated
#' @param radius numeric(1). Buffer radius. here we assume circular buffers only
#' @param id character(1). Unique identifier of each point.
#' @param qsegs integer(1). Number of vertices at a quarter of a circle. Default is 90.
#' @param func a function taking a numeric vector argument.
#' @param kernel character(1). Name of a kernel function (yet to be implemented)
#' @param bandwidth numeric(1). Kernel bandwidth.
#' @return a data.frame object with mean value
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export
extract_with_buffer <- function(
    points, surf, radius, id, qsegs = 90, func = mean, kernel = NULL, bandwidth = NULL
    ) {
    # type check
    stopifnot("Check class of the input points.\n" = is(points, "SpatVector"))
    stopifnot("Check class of the input radius.\n" = is.numeric(radius))
    stopifnot(is.character(id))
    stopifnot(is.integer(qsegs))

    if (!is.null(kernel)) {
        extracted = extract_with_buffer.flat(points = points,
                                      surf = surf,
                                      radius = radius,
                                      id = id,
                                      func = func,
                                      qsegs = qsegs)
        return(extracted)
    }

    extracted = extract_with_buffer.kernel(points = points,
                                           surf = surf,
                                           radius = radius,
                                           id = id,
                                           func = func,
                                           qsegs = qsegs,
                                           kernel = kernel,
                                           bandwidth = bandwidth)
    return(extracted)

}



```


```{r, send_to = "R/interpret_computational_domain.R"}
#' @title Process a given function in the entire or partial computational grids (under construction)
#' 
#' @description Should 
#' @param grids sf/SpatVector object. Computational grids.
#' @param grid_id character(1) or numeric(2). Default is NULL. If NULL, all grid_ids are used. "id_from:id_to" format or c(unique(grid_id)[id_from], unique(grid_id)[id_to])
#' @param fun function supported in scomps. 
#' @param ... Arguments passed to fun.
#' @return a data.frame object with mean value
#' @author Insang Song \email{geoissong@@gmail.com}
#' 
#' @export
distribute_process <- function(grids, grid_id = NULL, fun, ...) {
    require(future.apply)
    
    # subset using grids and grid_id
    if (!is.null(grid_id)) {
        if (is.character(grid_id)) {
            grid_id_parsed = strsplit(grid_id, ":", fixed = TRUE)[[1]]
            grid_ids = c(which(unique(grids[["CGRIDID"]]) == grid_id_parsed[1]),
                         which(unique(grids[["CGRIDID"]]) == grid_id_parsed[2]))
        }
        if (is.numeric(grid_id)) {
            grid_ids = unique(grids[["CGRIDID"]])[grid_id]
        }
    }
    grids_target = grids[grid_ids,]
    grids_target_list = split(grids_target, grids_target[["CGRIDID"]])

    results_distributed = future.apply::future_lapply(
        \(x, ...) {
            fun(...)
        }, grids_target_list, points_cutslist, SIMPLIFY = FALSE,
        future.seed = TRUE)
    results_distributed = do.call(rbind, results_distributed)
    return(results_distributed)
}

```

## Documenting the package and building

We finish by running commands that will document, build, and install the package.  It may also be a good idea to check the package from within this file.

```{r}
litr::document() # <-- use instead of devtools::document()
devtools::test()
devtools::build()
devtools::install(build_vignettes = TRUE, dependencies = F)
# devtools::check(document = FALSE)

```