---
title: "CHOPIN: Computation for Climate and Health research On Parallelized INfrastructure: ``r params$package_name``"
author: "Insang Song"
date: "2024-01-24"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "chopin" # <-- change this to your package name
  package_parent_dir: "." # <-- relative to this file's location
---

<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->

## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.2.1.01262024",
    Title = "CHOPIN: Computation for Climate and Health research On Parallelized INfrastructure",
    Description = "A package for scalable geospatial computation for environmental health research",
    `Authors@R` = c(
      person(
        given = "Insang",
        family = "Song",
        email = "geoissong@gmail.com",
        role = c("aut", "cre"),
        comment = c(ORCID = "0000-0001-8732-3256")
      ),
      person(
        given = "Kyle",
        family = "Messier",
        role = c("aut", "ctb"),
        comment = c(ORCID = "0000-0001-9508-9623")
      )
    ),
    LazyData = "true",
    LazyDataCompression = "xz"
  )
)
#usethis::use_build_ignore("rds$", escape = FALSE)
usethis::use_build_ignore(c("/tools"), escape = FALSE)
usethis::use_build_ignore(c("/figure"), escape = FALSE)
usethis::use_build_ignore(c("/containers"), escape = FALSE)
usethis::use_build_ignore(c("\\*.Rmd"), escape = FALSE)
usethis::use_build_ignore(c("\\*.rmd"), escape = FALSE)

usethis::use_package("dplyr")
usethis::use_package("sf")
usethis::use_package("terra")
usethis::use_package("stars")
usethis::use_package("rlang")
usethis::use_package("methods")
usethis::use_package("exactextractr")
usethis::use_package("future")
usethis::use_package("future.apply")
usethis::use_package("covr", "Suggests")
usethis::use_package("lobstr", "Suggests")
usethis::use_package("testthat", "Suggests")
usethis::use_package("units", "Suggests")
usethis::use_package("tigris", "Suggests")
usethis::use_package("doFuture")
usethis::use_package("future.batchtools", "Suggests")
usethis::use_package("igraph", "Suggests")
usethis::use_package("withr", "Suggests")
usethis::use_mit_license()

usethis::use_pkgdown()

# https://cran.r-project.org/web/packages/roxygen2/vignettes/rd-formatting.html#lists
usethis::use_roxygen_md()
# usethis::use_pkgdown_github_pages()

# usethis::use_vignette("1_setting_distribution.rmd")
```
<!--
-->

```{r}
desc::desc_set(
  "https",
  "//spatiotemporal-exposures-and-toxicology.github.io/chopin"
  )
```


### Test data generation
```{r generate-test-data, eval=FALSE, include=FALSE}
OPENTOPO_CREDENTIAL <- ""

pkgs <- c("sf", "terra", "dplyr", "spatstat.random", "elevatr")
invisible(sapply(pkgs, library, character.only = TRUE, quietly = TRUE))
elevatr::set_opentopo_key(OPENTOPO_CREDENTIAL)
sf::sf_use_s2(FALSE)
set.seed(300)
ncpath <- system.file("shape/nc.shp", package = "sf")
ncpoly <- sf::read_sf(ncpath) %>%
  sf::st_transform("EPSG:5070")

ncrandpoint <- sf::st_sample(type = "Thomas", x = ncpoly, size = 300, mu = 0.00005, scale = 16000, kappa = 0.00005) %>%
  mutate(pid = seq_len(nrow(.))) %>%
  select(-label)
sf::st_crs(ncrandpoint) <- "EPSG:5070"
saveRDS(ncrandpoint, "./tests/testdata/nc_random_point.rds")

ncrast <- elevatr::get_elev_raster(ncpoly, z = 9, src = "srtm15plus", prj = terra::crs("EPSG:5070"))
ncrastt <- terra::rast(ncrast)
ncrastw <- terra::wrap(ncrastt)
# terra::writeRaster(ncrastt, "./tests/testdata/nc_srtm15_otm.tif", gdal=c("COMPRESS=DEFLATE"), overwrite = TRUE)
saveRDS(ncrastw, "./tests/testdata/nc_srtm15_otm.rds", compress = "xz")

library(nhdplusTools)
huc08s <- get_huc(AOI = sf::st_union(ncpoly), buffer = 10000L, type = "huc08")
library(readxl)

ecors <- list.files(path = "/Users/songi2/Documents/Ecoregions/",
  pattern = "*.xlsx", full.names = TRUE) %>%
  .[-length(.)] %>%
  lapply(\(x) readxl::read_excel(x, sheet = 4)) %>%
  do.call(bind_rows, .)

huc08sadd <- left_join(huc08s, ecors, by = c("huc8" = "Hydrologic Unit Code 8-Digit (HUC8)")) %>%
  select(-1:-12, -globalid)
huc08sadd
saveRDS(huc08sadd, "./tests/testdata/huc08_nc.rds", compress = "xz")
```


### Vignettes 1

```{r vig1, eval = TRUE}
litr::add_vignettes("../tools/vignettes-sources/v00_good_practice_parallelization.Rmd")
```

### Vignettes 2

```{r vig2, eval = TRUE}
litr::add_vignettes("../tools/vignettes-sources/v01_generate_computational_grid.Rmd")
```


### Vignettes 3

```{r vig3, eval = FALSE}
litr::add_vignettes("../tools/vignettes-sources/v02_distribute_process.Rmd")
```


### Add data
```{r add-data}
prediction_grid <- readRDS("../tools/testdata/prediction_grid.rds")
usethis::use_data(prediction_grid, compress = "xz")
```

```{r doc-data}
#' Regular grid points in the mainland United States at 1km spatial resolution
#'
#' @format A data frame with 8,092,995 rows and three variables:
#' \describe{
#' \item{site_id}{Unique point identifier. Arbitrarily generated.}
#' \item{lon}{Longitude}
#' \item{lat}{Latitude}
#' }
#' @note Coordinates are in EPSG:5070 (Conus Albers Equal Area)
#' @source Mainland United States polygon was obtained from
#' the US Census Bureau.
#' @examples
#' data("prediction_grid", package = "chopin")
"prediction_grid"

```

# Now to the package itself

### Create functions


```{r testcheck, eval = FALSE, include = FALSE}

repan <- function(d, bw) return ((3/4) * (1 - ((d/bw)^2)))

bench::mark(
    repanRun = repan(300, 1000),
    # cepanRun = kernelCpp(300, 1000, "epanechnikov"),
    rrkrun = kernelfunction("epanechnikov", 300, 1000),
    iterations = 1000L
 
)

```
```{r, send_to = "R/processing.R"}
#' Kernel functions
#' @param kernel Kernel type. One of
#' `"uniform"`, `"quartic"`, `"triweight"`, and `"epanechnikov"`
#' @param d Distance
#' @param bw Bandwidth of a kernel
#' @references \href{https://github.com/JanCaha/SpatialKDE}{SpatialKDE source}
#' @examples
#' v_dist <- c(1, 10, 100, 25, 50, 0.1)
#' bw_dist1 <- 1
#' bw_dist2 <- 10
#' kernelfunction(v_dist, bw_dist1, "uniform")
#' kernelfunction(v_dist, bw_dist1, "quartic")
#' kernelfunction(v_dist, bw_dist1, "triweight")
#' kernelfunction(v_dist, bw_dist1, "epanechnikov")
#' kernelfunction(v_dist, bw_dist2, "uniform")
#' kernelfunction(v_dist, bw_dist2, "quartic")
#' kernelfunction(v_dist, bw_dist2, "triweight")
#' kernelfunction(v_dist, bw_dist2, "epanechnikov")
#' @export
kernelfunction <-
  function(
    d,
    bw,
    kernel = c("uniform", "quartic", "triweight", "epanechnikov")
  ) {
    kernel <- match.arg(kernel)
    switch(kernel,
      uniform = 1,
      quartic = (15 / 16) * (1 - (1 - ((d / bw)^2))^2),
      triweight = 1 - ((d / bw)^3),
      epanechnikov = (3 / 4) * (1 - (d / bw)^2)
    )

  }
```


```{r test-kernel-function, eval = FALSE}
testthat::test_that("Kernel functions work okay", {
  testthat::expect_error(kernelfunction(10, 100, "hyperbolic"))
  testthat::expect_no_error(kernelfunction(10, 100, "uniform"))
  testthat::expect_no_error(kernelfunction(10, 100, "quartic"))
  testthat::expect_no_error(kernelfunction(10, 100, "triweight"))
  testthat::expect_no_error(kernelfunction(10, 100, "epanechnikov"))
})

```


```{r, send_to = "R/check.R"}
#' @title Return the package the input object is based on
#' @description Detect whether the input object is sf or Spat* object.
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @returns A character object; one of 'terra' and 'sf'
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' check_packbound(nc_sf)
#' nc_vect <- terra::vect(nc_sf)
#' check_packbound(nc_vect)
#' ## END OF EXAMPLE
#' @export
check_packbound <- function(input) {
  if (!any(class(input) %in% c("sf", "stars", "SpatVector", "SpatRaster"))) {
    stop("Input should be one of sf or Spat* object.\n")
  }
  if (methods::is(input, "SpatVector") || methods::is(input, "SpatRaster")) {
    return("terra")
  }
  return("sf")
}


#' Return the data type
#' @description This function returns one of 'vector' or 'raster'
#' depending on the input class.
#' @param input Spat*/sf/stars object.
#' @note Although \code{stars} object is a little ambiguous
#' whether to classify vector or raster,
#' it will be considered raster in this package.
#' @author Insang Song
#' @returns character(1). One of 'vector' or 'raster'.
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' check_packbound(nc_sf)
#' nc_vect <- terra::vect(nc_sf)
#' check_packbound(nc_vect)
#' @importFrom methods is
#' @importFrom terra vect
#' @importFrom terra rast
#' @export
check_datatype <- function(input) {
  if (!any(class(input) %in% c("sf", "stars", "SpatVector", "SpatRaster"))) {
    stop("Input should be one of sf or Spat* object.\n")
  }
  if (any(methods::is(input, "SpatVector"), methods::is(input, "sf"))) {
    return("vector")
  }
  if (any(methods::is(input, "SpatRaster"), methods::is(input, "stars"))) {
    return("raster")
  }
}
```

```{r test-packbound, send_to = "tests/testthat/test-check.R"}
testthat::test_that("What package does the input object belong?",
  {
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))
    bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars <- stars::read_stars(bcsd_path)

    packbound_stars <- check_packbound(bcsd_stars)
    sprast_bcsd <- terra::rast(bcsd_path)
    packbound_terra <- check_packbound(sprast_bcsd)

    testthat::expect_equal(packbound_stars, "sf")
    testthat::expect_equal(packbound_terra, "terra")
  }
)


testthat::test_that("What package does the input object belong?",
  {
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))
    bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars <- stars::read_stars(bcsd_path)

    nc <- system.file(package = "sf", "shape/nc.shp")
    nc <- sf::read_sf(nc)

    datatype_stars <- check_datatype(bcsd_stars)
    datatype_sf <- check_datatype(nc)

    testthat::expect_equal(datatype_stars, "raster")
    testthat::expect_equal(datatype_sf, "vector")
  }
)
```

```{r, send_to = "R/preprocessing.R"}
#' @title Switch spatial data class
#' @description Convert class between `sf`/`stars`-`terra`
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @returns Data converted to the other package class
#' (if sf, terra; if terra, sf)
#' @examples
#' library(sf)
#' library(stars)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' ## generate a random raster
#' ras_rand <- terra::rast(nrow = 30, ncol = 30)
#' terra::values(ras_rand) <- runif(900)
#' stars_rand <- switch_packbound(ras_rand)
#' stars_rand
#' # should return stars object
#'
#' vec_rand <- terra::spatSample(ras_rand, size = 10L, as.points = TRUE)
#' sf_rand <- switch_packbound(vec_rand)
#' sf_rand
#' # should return sf object
#' @importFrom terra vect
#' @importFrom terra rast
#' @importFrom sf st_as_sf
#' @importFrom stars st_as_stars
#' @export
switch_packbound <- function(input) {
  if (!any(class(input) %in% c("sf", "stars", "SpatVector", "SpatRaster"))) {
    stop("Input should be one of sf or Spat* object.\n")
  }
  cls_input <- check_packbound(input)
  type_input <- check_datatype(input)

  switched <-
    switch(cls_input,
      sf = switch(type_input,
        vector = terra::vect(input),
        raster = terra::rast(input)
      ),
      terra = switch(type_input,
        vector = sf::st_as_sf(input),
        raster = stars::st_as_stars(input)
      )
    )

  return(switched)
}
```


```{r test-format, send_to = "tests/testthat/test-preprocessing.R"}

testthat::test_that("Format is well converted",
  {
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))

    # starts from sf/stars
    bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars <- stars::read_stars(bcsd_path)
    nc <- system.file(package = "sf", "shape/nc.shp")
    nc <- sf::read_sf(nc)

    stars_bcsd_tr <- switch_packbound(bcsd_stars)
    sf_nc_tr <- switch_packbound(nc)

    testthat::expect_equal(check_packbound(stars_bcsd_tr), "terra")
    testthat::expect_equal(check_packbound(sf_nc_tr), "terra")

    stars_bcsd_trb <- switch_packbound(stars_bcsd_tr)
    sf_nc_trb <- switch_packbound(sf_nc_tr)

    testthat::expect_equal(check_packbound(stars_bcsd_trb), "sf")
    testthat::expect_equal(check_packbound(sf_nc_trb), "sf")
  }
)


```

```{r, send_to = "R/check.R"}
#' @title check_crs_align: Check coordinate system then reproject
#' @description The input is checked whether its coordinate system is
#'  present. If not, it is reprojected to the CRS specified in
#' \code{crs_standard}.
#' @param input Input object one of sf or terra::Spat* object
#' @param crs_standard character(1). A standard definition of
#'  coordinate reference system. Default is "EPSG:4326"
#'  Consult [epsg.io](https://epsg.io) for details of other CRS.
#' @returns A (reprojected) sf or SpatVector object.
#' @author Insang Song
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' base_crs <- "OGC:CRS84"
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' check_crs_align(nc_sf, base_crs)
#'
#' nc_vect <- terra::vect(nc_sf)
#' check_crs_align(nc_vect, base_crs)
#' @importFrom sf st_crs
#' @importFrom sf st_transform
#' @importFrom terra crs
#' @importFrom terra project
#' @export
check_crs_align <-
  function(
    input,
    crs_standard = "EPSG:4326"
  ) {
    if (!grepl("[[:alpha:]]+{3,4}\\:[0-9]{4,7}", crs_standard)) {
      stop("crs_standard seems to be in invalid format.
        It should be '[authority]:[code]' format.
        Please refer to epsg.io and ?sf::st_crs or ?terra::crs.\n")
    }

    bound_package <- check_packbound(input)
    input_crs <- switch(
      bound_package,
      sf = sf::st_crs(input)$epsg,
      terra = terra::crs(input, describe = TRUE)$code
    )
    standard_crs <- switch(
      bound_package,
      sf = sf::st_crs(crs_standard)$epsg,
      terra = terra::crs(crs_standard, describe = TRUE)$code
    )
    if (input_crs == standard_crs) {
      return(input)
    }
    input_transformed <- switch(
      bound_package,
      sf = sf::st_transform(input, sf::st_crs(crs_standard)),
      terra = terra::project(x = input, y = crs_standard)
    )
    return(input_transformed)
}
```


```{r test-crs-align, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("CRS is transformed when it is not standard", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  nctr <- terra::vect(nc)
  terra::crs(nctr) <- "EPSG:5070"
  ncna <- nc
  sf::st_crs(ncna) <- NA
  ncnatr <- terra::vect(ncna)

  testthat::expect_error(check_crs_align(nc, 4326))
  testthat::expect_error(check_crs_align(ncna, crs_standard = "EPSG:4326"))
  testthat::expect_error(check_crs_align(ncnatr, "EPSG:4326"))

  testthat::expect_no_error(check_crs_align(nc, crs_standard = "EPSG:4326"))
  testthat::expect_no_error(check_crs_align(nc, crs_standard = "EPSG:5070"))
  testthat::expect_no_error(check_crs_align(nctr, crs_standard = "EPSG:4326"))
  testthat::expect_no_error(check_crs_align(nctr, crs_standard = "EPSG:5070"))

  nctr_align <- check_crs_align(nctr, "EPSG:4326")
  nc_align <- check_crs_align(nc, "EPSG:4326")

  testthat::expect_s3_class(nc_align, "sf")
  testthat::expect_s4_class(nctr_align, "SpatVector")

  nc_align_epsg <- sf::st_crs(nc_align)$epsg 
  nctr_align_epsg <- terra::crs(nctr_align, describe = TRUE)$code

  testthat::expect_equal(nc_align_epsg, 4326)
  testthat::expect_equal(nctr_align_epsg, "4326")

  terra::crs(ncnatr) <- NULL
  # error case
  testthat::expect_error(check_crs_align(ncnatr, "EPSG:4326"))

})

```


```{r, send_to = "R/check.R"}
#' Validate and repair input vector data
#' @description It tries repairing input vector data.
#' Vector validity violation usually appears in polygon data with
#' self-crossing or
#' hole orders. This function will pass the input_vector object to
#' sf::st_make_valid() (if input_vector is sf) or
#' terra::makeValid() (if input_vector is SpatVector).
#' May take some time depending on the geometry complexity.
#' @author Insang Song
#' @param input_vector One of sf or vect class. Target points of computation.
#' @returns A repaired sf or SpatVector object depending on
#' the class of input_vector.
#' @export
validate_and_repair_vectors <- function(input_vector) {
  detected <- check_packbound(input_vector)

  validated <- switch(detected,
    terra = terra::makeValid(input_vector),
    sf = sf::st_make_valid(input_vector)
  )

  return(validated)
}

```


```{r test-validate, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("vector validity check is cleared", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)

  testthat::expect_no_error(validate_and_repair_vectors(nc))

  nct <- terra::vect(nc)
  testthat::expect_no_error(validate_and_repair_vectors(nct))
})

```



```{r, send_to = "R/preprocessing.R"}
#' Setting the clipping extent
#' @description Return clipping extent with buffer radius.
#'  It assumes the input CRS is projected and linear unit is meters.
#' @author Insang Song
#' @param pnts One of sf or vect class. Target points of computation.
#' @param buffer_r numeric(1). Buffer radius. It is assumed to be in meters
#' @returns A terra::ext or sfc_POLYGON object of the computation extent.
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' set_clip_extent(nc_sf)
#' nc_vect <- terra::vect(nc_sf)
#' set_clip_extent(nc_vect)
#' @importFrom terra ext
#' @importFrom sf st_bbox
#' @importFrom sf st_as_sfc
#' @export
set_clip_extent <- function(
  pnts,
  buffer_r
  ) {
  detected <- check_packbound(pnts)
  if (detected == "terra") {
    ext_input <- terra::ext(pnts)
    # Note that `+` operation on
    # terra::ext output accounts for the operand as it is.
    ext_input <- ext_input + (1.1 * buffer_r)
  }
  if (detected == "sf") {
    ext_input <- sf::st_bbox(pnts)
    # Note that `+` operation on st_bbox output
    # simply adds the number; we add a vector here.
    ext_input <- ext_input + ((1.1 * c(-1, -1, 1, 1) * buffer_r))
    ext_input <- sf::st_as_sfc(ext_input)
  }
  return(ext_input)
}
```


```{r test-clip, send_to = "tests/testthat/test-preprocessing.R"}
testthat::test_that("Clip extent is set properly", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("shape/nc.shp", package = "sf")
  suppressWarnings({
    nc <- sf::read_sf(ncpath) |>
      sf::st_transform("EPSG:5070") |>
      sf::st_centroid()
  })

  radius <- 1e4L

  (nc_ext_sf <- set_clip_extent(nc, radius))

  nct <- terra::vect(nc)
  (nc_ext_terra <- set_clip_extent(nct, radius))

  (proper_xmin <- sf::st_bbox(nc)[1] - (1.1 * radius))

  testthat::expect_s3_class(nc_ext_sf, "sfc")
  testthat::expect_s4_class(nc_ext_terra, "SpatExtent")

  nc_ext_sf_1 <- sf::st_bbox(nc_ext_sf)[1]
  nc_ext_terra_1 <- nc_ext_terra[1]

  testthat::expect_equal(nc_ext_sf_1, proper_xmin)
  testthat::expect_equal(nc_ext_terra_1, proper_xmin)

})

```


```{r, send_to = "R/processing.R"}
#' Extent clipping
#' @description Clip input vector by
#'  the expected maximum extent of computation.
#' @author Insang Song
#' @param pnts `sf` or `SpatVector` object
#' @param buffer_r `numeric(1)`. Circular buffer radius.
#'  this value will be automatically multiplied by 1.1
#' @param target_input `sf` or `SpatVector` object to be clipped
#' @returns A clipped `sf` or `SpatVector` object.
#' @examples
#' library(sf)
#' library(stars)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
#' bcsd <- stars::read_stars(bcsd_path)
#' bcsd_rpnt <- sf::st_sample(bcsd, 4L)
#' bcsd_rpntm <- sf::st_sample(bcsd, 1000L)
#' clip_as_extent(bcsd_rpntm, 1000, bcsd_rpnt)
#' @importFrom sf st_intersection
#' @importFrom terra intersect
#' @export
clip_as_extent <- function(
  pnts,
  buffer_r,
  target_input
) {
  if (any(sapply(list(pnts, buffer_r, target_input), is.null))) {
    stop("One or more required arguments are NULL. Please check.\n")
  }
  detected_pnts <- check_packbound(pnts)
  detected_target <- check_packbound(target_input)

  if (detected_pnts != detected_target) {
    warning("Inputs are not the same class.\n")
    target_input <- switch_packbound(target_input)
  }

  ext_input <- set_clip_extent(pnts, buffer_r)
  cat("Clip target features with the input feature extent...\n")
  if (detected_pnts == "sf") {
    cae <- ext_input |>
      sf::st_intersection(x = target_input)
  }
  if (detected_pnts == "terra") {
    cae <- terra::intersect(target_input, ext_input)
  }

  return(cae)
}
```

```{r test-clip-extent-vector, eval = FALSE, send_to = "tests/testthat/test-processing.R"}
testthat::test_that("Vector inputs are clipped by clip_as_extent", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- testthat::test_path("..", "testdata", "nc_hierarchy.gpkg")
  nccnty <- terra::vect(
    ncpath, layer = "county",
    query = "SELECT * FROM county WHERE GEOID IN (37063, 37183)"
  )
  nctrct <- terra::vect(ncpath, layer = "tracts")

  ncp <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncpt <- terra::vect(ncp)

  ncpt <- ncpt[nccnty, ]

  # terra-terra
  testthat::expect_no_error(
    suppressWarnings(cl_terra <- clip_as_extent(
    pnts = ncpt, buffer_r = 3e4L, target_input = nctrct
  )))
  testthat::expect_s4_class(cl_terra, "SpatVector")
  
  # sf-sf
  ncp <- sf::st_as_sf(ncpt)
  nccntysf <- sf::st_as_sf(nccnty)
  nctrct <- sf::st_as_sf(nctrct)
  testthat::expect_no_error(
    suppressWarnings(cl_sf <- clip_as_extent(
    pnts = ncp, buffer_r = 3e4L, target_input = nctrct
  )))
  testthat::expect_s3_class(cl_sf, "sf")

  # sf-terra
  testthat::expect_no_error(
    suppressWarnings(clip_as_extent(
      pnts = ncpt, buffer_r = 3e4L,
      target_input = sf::st_as_sf(nctrct))
  ))

  testthat::expect_error(
    clip_as_extent(
      pnts = NULL, buffer_r = 3e4L, target_input = nctrct
  ))

})

```

```{r, send_to = "R/processing.R"}
#' @title clip_as_extent_ras: Clip input raster.
#' @description Clip input raster by the expected maximum extent of
#' computation.
#' @param pnts `sf` or `SpatVector` object
#' @param buffer_r numeric(1). buffer radius.
#' This value will be automatically multiplied by 1.25
#' @param ras `SpatRaster` object to be clipped
#' @param nqsegs `integer(1)`. the number of points per a quarter circle
#' @author Insang Song
#' @examples
#' library(terra)
#'
#' ras_rand <- terra::rast(nrow = 20, ncol = 20)
#' terra::values(ras_rand) <- runif(400L)
#' ras_rand_p <-
#'   data.frame(
#'     x = c(3, 5, 3.2, 8),
#'     y = c(12, 10, 15, 12),
#'     z = c(0, 1, 2, 3)
#'   )
#' ras_rand_p <- terra::vect(ras_rand_p, geom = c("x", "y"))
#' clip_as_extent_ras(ras_rand_p, 1.5, ras_rand)
#' @importFrom terra vect
#' @importFrom terra crop
#' @export
clip_as_extent_ras <- function(
  pnts = NULL,
  buffer_r = NULL,
  ras = NULL,
  nqsegs = 180L
) {
  if (any(sapply(list(pnts, buffer_r, ras), is.null))) {
    stop("Any of required arguments are NULL. Please check.\n")
  }
  ext_input <- set_clip_extent(pnts, buffer_r) |>
    terra::vect()

  cae <- terra::crop(ras, ext_input, snap = "out")
  return(cae)
}
```


```{r test-clip-extent, eval=F, send_to = "tests/testthat/test-processing.R"}
testthat::test_that("Clip by extent works without errors", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  ncelev <- terra::unwrap(readRDS("../testdata/nc_srtm15_otm.rds"))
  terra::crs(ncelev) <- "EPSG:5070"
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  ncp <- readRDS("../testdata/nc_random_point.rds")
  ncp_terra <- terra::vect(ncp)

  testthat::expect_no_error(clip_as_extent_ras(ncp, 30000L, ncelev))
  testthat::expect_no_error(clip_as_extent_ras(ncp_terra, 30000L, ncelev))
  testthat::expect_error(clip_as_extent_ras(ncp_terra, NULL, ncelev))
})



```

```{r, send_to = "R/preprocessing.R"}
#' Quick call for SpatRaster with a window
#' @param rasterpath character(1). Path to the raster file.
#' @param win Named integer vector (4) or terra::ext() results.
#' @returns SpatRaster object.
#' @author Insang Song
#' @examples
#' library(terra)
#' bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
#' ext_small <- terra::ext(
#'   c(xmin = -80, xmax = -76, ymin = 35, ymax = 36)
#' )
#' rast_short(bcsd_path, ext_small)
#' @importFrom methods is
#' @export
rast_short <- function(rasterpath = NULL, win = NULL) {
  if (!(all(is.numeric(win), !is.null(attr(win, "names")), length(win) == 4) ||
          methods::is(win, "SpatExtent"))) {
    stop(
      "Argument win should be one of named numeric vector or SpatExtent object.
      \n"
    )
  }
  if (
    all(
      is.numeric(win),
      !all(grepl("(xmax|xmin|ymax|ymin)", names(win))) || is.null(names(win))
    )
  ) {
    stop(
      "Numeric win without names is detected.
Set valid names for all win elements.\n"
    )
  }
  invisible(terra::rast(rasterpath, win = win))
}

```


```{r test-rasterbound, send_to = "tests/testthat/test-preprocessing.R"}
testthat::test_that("Raster is read properly with a window.", {
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")

  ext_numeric <- c(-84, -82, 34, 36) # unnamed
  testthat::expect_error(rast_short(bcsd_path, ext_numeric[1:3]))
  testthat::expect_error(rast_short(bcsd_path, ext_numeric))

  names(ext_numeric) <- c("xmin", "xmax", "ymin", "ymax")
  rastshort_num <- rast_short(bcsd_path, ext_numeric)
  testthat::expect_s4_class(rastshort_num, "SpatRaster")

  ext_terra <- terra::ext(ext_numeric)
  rastshort_terra <- rast_short(bcsd_path, ext_terra)
  testthat::expect_s4_class(rastshort_terra, "SpatRaster")

})


```


```{r}
#' Estimate computational demands from inputs (to be written)
#' @param inputs character vector of file paths
#' @param nx integer(1).
#' @param ny integer(1).
#' @param padding numeric(1). Extrusion factor
#' @author Insang Song
#' @export
estimate_demands <- function(
  inputs,
  nx, ny,
  padding
) {
  ## cpu
  ## memory
  ## estimate maximum coverage
  ## clipped data size
  ## total distributed memory
  ## return a list of total demands
  ## print summary of results
}

```


```{r, send_to = "R/gridding.R"}
#' Get a set of computational regions
#' @param input sf or Spat* object.
#' @param mode character(1). Mode of region construction.
#'  One of "grid" (simple grid regardless of
#'  the number of features in each grid),
#'  "density" (clustering-based varying grids),
#'  "grid_advanced" (merging adjacent grids with
#'  smaller number of features than grid_min_features). 
#' @param nx integer(1). The number of grids along x-axis.
#' @param ny integer(1). The number of grids along y-axis.
#' @param grid_min_features integer(1). A threshold to merging adjacent grids
#' @param padding numeric(1). A extrusion factor to make buffer to
#'  clip actual datasets. Depending on the length unit of the CRS of input.
#' @param unit character(1). The length unit for padding (optional).
#'  units::set_units is used for padding when sf object is used.
#'  See [units package vignette (web)](https://cran.r-project.org/web/packages/units/vignettes/measurement_units_in_R.html)
#'  for the list of acceptable unit forms.
#' @param ... arguments passed to the internal function
#' @return A list of two,
#'   \code{original}: exhaustive and non-overlapping
#'  grid polygons in the class of input
#'   \code{padded}: a square buffer of each polygon in
#'  \code{original}. Used for computation.
#' @description Using input points, the bounding box is split to
#'  the predefined numbers of columns and rows.
#'  Each grid will be buffered by the radius.
#' @author Insang Song
#' @examples
#' # data
#' library(sf)
#' ncpath <- system.file("shape/nc.shp", package = "sf")
#' nc <- read_sf(ncpath)
#' nc <- st_transform(nc, "EPSG:5070")
#' # run
#' nc_comp_region <- get_computational_regions(nc, nx = 12, ny = 8)
#' par(mfcol = c(1, 2))
#' plot(nc_comp_region$original)
#' plot(nc_comp_region$padded)
#' @export
get_computational_regions <-
  function(
      input,
      mode = c("grid", "grid_advanced", "density"),
      nx = 10L,
      ny = 10L,
      grid_min_features = 30L,
      padding = NULL,
      unit = NULL,
      ...) {
    mode <- match.arg(mode)

    if (!all(
      is.integer(nx),
      is.integer(ny),
      is.integer(grid_min_features)
    )
    ) {
      stop("nx, ny, and grid_min_features must be integer.\n")
    }
    if (!is.numeric(padding)) {
      message("padding should be numeric.
We try converting padding to numeric...\n")
      padding <- try(as.numeric(padding))
      if (inherits(padding, "try-error")) {
        stop("padding is not convertible to numeric.\n")
      }
    }

    # valid unit compatible with units::set_units?
    grid_reg <-
      switch(mode,
        grid = sp_index_grid(points_in = input, ncutsx = nx, ncutsy = ny),
        grid_advanced = grid_merge(
                                   points_in = input,
                                   sp_index_grid(input, nx, ny),
                                   grid_min_features = grid_min_features),
        density = simpleError("density method is under development.\n")
      )

    type_grid_reg <- check_packbound(grid_reg)
    grid_reg_pad <-
      switch(type_grid_reg,
             sf =
             sf::st_buffer(grid_reg,
                           dist = padding,
                           endCapStyle = "SQUARE",
                           joinStyle = "MITRE"),
             terra =
             terra::buffer(grid_reg,
                           width = padding,
                           capstyle = "square",
                           joinstyle = "mitre"))
    grid_results <-
      list(original = grid_reg,
           padded = grid_reg_pad)
    return(grid_results)

  }

#' @title sp_index_grid: Generate grid polygons
#' @description Returns a sf object that includes x- and y- index
#'  by using two inputs ncutsx and ncutsy, which are x- and
#'  y-directional splits, respectively.
#' @param points_in sf or SpatVector object. Target points of computation.
#' @param ncutsx integer(1). The number of splits along x-axis.
#' @param ncutsy integer(1). The number of splits along y-axis.
#' @returns A sf or SpatVector object of computation grids with
#'  unique grid id (CGRIDID).
#' @author Insang Song
#' @importFrom terra rast
#' @importFrom terra as.polygons
#' @importFrom sf st_as_sf
#' @importFrom sf st_make_grid
#' @export
sp_index_grid <-
  function(
    points_in,
    ncutsx,
    ncutsy
  ) {
    package_detected <- check_packbound(points_in)

    grid_out <-
      switch(package_detected,
        sf = sf::st_make_grid(points_in, n = c(ncutsx, ncutsy)) |>
          as.data.frame() |>
          sf::st_as_sf(),
        terra = terra::rast(points_in, nrows = ncutsy, ncols = ncutsx) |>
          terra::as.polygons()
      )
    # grid select
    grid_out <- grid_out[points_in, ]

    grid_out$CGRIDID <- seq(1, nrow(x = grid_out))
    return(grid_out)
}


#' @title grid_merge: Merge grid polygons with given rules
#' @description Merge boundary-sharing (in "Rook" contiguity) grids with
#'  fewer target features than the threshold.
#'  This function strongly assumes that the input
#'  is returned from the sp_index_grid,
#'  which has 'CGRIDID' as the unique id field.
#' @author Insang Song
#' @param points_in sf or SpatVector object. Target points of computation.
#' @param grid_in sf or SpatVector object. The grid generated by sp_index_grid
#' @param grid_min_features integer(1). Threshold to merge adjacent grids.
#' @return A sf or SpatVector object of computation grids.
#' @examples
#' # library(sf)
#' # library(igraph)
#' # ligrary(dplyr)
#' # dg <- sf::st_as_sfc(st_bbox(c(xmin = 0, ymin = 0, xmax = 8e5, ymax = 6e5)))
#' # sf::st_crs(dg) <- 5070
#' # dgs <- sf::st_as_sf(st_make_grid(dg, n = c(20, 15)))
#' # dgs$CGRIDID <- seq(1, nrow(dgs))
#' #
#' # dg_sample <- st_sample(dg, kappa = 5e-9, mu = 15,
#' # scale = 20000, type = "Thomas")
#' # sf::st_crs(dg_sample) <- sf::st_crs(dg)
#' # dg_merged <- grid_merge(sf::st_as_sf(sss), dgs, 100)
#'
#' #### NOT RUN ####
#' @importFrom dplyr group_by
#' @importFrom dplyr summarize
#' @importFrom dplyr ungroup
#' @importFrom dplyr n
#' @importFrom sf st_relate
#' @importFrom sf st_length
#' @importFrom sf st_cast
#' @importFrom rlang sym
#' @export
grid_merge <- function(points_in, grid_in, grid_min_features) {
  package_detected <- check_packbound(points_in)
  if (package_detected == "terra") {
    points_in <- sf::st_as_sf(points_in)
    grid_in <- sf::st_as_sf(grid_in)
  }

  n_points_in_grid <- lengths(sf::st_intersects(grid_in, points_in))
  grid_self <- sf::st_relate(grid_in, grid_in, pattern = "2********")
  grid_rook <- sf::st_relate(grid_in, grid_in, pattern = "F***1****")
  grid_rooks <- mapply(c, grid_self, grid_rook, SIMPLIFY = FALSE)
  grid_lt_threshold <- (n_points_in_grid < grid_min_features)

  # does the number of points per grid exceed minimum threshold?
  if (sum(grid_lt_threshold) < 2) {
    stop("Threshold is too low. Please try higher threshold.\n")
  }
  grid_lt_threshold <- seq(1, nrow(grid_in))[grid_lt_threshold]

  # This part does not work as expected.
  # Should investigate edge list and actual row index of the grid object; 
  identified <- lapply(grid_rooks,
                       function(x) sort(x[which(x %in% grid_lt_threshold)]))
  identified <- identified[grid_lt_threshold]
  identified <- unique(identified)
  identified <- identified[sapply(identified, length) > 1]

  identified_graph <-
    lapply(identified, function(x) t(utils::combn(x, 2))) |>
    Reduce(f = rbind, x = _) |>
    unique() |>
    apply(X = _, 2, as.character) |>
    igraph::graph_from_edgelist(el = _, directed = 0) |>
    igraph::mst() |>
    igraph::components()

  identified_graph_member <- identified_graph$membership

  merge_idx <- as.integer(names(identified_graph_member))
  merge_member <- split(merge_idx, identified_graph_member)
  merge_member_label <-
    unlist(lapply(merge_member, function(x) paste(x, collapse = "_")))
  merge_member_label <- merge_member_label[identified_graph_member]

  # sf object manipulation
  grid_out <- grid_in
  grid_out[["CGRIDID"]][merge_idx] <- merge_member_label

  grid_out <- grid_out |>
    dplyr::group_by(!!rlang::sym("CGRIDID")) |>
    dplyr::summarize(n_merged = dplyr::n()) |>
    dplyr::ungroup()

  ## polsby-popper test for shape compactness
  grid_merged <- grid_out[which(grid_out$n_merged > 1),]
  grid_merged_area <- as.numeric(sf::st_area(grid_merged))
  grid_merged_perimeter <-
    as.numeric(sf::st_length(sf::st_cast(grid_merged, "LINESTRING")))
  grid_merged_pptest <-
    (4 * pi * grid_merged_area) / (grid_merged_perimeter ^ 2)

  # pptest value is bounded [0,1];
  # 0.3 threshold is groundless at this moment,
  # possibly will make it defined by users.
  if (max(unique(identified_graph_member)) > floor(0.1 * nrow(grid_in)) ||
        any(grid_merged_pptest < 0.3)) {
    message("The reduced computational regions have too complex shapes.
     Consider increasing thresholds or using the original grids.\n")
  }

  return(grid_out)

}



```

```{r grid-internal, include = F, eval = F}
    sp_index_grid_sf <- function(points_in, ncutsx, ncutsy) {
      grid1 <- sf::st_make_grid(points_in, n = c(ncutsx, ncutsy)) |>
        as.data.frame() |>
        sf::st_as_sf()
      grid1 <- grid1[points_in, ]
      return(grid1)
    }
    sp_index_grid_terra <- function(points_in, ncutsx, ncutsy) {
      grid1 <- terra::rast(points_in, nrows = ncutsy, ncols = ncutsx)
      grid1 <- terra::as.polygons(grid1)
      grid1 <- grid1[points_in, ]
      return(grid1)
    }
```

```{r test-compregion, send_to = "tests/testthat/test-gridding.R"}
testthat::test_that("Grid split is well done.", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")

  testthat::expect_no_error(
    get_computational_regions(nc, mode = "grid", padding = 3e4L)
  )
  ncgrid <- get_computational_regions(nc, mode = "grid", padding = 3e4L)
  testthat::expect_s3_class(ncgrid$original, "sf")

  nctr <- terra::vect(nc)
  testthat::expect_no_error(
    get_computational_regions(nctr, mode = "grid", padding = 3e4L)
  )
  ncgridtr <- get_computational_regions(nctr, mode = "grid", padding = 3e4L)
  testthat::expect_s4_class(ncgridtr$original, "SpatVector")

})

```

```{r test-gridmerge, eval=FALSE, send_to = "tests/testthat/test-gridding.R"}
testthat::test_that("Grid merge is well done.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("igraph")
  withr::local_package("dplyr")
  withr::local_options(list(sf_use_s2 = FALSE))
  withr::local_seed(20231121)

  nc <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  nctr <- terra::vect(nc)
  ncp <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncrp <- sf::st_as_sf(sf::st_sample(nc, 1000L))

  gridded <-
    get_computational_regions(ncrp,
                              mode = "grid",
                              nx = 8L, ny = 5L,
                              padding = 1e4L)
  # suppress warnings for "all sub-geometries for which ..."
  testthat::expect_warning(grid_merge(ncrp, gridded$original, 25L))

  ncptr <- terra::vect(ncrp)
  griddedtr <-
    get_computational_regions(ncptr,
                              mode = "grid",
                              nx = 8L, ny = 5L,
                              padding = 1e4L)
  testthat::expect_warning(grid_merge(ncptr, griddedtr$original, 25L))

})

```


```{r, send_to = "R/check.R"}
#' Generate a rectangular polygon from extent
#' @param extent input extent.
#'  A numeric vector with xmin/xmax/ymin/ymax,
#'  sf::st_bbox() or terra::ext() outputs.
#' @param output_class character(1).
#'  Class of the output polygon. One of "sf" or "terra"
#' @param crs character(1). Coordinate reference system definition.
#' @returns `sf` or `SpatVector` object of a rectangular polygon.
#' @author Insang Song
#' @examples
#' library(sf)
#' library(terra)
#' numext1 <- c(-100, -70, 30, 40)
#' names(numext1) <- c("xmin", "xmax", "ymin", "ymax")
#' extent_to_polygon(numext1, "sf")
#' extent_to_polygon(numext1, "terra")
#' @importFrom sf st_as_sf
#' @importFrom sf st_bbox
#' @importFrom sf st_set_crs
#' @importFrom terra vect
#' @importFrom terra ext
#' @importFrom terra set.crs
#' @export
extent_to_polygon <- function(
    extent = NULL,
    output_class = c("sf", "terra"),
    crs = "EPSG:4326") {
  output_class <- match.arg(output_class)
  if (methods::is(extent, "numeric")) {
    if (is.null(attr(extent, "names"))) {
      stop("Your extent is an unnamed numeric vector.
Please define names xmin/xmax/ymin/ymax explicitly.\n")
    }
    extent <- switch(
      output_class,
      sf = sf::st_bbox(extent),
      terra = terra::ext(extent)
    )
  }

  extent_polygon <- switch(
    output_class,
    sf = sf::st_as_sf(sf::st_as_sfc(extent)),
    terra = terra::vect(extent)
  )

  extent_polygon <- switch(
    output_class,
    sf = sf::st_set_crs(extent_polygon, sf::st_crs(crs)),
    terra = terra::set.crs(extent_polygon, terra::crs(crs))
  )

  return(extent_polygon)

}

```

```{r test-extentpoly, send_to = "tests/testthat/test-check.R"}
testthat::test_that("input extent is converted to a polygon", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  mainland_vec <- c(xmin = -128, xmax = -62, ymin = 25, ymax = 52)
  mainland_box <- extent_to_polygon(mainland_vec, output_class = "sf")
  mainland_box_t <- extent_to_polygon(mainland_vec, output_class = "terra")
  mainland_vec_un <- unname(mainland_vec)

  testthat::expect_s3_class(mainland_box, "sf")
  # terra Spat* objects are s4 class...
  testthat::expect_s4_class(mainland_box_t, "SpatVector")
  # error cases
  testthat::expect_error(
    extent_to_polygon(mainland_vec_un, output_class = "sf")
  )
  testthat::expect_error(
    extent_to_polygon(mainland_vec_un, output_class = "GeoDataFrames")
  )
})

```



```{r, send_to = "R/check.R"}
#' Check if the data extent is inside the reference bounding box
#' @description One of the most common errors in spatial computation is rooted
#' in the entirely or partly incomparable spatial extents of input datasets.
#' This function returns whether your data is inside the target computational
#' extent.
#' It is assumed that you know and have the exact computational region.
#' This function will return `TRUE` if the reference region
#' completely contains your data's extent and `FALSE` otherwise.
#' @param data_query sf*/stars/SpatVector/SpatRaster object.
#' @param reference sf*/stars/SpatVector/SpatRaster object
#' @returns logical(1). `TRUE` (the queried data extent is completely within
#'  the reference bounding box) or `FALSE`
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' library(sf)
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- sf::st_read(ncpath)
#' nc <- sf::st_transform("EPSG:4326")
#'
#' refextnum <- c(-100, -60, 20, 40)
#' names(refextnum) <- c("xmin", "xmax", "ymin", "ymax")
#' refext <- extent_to_polygon(refextnum)
#' check_bbox(nc, refext)
#' @importFrom sf st_as_sfc
#' @importFrom sf st_crs
#' @importFrom sf st_bbox
#' @importFrom sf st_transform
#' @importFrom sf st_within
#' @export
check_bbox <- function(
  data_query = NULL,
  reference = NULL
) {
  reference <- sf::st_as_sfc(sf::st_bbox(reference))
  print(sf::st_crs(reference))

  data_query_bb <-
    sf::st_as_sfc(sf::st_bbox(data_query),
                  crs = sf::st_crs(data_query))
  print(sf::st_crs(data_query_bb))
  query_matched <- sf::st_transform(data_query_bb, sf::st_crs(reference))
  check_result <- as.logical(unlist(sf::st_within(query_matched, reference)))
  return(check_result)
}


```

```{r test-bbox, eval=FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("Check bbox abides.", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  ncp <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")

  testthat::expect_no_error(check_bbox(ncp, nc))
  res <- check_bbox(ncp, nc)
  testthat::expect_equal(res, TRUE)

  # error cases
  testthat::expect_no_error(check_bbox(ncp, sf::st_bbox(nc)))
})

```


```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with points and a buffer radius
#' @description For simplicity, it is assumed that the coordinate systems of
#'  the points and the raster are the same.
#' @param points `sf`/`SpatVector` object.
#' Coordinates where buffers will be generated.
#' @param surf `SpatRaster` object.
#'  A raster at which summary will be calculated
#' @param radius numeric(1). Buffer radius. here we assume circular buffers only
#' @param id character(1). Unique identifier of each point.
#' @param qsegs integer(1). Number of vertices at a quarter of a circle.
#'  Default is 90L.
#' @param func a function taking a numeric vector argument.
#' @param kernel character(1). Name of a kernel function
#' One of `"uniform"`, `"triweight"`, `"quartic"`, and `"epanechnikov"`
#' @param bandwidth numeric(1). Kernel bandwidth.
#' @returns a data.frame object with mean value
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' library(terra)
#' rrast <- terra::rast(nrow = 100, ncol = 100)
#' terra::crs(rrast) <- ""
#' terra::values(rrast) <- rgamma(1e4, 4, 2)
#' rpnt <- terra::spatSample(rrast, 100L, as.points = TRUE)
#' rpnt$pid <- sprintf("id_%03d", seq(1, 100))
#' extract_with_buffer(rpnt, rrast, 4, "pid")
#' @importFrom exactextractr exact_extract
#' @importFrom methods is
#' @importFrom terra ext
#' @importFrom terra crop
#' @importFrom terra buffer
#' @importFrom dplyr group_by
#' @importFrom dplyr summarize
#' @importFrom dplyr all_of
#' @importFrom dplyr across
#' @importFrom dplyr ungroup
#' @export
extract_with_buffer <- function(
  points = NULL,
  surf = NULL,
  radius = NULL,
  id = NULL,
  qsegs = 90L,
  func = "mean",
  kernel = NULL,
  bandwidth = NULL
) {
  # type check
  if (!methods::is(points, "SpatVector")) {
    if (!methods::is(points, "sf")) {
      stop("Check class of the input points.\n")
    }
    points <- terra::vect(points)
  }
  if (!is.numeric(radius)) {
    stop("Check class of the input radius.\n")
  }
  if (!is.character(id)) {
    stop("id should be a character.\n")
  }
  if (!is.numeric(qsegs)) {
    stop("qsegs should be numeric.\n")
  }

  if (!is.null(kernel)) {
    extracted <-
      extract_with_buffer_kernel(points = points,
                                 surf = surf,
                                 radius = radius,
                                 id = id,
                                 func = func,
                                 qsegs = qsegs,
                                 kernel = kernel,
                                 bandwidth = bandwidth)
    return(extracted)
  }

  extracted <-
    extract_with_buffer_flat(points = points,
                             surf = surf,
                             radius = radius,
                             id = id,
                             func = func,
                             qsegs = qsegs)
  return(extracted)

}

# Subfunction: extract with buffers (flat weight; simple mean)
#' @rdname extract_with_buffer
#' @export
extract_with_buffer_flat <- function(
  points = NULL,
  surf = NULL,
  radius = NULL,
  id = NULL,
  qsegs = NULL,
  func = "mean",
  kernel = NULL,
  bandwidth = NULL
) {
  # generate buffers
  bufs <- terra::buffer(points, width = radius, quadsegs = qsegs)
  bufs <- reproject_b2r(bufs, surf)
  # crop raster
  bufs_extent <- terra::ext(bufs)
  surf_cropped <- terra::crop(surf, bufs_extent, snap = "out")

  # extract raster values
  surf_at_bufs <-
    exactextractr::exact_extract(
      x = surf_cropped,
      y = sf::st_as_sf(bufs),
      fun = func,
      force_df = TRUE,
      append_cols = id,
      progress = FALSE,
      max_cells_in_memory = 5e07
    )
  surf_at_bufs_summary <-
    surf_at_bufs

  return(surf_at_bufs_summary)
}


# Subfunction: extract with buffers (kernel weight; weighted mean)
#' @rdname extract_with_buffer
#' @export
extract_with_buffer_kernel <- function(
  points = NULL,
  surf = NULL,
  radius = NULL,
  id = NULL,
  qsegs = NULL,
  func = stats::weighted.mean,
  kernel = NULL,
  bandwidth = NULL
) {
  # generate buffers
  bufs <- terra::buffer(points, width = radius, quadsegs = qsegs)
  bufs <- reproject_b2r(bufs, surf)

  # crop raster
  bufs_extent <- terra::ext(bufs)
  surf_cropped <- terra::crop(surf, bufs_extent, snap = "out")
  name_surf_val <-
    ifelse(terra::nlyr(surf_cropped) == 1,
           "value", names(surf_cropped))

  coords_df <- as.data.frame(points, geom = "XY")
  coords_df <-
    coords_df[, grep(sprintf("^(%s|%s|%s)", id, "x", "y"), names(coords_df))]
  names(coords_df)[grep("(x|y)", names(coords_df))] <- c("xorig", "yorig")
  xorig <- yorig <- NULL
  x <- y <- NULL
  pairdist <- NULL
  w_kernel <- NULL
  # extract raster values
  surf_at_bufs <-
    exactextractr::exact_extract(
      x = surf_cropped,
      y = sf::st_as_sf(bufs),
      force_df = TRUE,
      include_cols = id,
      progress = FALSE,
      include_area = TRUE,
      include_xy = TRUE,
      max_cells_in_memory = 5e07
    )
  surf_at_bufs <- do.call(rbind, surf_at_bufs)
  surf_at_bufs_summary <-
    surf_at_bufs |>
    dplyr::left_join(coords_df, by = id) |>
    dplyr::mutate(
      pairdist = terra::distance(
        x = cbind(xorig, yorig),
        y = cbind(x, y),
        pairwise = TRUE,
        lonlat = terra::is.lonlat(points)
      ),
      w_kernel = kernelfunction(pairdist, bandwidth, kernel),
      w_kernelarea = w_kernel * coverage_fraction
    ) |>
    dplyr::group_by(!!rlang::sym(id)) |>
    dplyr::summarize(
      dplyr::across(dplyr::all_of(name_surf_val), ~func(., w = w_kernelarea))
    ) |>
    dplyr::ungroup()
  colnames(surf_at_bufs_summary)[1] <- id
  return(surf_at_bufs_summary)
}

```

```{r, eval = FALSE, include = FALSE}
  # starts from sf/stars
  ncp <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncp <- terra::vect(ncp)
  nccnty <- system.file("shape/nc.shp", package = "sf")
  nccnty <- sf::st_read(nccnty)
  nccnty <- sf::st_transform(nccnty, "EPSG:5070")
  nccntytr <- terra::vect(nccnty)
  ncelev <- readRDS(testthat::test_path("..", "testdata", "nc_srtm15_otm.rds"))
  ncelev <- terra::unwrap(ncelev)

kk <-
  extract_with_buffer_kernel(ncp, ncelev, 3000L, "pid", 90L, kernel = "epanechnikov", bandwidth = 4000L)
head(kk)


library(terra)
rrast <- terra::rast(nrow = 100, ncol = 100)
 terra::values(rrast) <- rgamma(1e4, 4, 2)
 rpnt <- terra::spatSample(rrast, 100L, as.points = TRUE)
 rpnt$pid <- sprintf("id_%03d", seq(1, 100))
 extract_with_buffer(rpnt, rrast, 4, "pid")


library(terra)
ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
nc <- terra::vect(ncpath)
nc <- terra::project(nc, "EPSG:5070")
rrast <- terra::rast(nc, nrow = 100, ncol = 220)
ncr <- terra::rasterize(nc, rrast)
terra::values(rrast) <- rgamma(2.2e4, 4, 2)
rpnt <- terra::spatSample(rrast, 16L, as.points = TRUE)
rpnt$pid <- sprintf("ID-%02d", seq(1, 16))
rpoly <- terra::buffer(rpnt, 5, capstyle = "square", joinstyle = "bevel")
extract_with_polygons(rpoly, rrast, "pid")


library(terra)

rrast <- terra::rast(nrow = 100, ncol = 100)
terra::values(rrast) <- rgamma(1e4, 4, 2)
terra::crs(rrast) <- ""
rpnt <- terra::spatSample(rrast, 16L, as.points = TRUE)
rpnt$pid <- rep(sprintf("ID-%d", seq(1, 4)), each = 4)
rpoly <- terra::aggregate(rpnt, "pid")
extract_with_polygons(rpoly, rrast, "pid")


```

```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with generic polygons
#' @description For simplicity, it is assumed that the coordinate systems of
#'  the points and the raster are the same.
#'  Kernel function is not yet implemented.
#' @param polys `sf`/`SpatVector` object. Polygons.
#' @param surf `SpatRaster` object.
#'  A raster from which a summary will be calculated
#' @param id character(1). Unique identifier of each point.
#' @param func a generic function name in string or
#'  a function taking two arguments that are
#'  compatible with \code{\link[exactextractr]{exact_extract}}.
#'  For example, `"mean"` or `\(x, w) weighted.mean(x, w, na.rm = TRUE)`
#' @returns a data.frame object with function value
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- terra::vect(ncpath)
#' nc <- terra::project(nc, "EPSG:5070")
#' rrast <- terra::rast(nc, nrow = 100, ncol = 220)
#' ncr <- terra::rasterize(nc, rrast)
#' terra::values(rrast) <- rgamma(2.2e4, 4, 2)
#' rpnt <- terra::spatSample(rrast, 16L, as.points = TRUE)
#' rpnt$pid <- sprintf("ID-%02d", seq(1, 16))
#' rpoly <-
#'   terra::buffer(rpnt, 5, capstyle = "square", joinstyle = "bevel")
#' extract_with_polygons(rpoly, rrast, "pid")
#' @importFrom methods is
#' @importFrom rlang sym
#' @importFrom dplyr across
#' @importFrom exactextractr exact_extract
#' @export
extract_with_polygons <- function(
  polys = NULL,
  surf = NULL,
  id = NULL,
  func = "mean"
) {
  # type check
  if (!methods::is(polys, "SpatVector")) {
    if (!methods::is(polys, "sf")) {
      stop("Check class of the input points.\n")
    }
    polys <- terra::vect(polys)
  }
  if (!methods::is(surf, "SpatRaster")) {
    stop("Check class of the input raster.\n")
  }
  if (!is.character(id)) {
    stop("id should be a character.\n")
  }

  cls_polys <- check_packbound(polys)
  cls_surf <- check_packbound(surf)

  if (cls_polys != cls_surf) {
    polys <- switch_packbound(polys)
  }

  polys <- reproject_b2r(polys, surf)

  extracted_poly <-
    exactextractr::exact_extract(
      x = surf,
      y = sf::st_as_sf(polys),
      fun = func,
      force_df = TRUE,
      append_cols = id,
      progress = FALSE,
      max_cells_in_memory = 5e07
    )
  return(extracted_poly)
}

```

```{r, send_to = "R/processing.R"}
#' Extract raster values with point buffers or polygons
#' @param vector `sf`/`SpatVector` object.
#' @param raster `SpatRaster` object.
#' @param id character(1). Unique identifier of each point.
#' @param func function taking one numeric vector argument.
#' @param mode one of `"polygon"`
#'  (generic polygons to extract raster values with) or
#'  `"buffer"` (point with buffer radius)
#' @param ... various. Passed to extract_with_buffer.
#'  See \code{?extract_with_buffer} for details.
#' @returns A data.frame object with summarized raster values with
#'  respect to the mode (polygon or buffer) and the function.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' ## See ?extract_with_polygons and ?extract_with_buffers
#' @export
extract_with <- function(
  vector = NULL,
  raster = NULL,
  id = NULL,
  func = "mean",
  mode = c("polygon", "buffer"),
  ...
) {

  mode <- match.arg(mode)

  stopifnot(is.character(id))
  stopifnot(id %in% names(vector))

  extracted <-
    switch(mode,
      polygon =
      extract_with_polygons(
        polys = vector,
        surf = raster,
        id = id,
        func = func,
        ...
      ),
      buffer =
      extract_with_buffer(
        points = vector,
        surf = raster,
        id = id,
        func = func,
        ...
      )
    )
  return(extracted)
}

#' @title Reproject vectors to raster's CRS
#' @param vector `sf`/`stars`/`SpatVector`/`SpatRaster` object
#' @param raster `SpatRaster` object
#' @returns Reprojected object in the same class as \code{vector}
#' @author Insang Song
#' @examples
#' # NOT TO RUN
#' @importFrom sf st_transform
#' @importFrom terra project
#' @importFrom terra crs
#' @export
reproject_b2r <-
  function(vector,
           raster) {
    detected_vec <- check_packbound(vector)
    switch(detected_vec,
           sf = sf::st_transform(vector, terra::crs(raster)),
           terra = terra::project(vector, terra::crs(raster)))
  }

```


```{r test-extractwith, eval=FALSE, send_to = "tests/testthat/test-processing.R"}
testthat::test_that("extract_with runs well", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_package("dplyr")
  withr::local_package("rlang")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  ncp <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncp <- terra::vect(ncp)
  nccnty <- system.file("shape/nc.shp", package = "sf")
  nccnty <- sf::st_read(nccnty)
  nccnty <- sf::st_transform(nccnty, "EPSG:5070")
  nccntytr <- terra::vect(nccnty)
  ncelev <- readRDS(testthat::test_path("..", "testdata", "nc_srtm15_otm.rds"))
  ncelev <- terra::unwrap(ncelev)

  nccnty4326 <- sf::st_transform(nccnty, "EPSG:4326")
  testthat::expect_no_error(reproject_b2r(nccnty4326, ncelev))

  # test two modes
  testthat::expect_no_error(
    ncexpoly <- extract_with(
                             nccntytr,
                             ncelev,
                             "FIPS",
                             mode = "polygon")
  )
  testthat::expect_no_error(
    ncexbuff <- extract_with(ncp,
                             ncelev,
                             "pid",
                             mode = "buffer",
                             radius = 1e4L)
  )

  testthat::expect_no_error(
    ncexbuffkern <- extract_with_buffer(ncp,
                             ncelev,
                             "pid",
                             kernel = "epanechnikov",
                             func = stats::weighted.mean,
                             bandwidth = 1.25e4L,
                             radius = 1e4L)
  )

  testthat::expect_no_error(
    ncexbuffkern <- extract_with(ncp,
                             ncelev,
                             "pid",
                             mode = "buffer",
                             kernel = "epanechnikov",
                             func = stats::weighted.mean,
                             bandwidth = 1.25e4L,
                             radius = 1e4L)
  )


  # errors
  testthat::expect_error(
    extract_with(nccntytr,
                 ncelev,
                 "GEOID",
                 mode = "whatnot")
  )
  testthat::expect_error(
    extract_with(nccntytr,
                 ncelev,
                 "GEOID",
                 mode = "polygon")
  )
  testthat::expect_error(
    extract_with(nccntytr,
                 ncelev,
                 1,
                 mode = "buffer",
                 radius = 1e4L)
  )
  testthat::expect_error(
    extract_with(as.list(ncp),
                 ncelev,
                 "GEOID",
                 mode = "buffer",
                 radius = 1e4L)
  )
  testthat::expect_error(
    extract_with(sf::st_as_sf(ncp),
                 ncelev,
                 "GEOID",
                 mode = "buffer",
                 radius = 1e4L)
  )
  testthat::expect_error(
    extract_with(sf::st_as_sf(ncp),
                 ncelev,
                 1,
                 mode = "buffer",
                 radius = "Ibidem")
  )
  testthat::expect_error(
    extract_with_buffer(ncp,
                        ncelev,
                        "pid",
                        kernel = "epanechnikov",
                        func = stats::weighted.mean,
                        bandwidth = 1.25e4L,
                        radius = 1e4L,
                        qsegs = 3 + 2i)
  )

})


```


```{r, send_to = "R/check.R"}
#' Check Coordinate Reference System
#' @param x `sf`/`stars`/`SpatVector`/`SpatRaster` object.
#' @return A st_crs or crs object.
#' @description It returns st_crs object from `sf`/Spat* objects.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' # data
#' library(sf)
#' ncpath = system.file("shape/nc.shp", package = "sf")
#' nc = read_sf(ncpath)
#' check_crs(nc)
#' @importFrom sf st_crs
#' @importFrom terra crs
#' @importFrom methods is
#' @export
check_crs <- function(x) {
  ref_class <- c("sf", "stars", "SpatVector",
                 "SpatRaster", "SpatRasterDataset")

  if (!any(ref_class %in% class(x))) {
    stop("Input is invalid.\n")
  }
  class_type <- check_packbound(x)
  if (class_type == "sf" && is.na(sf::st_crs(x))) {
    stop("No CRS is defined in the input.
    Please consult the metadata or the data source.\n")
  }
  if (class_type == "terra" && any(is.na(terra::crs(x)), terra::crs(x) == "")) {
    stop("No CRS is defined in the input.
    Please consult the metadata or the data source.\n")
  }

  if (methods::is(x, "sf") || methods::is(x, "stars")) {
    crs_wkt <- sf::st_crs(x)
  } else {
    crs_wkt <- terra::crs(x)
  }

  return(crs_wkt)
}
```


```{r test-check_crs, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("check_crs is working as expected", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  ncpath <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(ncpath)
  nct <- terra::vect(nc)
  crs_checked1 <- check_crs(nc)
  dummy <- character(0)
  crs_checked2 <- check_crs(nct)

  testthat::expect_equal(crs_checked1, sf::st_crs(nc))
  testthat::expect_equal(crs_checked2, terra::crs(nct))
  testthat::expect_error(check_crs(dummy))
  ncna <- nc
  sf::st_crs(ncna) <- NA
  testthat::expect_error(check_crs(ncna))
  nctna <- nct
  terra::crs(nctna) <- ""
  testthat::expect_error(check_crs(nctna))

})

```

```{r, send_to = "R/check.R"}
#' Check if the boundary of the vector/raster object is inside the reference
#' @param input_object sf/stars/SpatVector/SpatRaster object.
#' @param reference sf/stars/SpatVector/SpatRaster object.
#' @returns logical
#' @author Insang Song \email{geoissong@@gmail.com}
#' @importFrom methods is
#' @importFrom sf st_bbox
#' @importFrom sf st_as_sfc
#' @importFrom sf st_covered_by
#' @export
check_within_reference <- function(input_object, reference) {
  if (!any(
    methods::is(input_object, "sf"),
    methods::is(input_object, "stars"),
    methods::is(input_object, "SpatVector"),
    methods::is(input_object, "SpatRaster")
  )) {
    stop("Input is invalid.\n")
  }

  if (!any(
    methods::is(reference, "sf"),
    methods::is(reference, "stars"),
    methods::is(reference, "SpatVector"),
    methods::is(reference, "SpatRaster")
  )) {
    stop("Reference is invalid.\n")
  }

  bbox_input <- input_object |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  bbox_reference <- reference |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  iswithin <- sf::st_covered_by(bbox_input, bbox_reference)
  iswithin <- length(iswithin[[1]])
  iswithin <- (iswithin == 1)
  invisible(iswithin)
}


```

```{r test-within-reference, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("nc data is within the mainland US", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  ncpath <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(ncpath)
  nc <- sf::st_transform(nc, "EPSG:4326")
  mainland_vec <- c(xmin = -128, xmax = -62, ymin = 22, ymax = 52)
  mainland_box <- extent_to_polygon(mainland_vec, output_class = "sf")
  within_res <- check_within_reference(nc, mainland_box)
  testthat::expect_equal(within_res, TRUE)

  # error cases
  testthat::expect_error(check_within_reference(list(1), mainland_box))
  testthat::expect_error(check_within_reference(nc, list(1)))

})

```

```{r, send_to = "R/processing.R"}
#' Calculate SEDC covariates
#' @param point_from SpatVector object. Locations where
#'  the sum of SEDCs are calculated.
#' @param point_to SpatVector object. Locations where each SEDC is calculated.
#' @param id character(1). Name of the unique id field in point_to.
#' @param sedc_bandwidth numeric(1).
#' Distance at which the source concentration is reduced to
#'  exp(-3) (approximately -95 %)
#' @param threshold numeric(1). For computational efficiency,
#'  the nearest points in threshold will be selected.
#'  Default is \code{2 * sedc_bandwidth}.
#' @param target_fields character(varying). Field names in characters.
#' @return data.frame (tibble) object with input field names with
#'  a suffix \code{"_sedc"} where the sums of EDC are stored.
#'  Additional attributes are attached for the EDC information.
#'    - attr(result, "sedc_bandwidth"): the bandwidth where
#'  concentration reduces to approximately five percent
#'    - attr(result, "sedc_threshold"): the threshold distance
#'  at which emission source points are excluded beyond that
#' @note Distance calculation is done with terra functions internally.
#'  Thus, the function internally converts sf objects in
#'  \code{point_*} arguments to terra.
#'  The optimal EDC should be carefully chosen by users.
#' @author Insang Song
#' @importFrom dplyr as_tibble
#' @importFrom dplyr left_join
#' @importFrom dplyr summarize
#' @importFrom dplyr mutate
#' @importFrom dplyr group_by
#' @importFrom dplyr all_of
#' @importFrom dplyr across
#' @importFrom dplyr ungroup
#' @importFrom terra nearby
#' @importFrom terra distance
#' @importFrom terra buffer
#' @importFrom rlang sym
#' @export
calculate_sedc <-
  function(
    point_from = NULL,
    point_to = NULL,
    id = NULL,
    sedc_bandwidth = NULL,
    threshold = NULL,
    target_fields = NULL
  ) {
    # define sources, set SEDC exponential decay range
    len_point_from <- seq_len(nrow(point_from))
    len_point_to <- seq_len(nrow(point_to))

    pkginfo_from <- check_packbound(point_from)
    pkginfo_to <- check_packbound(point_to)

    if (any(pkginfo_from == "sf", pkginfo_to == "sf")) {
      point_from <- switch_packbound(point_from)
      point_to <- switch_packbound(point_to)
    }
    point_from$from_id <- len_point_from
    # select egrid_v only if closer than 3e5 meters from each aqs
    point_from_buf <-
      terra::buffer(
        point_from,
        width = threshold,
         quadsegs = 90
      )
    point_to <- point_to[point_from_buf, ]
    point_to$to_id <- len_point_to

    # near features with distance argument: only returns integer indices
    near_from_to <- terra::nearby(point_from, point_to, distance = threshold)
    # attaching actual distance
    dist_near_to <- terra::distance(point_from, point_to)
    dist_near_to_df <- as.vector(dist_near_to)
    # adding integer indices
    dist_near_to_tdf <-
      expand.grid(
                  from_id = len_point_from,
                  to_id = len_point_to)
    dist_near_to_df <- cbind(dist_near_to_tdf, dist = dist_near_to_df)

    # summary
    near_from_to <- near_from_to |>
      dplyr::as_tibble() |>
      dplyr::left_join(data.frame(point_from)) |>
      dplyr::left_join(data.frame(point_to)) |>
      dplyr::left_join(dist_near_to_df) |>
      # per the definition in
      # https://mserre.sph.unc.edu/BMElab_web/SEDCtutorial/index.html
      # exp(-3) is about 0.05
      dplyr::mutate(w_sedc = exp((-3 * dist) / sedc_bandwidth)) |>
      dplyr::group_by(!!rlang::sym(id)) |>
      dplyr::summarize(
        dplyr::across(
          dplyr::all_of(target_fields),
          list(sedc = ~sum(w_sedc * ., na.rm = TRUE))
        )
      ) |>
      dplyr::ungroup()

    attr(near_from_to, "sedc_bandwidth") <- sedc_bandwidth
    attr(near_from_to, "sedc_threshold") <- threshold

    return(near_from_to)
  }

```


```{r test-sedc, eval = FALSE}
testthat::test_that("SEDC are well calculated.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("dplyr")
  withr::local_package("testthat")
  withr::local_options(list(sf_use_s2 = FALSE))

  # read and generate data
  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <-
    readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncrand <- terra::spatSample(ncpoly, 250L)
  ncrand$pollutant1 <- stats::rgamma(250L, 1, 0.01)
  ncrand$pollutant2 <- stats::rnorm(250L, 30, 4)
  ncrand$pollutant3 <- stats::rbeta(250L, 0.5, 0.5)

  polnames <- paste0("pollutant", 1:3)

  testthat::expect_no_error(
    sedc_calc <-
      calculate_sedc(ncpnts, ncrand, "pid", 3e4L, 5e4L, polnames)
  )
  testthat::expect_s3_class(sedc_calc, "data.frame")

  testthat::expect_equal(
    sum(paste0(polnames, "_sedc") %in% names(sedc_calc)),
    length(polnames)
  )
  testthat::expect_true(!is.null(attr(sedc_calc, "sedc_bandwidth")))
  testthat::expect_true(!is.null(attr(sedc_calc, "sedc_threshold")))

  ncpnts <-
    readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncpnts <- sf::st_transform(ncpnts, "EPSG:5070")
  ncrandsf <- sf::st_as_sf(ncrand)

  testthat::expect_no_error(
    calculate_sedc(ncpnts, ncrandsf, "pid", 3e4L, 5e4L, polnames)
  )
})

```


```{r, send_to = "R/processing.R"}
#' Computing area weighted covariates using two polygon sf or SpatVector objects
#' @param poly_in A sf/SpatVector object at weighted means will be calculated.
#' @param poly_weight A sf/SpatVector object from
#'  which weighted means will be calculated.
#' @param id_poly_in character(1).
#'  The unique identifier of each polygon in poly_in
#' @return A data.frame with all numeric fields of area-weighted means.
#' @description When poly_in and poly_weight are different classes,
#'  poly_weight will be converted to the class of poly_in.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' # package
#' library(sf)
#'
#' # run
#' nc <- sf::st_read(system.file("shape/nc.shp", package="sf"))
#' nc <- sf::st_transform(nc, 5070)
#' pp <- sf::st_sample(nc, size = 300)
#' pp <- sf::st_as_sf(pp)
#' pp[["id"]] <- seq(1, nrow(pp))
#' sf::st_crs(pp) <- "EPSG:5070"
#' ppb <- sf::st_buffer(pp, nQuadSegs=180, dist = units::set_units(20, 'km'))
#'
#' system.time({ppb_nc_aw <- aw_covariates(ppb, nc, 'id')})
#' summary(ppb_nc_aw)
#' #### Example of aw_covariates ends ####
#' @importFrom terra expanse
#' @importFrom rlang sym
#' @importFrom dplyr where
#' @importFrom dplyr group_by
#' @importFrom dplyr summarize
#' @importFrom dplyr across
#' @importFrom dplyr ungroup
#' @importFrom terra intersect
#' @importFrom sf st_interpolate_aw
#' @importFrom stats weighted.mean
#' @export
aw_covariates <-
  function(
    poly_in = NULL,
    poly_weight = NULL,
    id_poly_in = "ID"
  ) {
    if (!any(
      methods::is(poly_in, "sf"),
      methods::is(poly_weight, "sf"),
      methods::is(poly_in, "SpatVector"),
      methods::is(poly_weight, "SpatVector")
    )) {
      stop("Inputs have invalid classes.\n")
    }
    ## distinguish numeric and nonnumeric columns
    index_numeric <-
      grep("(integer|numeric)", unlist(sapply(poly_weight, class)))

    aw_covariates_terra <-
      function(
        poly_in = NULL,
        poly_weight = NULL,
        id_poly_in = id_poly_in
      ) {
          poly_intersected <- terra::intersect(poly_in, poly_weight)
          poly_intersected[["area_segment_"]] <-
            terra::expanse(poly_intersected)
          poly_intersected <- data.frame(poly_intersected) |>
            dplyr::group_by(!!rlang::sym(id_poly_in)) |>
            dplyr::summarize(
              dplyr::across(
                dplyr::where(is.numeric),
                ~stats::weighted.mean(., w = area_segment_)
              )
            ) |>
            dplyr::ungroup()
          return(poly_intersected)
      }

    class_poly_in <- check_packbound(poly_in)
    class_poly_weight <- check_packbound(poly_weight)

    if (class_poly_in != class_poly_weight) {
      poly_weight <- switch_packbound(poly_weight)
    }

    switch(class_poly_in,
      sf =
      suppressWarnings(
        sf::st_interpolate_aw(
          poly_weight[, index_numeric],
          poly_in, extensive = FALSE
        )
      ),
      terra =
      aw_covariates_terra(
        poly_in, poly_weight[, index_numeric],
        id_poly_in = id_poly_in
      )
    )

  }


```


```{r aw-test, eval = FALSE, send_to = "tests/testthat/test-processing.R"}

testthat::test_that("aw_covariates works as expected.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("units")
  withr::local_package("dplyr")
  withr::local_package("testthat")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- sf::st_read(system.file("shape/nc.shp", package = "sf"))
  nc <- sf::st_transform(nc, 5070)
  pp <- sf::st_sample(nc, size = 300)
  pp <- sf::st_as_sf(pp)
  pp[["id"]] <- seq(1, nrow(pp))
  sf::st_crs(pp) <- "EPSG:5070"
  ppb <- sf::st_buffer(pp, nQuadSegs = 180, dist = units::set_units(20, "km"))

  testthat::expect_no_error(
    system.time({ppb_nc_aw <- aw_covariates(ppb, nc, "id")})
  )
  expect_s3_class(ppb_nc_aw, "sf")

  # terra
  ppb_t <- terra::vect(ppb)
  nc_t <- terra::vect(nc)
  testthat::expect_no_error(
    system.time({ppb_nc_aw <- aw_covariates(ppb_t, nc_t, "id")})
  )
  expect_s3_class(ppb_nc_aw, "data.frame")

  # auto convert formats
  testthat::expect_no_error(
    system.time({ppb_nc_aw <- aw_covariates(ppb_t, nc, "id")})
  )
  expect_s3_class(ppb_nc_aw, "data.frame")

  # error case
  testthat::expect_error(aw_covariates(as.list(ppb_t), nc, "id"))
})



```


```{r, send_to = "R/check.R"}
#' Detect classes in function arguments
#' @param args Any list, but preferably generated by \code{list(...)} inside
#' a function.
#' @param search character(1). Class name to search. Partial match is supported.
#' @returns logical vector.
#' @author Insang Song
#' @description When a R function is defined in an ordinary
#' fashion (i.e., assigning a function by \code{<- function(...)})
#' would be subject to ambiguity particularly if the function
#' name is the same as the generic function name(s).
#' This function supports detecting classes of arguments in
#' a loosely defined function.
#' @export
detect_class <- function(
  args = NULL,
  search = NULL
) {
  searchphrase <- sprintf("(%s)", search)
  args_scanned <- lapply(args, function(x) any(grepl(searchphrase, class(x))))
  args_scanned <- sapply(args_scanned, any)
  return(args_scanned)
}


```


```{r test-detect-class, eval = FALSE, send_to = "tests/testthat/test-detect_class.R"}
testthat::test_that("classes are detected.", {
  withr::local_package("terra")
  random_df <- data.frame(x = runif(10), y = runif(10))
  random_tv <- terra::vect(random_df, geom = c("x", "y"))
  test_args <- list(vector = random_tv,
                    func = mean,
                    pipi = pi,
                    zodiac = "Horse")
  set_detected <- detect_class(test_args, "SpatVector")
  # test partial match
  set_detectedp <- detect_class(test_args, "Spat")

  testthat::expect_true(is.logical(set_detected))
  testthat::expect_true(is.logical(set_detectedp))
  # both are the same
  testthat::expect_true(all.equal(set_detected, set_detectedp))

  vect_pop <- test_args[set_detected][[1]]
  testthat::expect_s4_class(vect_pop, "SpatVector")

  # does it well in a function as designed?
  downy <- function(...) {
    largs <- list(...)
    detect_class(largs, "SpatVector")
  }
  bear <- downy(v = random_tv, f = mean, pipi = pi)

  testthat::expect_true(is.logical(bear))
  testthat::expect_true(bear[[1]] == TRUE)

})

```


```{r, send_to = "R/scale_process.R"}
#' Parallelization error fallback
#' @param err Error status or message.
#' @param fun function.
#' @param debug logical(1). Print error messages (`TRUE`) or not (`FALSE`)
#' @returns data.frame with one column
#' @note This function assumes that the `fun` has an argument named
#' `"id"`.
#' @author Insang Song
#' @export
par_fallback <-
  function(
    err = NULL,
    fun = NULL,
    debug = FALSE
  ) {
    if (debug) {
      print(err)
    }
    fallback <- data.frame(ID = NA)
    fun_args <- formals(fun)
    indx <- grepl("id", names(fun_args))
    if (any(indx)) {
      detected_id <- fun_args[indx]
    } else {
      detected_id <- "id"
    }
    colnames(fallback)[1] <- detected_id
    return(fallback)
  }

```

```{r test-par_fallback, eval = FALSE, send_to = "tests/testthat/test-par_fallback.R"}
testthat::test_that(
  "par_fallback works",
  {
    withr::local_package("terra")
    dc <- terra::vect("POINT (12 8)", crs = "EPSG:4326")
    dc$site_id <- "SITE1"
    rdd <- terra::rast(nrow = 10, ncol = 10, crs = "EPSG:4326")
    terra::ext(rdd) <-
      c(xmin = 10, xmax = 20, ymin = 0, ymax = 10)
    terra::values(rdd) <- runif(100L)

    foo1 <- extract_with
    foo2 <- mean
    testthat::expect_no_error(
      par_fallback(
        err = foo1(dc, rdd, id = "site_id", mode = "buffer", radius = 5e4),
        fun = foo1,
        debug = TRUE
      )
    )
    testthat::expect_no_error(
      par_fallback(
        err = foo1(),
        fun = foo2,
        debug = FALSE
      )
    )
  }
)


```

```{r, send_to = "R/scale_process.R"}
#' @title Process a given function in the entire or partial computational grids
#' @description Currently only accepting \link[future]{multicore} setting
#'  (single node, single process, and multiple threads).
#'  For details of the terminology in \code{future} package,
#'  refer to \link[future]{plan}. This function assumes that
#'  users have one raster file and a sizable and spatially distributed
#'  target locations. Each thread will process ceiling($|N_g|/|N_t|$) grids
#'  where $|N_g|$ denotes the number of grids and $|N_t|$ denotes
#'  the number of threads.
#' @note In dynamic dots (\code{...}), the first and second
#' arguments should be the \code{fun_dist} arguments where
#' sf/SpatVector objects are accepted.
#' Virtually any sf/terra functions that accept two arguments
#' can be put in \code{fun_dist}, but please be advised that
#' some spatial operations do not necessarily give the
#' exact result from what would have been done single-thread.
#' For example, distance calculated through this function may return the
#' lower value than actual because the computational region was reduced.
#' This would be the case especially where the target features
#' are spatially sparsely distributed.
#' @param grids sf/SpatVector object. Computational grids.
#'  It takes a strict assumption that the grid input is
#'  an output of \code{get_computational_regions}
#' @param grid_target_id character(1) or numeric(2).
#'  Default is NULL. If NULL, all grid_ids are used.
#'  \code{"id_from:id_to"} format or
#'  \code{c(unique(grid_id)[id_from], unique(grid_id)[id_to])}
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param fun_dist `sf`, `terra` or `chopin` functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' @returns a data.frame object with computation results.
#'  For entries of the results, consult the function used in
#'  \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#'
#' @examples
#' library(future)
#' plan(multicore, workers = 4)
#' # Does not run ...
#' # distribute_process_grid()
#' @import future
#' @importFrom future.apply future_lapply
#' @importFrom rlang inject
#' @importFrom rlang !!!
#' @export
distribute_process_grid <-
  function(
    grids,
    grid_target_id = NULL,
    debug = FALSE,
    fun_dist,
    ...
  ) {
    if (is.character(grid_target_id) && !grepl(":", grid_target_id)) {
      stop("Character grid_target_id should be in a form of 'startid:endid'.\n")
    }
    if (is.numeric(grid_target_id)) {
      if (length(grid_target_id) != 2) {
        stop(
          "Numeric grid_target_id should be in a form of c(startid, endid).\n"
        )
      }
      grid_target_ids <- unlist(grids$original[["CGRIDID"]])[grid_target_id]
    }
    # subset using grids and grid_id
    if (is.null(grid_target_id)) {
      grid_target_ids <- unlist(grids$original[["CGRIDID"]])
    }
    if (is.character(grid_target_id)) {
      grid_id_parsed <- strsplit(grid_target_id, ":", fixed = TRUE)[[1]]
      grid_target_ids <-
        c(which(unlist(grids$original[["CGRIDID"]]) == grid_id_parsed[1]),
          which(unlist(grids$original[["CGRIDID"]]) == grid_id_parsed[2]))
    }

    grids_target <-
      grids$original[grid_target_ids %in% unlist(grids$original[["CGRIDID"]]), ]
    grids_target_list <- split(grids_target, unlist(grids_target[["CGRIDID"]]))

    results_distributed <-
      future.apply::future_lapply(
        grids_target_list,
        function(grid) {
          sf::sf_use_s2(FALSE)

          run_result <- tryCatch({
            args_input <- list(...)
            ## Strongly assuming that
            # the first is "at", the second is "from"
            args_input[[1]] <-
              args_input[[1]][grid, ]
            if (methods::is(args_input[[2]], "SpatVector")) {
              gpad_in <- grids$padded[grids$padded$CGRIDID == grid$CGRIDID, ]
              args_input[[2]] <- args_input[[2]][gpad_in, ]
            }
            if (!"id" %in% names(formals(fun_dist))) {
              args_input$id <- NULL
            }

            res <- rlang::inject(fun_dist(!!!args_input))
            cat(
              sprintf(
                "Your input function was successfully run at CGRIDID: %s\n",
                as.character(unlist(grid[["CGRIDID"]]))
              )
            )

            if (!is.data.frame(res)) {
              res <- as.data.frame(res)
            }

            return(res)
          },
          error = function(e) {
            par_fallback(e, fun_dist, debug)
            # if (debug) print(e)
            # fallback <- data.frame(ID = NA)
            # if ("id" %in% names(formals(fun_dist))) {
            #   detected_id <- list(...)
            #   detected_id <- detected_id$id
            # } else {
            #   detected_id <- "id"
            # }
            # colnames(fallback)[1] <- detected_id
            # return(fallback)
          })

          return(run_result)
        },
        future.seed = TRUE,
        future.packages = c("terra", "sf", "dplyr", "chopin", "exactextractr")
      )
    results_distributed <- do.call(dplyr::bind_rows, results_distributed)

    return(results_distributed)
  }


#' @title Process a given function using a hierarchy in input data
#'
#' @description "Hierarchy" refers to a system,
#'  which divides the entire study region into multiple subregions.
#'  It is oftentimes reflected in an area code system
#'  (e.g., FIPS for US Census geographies, HUC-4, -6, -8, etc.).
#'  Currently only accepting \link[future]{multicore} setting
#'  (single node, single process, and multiple threads).
#'  For details of the terminology in \code{future} package,
#'  refer to \link[future]{plan}.
#'  This function assumes that users have one raster file and
#'  a sizable and spatially distributed target locations.
#'  Each thread will process ceiling($|N_{g}|/|N_{t}|$) grids where
#'  $|N_{g}|$ denotes the number of grids and $|N_{t}|$ denotes
#'  the number of threads. Please be advised that
#'  accessing the same file simultaneously with
#'  multiple processes may result in errors.
#' @note In dynamic dots (\code{...}), the first and second
#' arguments should be the \code{fun_dist} arguments where
#' `sf`/`SpatVector` objects are accepted.
#' Virtually any sf/terra functions that accept two arguments
#' can be put in \code{fun_dist}, but please be advised that
#' some spatial operations do not necessarily give the
#' exact result from what would have been done single-thread.
#' For example, distance calculated through this function may return the
#' lower value than actual because the computational region was reduced.
#' This would be the case especially where the target features
#' are spatially sparsely distributed.
#' @param regions sf/SpatVector object.
#'  Computational regions. Only polygons are accepted.
#' @param split_level character(nrow(regions)) or character(1).
#'  The regions will be split by the common level value.
#'  The level should be higher than the original data level.
#'  A field name with the higher level information is also accepted.
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param fun_dist sf, terra, or chopin functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' @returns a data.frame object with computation results.
#'  For entries of the results, consult the function used in
#'  \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' library(future)
#' plan(multicore, workers = 4L)
#' # Does not run ...
#' # library(tigris)
#' # distribute_process_hierarchy()
#' @import future
#' @importFrom future.apply future_lapply
#' @importFrom rlang inject
#' @importFrom rlang !!!
#' @export
distribute_process_hierarchy <-
  function(
    regions,
    split_level = NULL,
    debug = FALSE,
    fun_dist,
    ...
  ) {

    if (!any(length(split_level) == 1, length(split_level) == nrow(regions))) {
      stop("The length of split_level is not valid.")
    }
    split_level <-
      ifelse(length(split_level) == nrow(regions),
             split_level,
             unlist(regions[[split_level]]))

    regions_list <- base::split(split_level, split_level)

    results_distributed <-
      future_lapply(
        regions_list,
        function(subregion) {
          sf::sf_use_s2(FALSE)
          run_result <-
            tryCatch(
              {
                # TODO: padded subregion to deal with
                # edge cases; how to determine padding?
                subregion <-
                  regions[startsWith(split_level, subregion)]
                args_input <- list(...)
                ## Strongly assuming that
                # the first is "at", the second is "from"
                args_input[[1]] <-
                  args_input[[1]][subregion, ]
                if (!"id" %in% names(formals(fun_dist))) {
                  args_input$id <- NULL
                }

                res <- rlang::inject(fun_dist(!!!args_input))
                if (!is.data.frame(res)) {
                  res <- as.data.frame(res)
                }
                return(res)
              },
              error =
              function(e) {
                par_fallback(e, fun_dist, debug)
                # if (debug) print(e)
                # fallback <- data.frame(ID = NA)
                # if ("id" %in% names(formals(fun_dist))) {
                #   detected_id <- list(...)
                #   detected_id <- detected_id$id
                # } else {
                #   detected_id <- "id"
                # }
                # colnames(fallback)[1] <- detected_id
                # return(fallback)
              }
            )
          return(run_result)
        },
        future.seed = TRUE,
        future.packages = c("terra", "sf", "dplyr",
                            "chopin", "future", "exactextractr")
      )
    results_distributed <- do.call(dplyr::bind_rows, results_distributed)

    return(results_distributed)
  }




#' @title Process a given function over multiple large rasters
#' @description Large raster files usually exceed the memory capacity in size.
#'  Cropping a large raster into a small subset even consumes
#'  a lot of memory and adds processing time.
#'  This function leverages terra SpatRaster proxy
#'  to distribute computation jobs over multiple cores.
#'  It is assumed that users have multiple large raster files
#'  in their disk, then each file path is assigned to a thread.
#'  Each thread will directly read raster values from
#'  the disk using C++ pointers that operate in terra functions.
#'  For use, it is strongly recommended to use vector data with
#'  small and confined spatial extent for computation to avoid
#'  out-of-memory error. For this, users may need
#'  to make subsets of input vector objects in advance.
#' @param filenames character(n). A vector or list of
#'  full file paths of raster files. n is the total number of raster files.
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param fun_dist sf, terra, or chopin functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' @returns a data.frame object with computation results.
#'  For entries of the results,
#'  consult the function used in \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#'
#' @examples
#' library(future)
#' plan(multicore, workers = 4)
#' # Does not run ...
#' # distribute_process_multirasters()
#' @import future
#' @import future.apply
#' @import doFuture
#' @export
distribute_process_multirasters <-
  function(
    filenames,
    debug = FALSE,
    fun_dist,
    ...
  ) {

    file_list <- split(filenames, filenames)
    results_distributed <-
      future_lapply(
        file_list,
        function(path) {
          run_result <-
            try({
              args_input <- list(...)
              vect_target_tr <- detect_class(args_input, "SpatVector")
              vect_target_sf <- detect_class(args_input, "sf")
              vect_target <- (vect_target_tr | vect_target_sf)
              vect_ext <- args_input[vect_target]
              vect_ext <- terra::ext(vect_ext[[1]])

              rast_target <- which(detect_class(args_input, "SpatRaster"))
              args_input[[rast_target]] <-
                rast_short(rasterpath = path, win = vect_ext)
              if (!"id" %in% names(formals(fun_dist))) args_input$id <- NULL

              res <- rlang::inject(fun_dist(!!!args_input))
              if (!is.data.frame(res)) res <- as.data.frame(res)
              res$base_raster <- path
              return(res)
            }
            )
          if (inherits(run_result, "try-error")) {
            par_fallback(run_result, fun_dist, debug)
          }
          #   if (debug) {
          #     message(attr(run_result, "condition")$message)
          #   }
          #   fallback <- data.frame(ID = NA)
          #   if ("id" %in% names(formals(fun_dist))) {
          #     detected_id <- list(...)
          #     detected_id <- detected_id$id
          #   }
          #   colnames(fallback)[1] <- detected_id
          #   run_result <- fallback
          # }
          # return(run_result)
        },
        future.seed = TRUE,
        future.packages =
        c("terra", "sf", "dplyr", "rlang",
          "chopin", "future",
          "exactextractr")
      )
    results_distributed <- do.call(dplyr::bind_rows, results_distributed)

    return(results_distributed)
  }



```


```{r test-distribute, eval=FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that("Processes are properly spawned and compute", {
  withr::local_package("terra")
  withr::local_package("sf")
  withr::local_package("future")
  withr::local_package("future.apply")
  withr::local_package("dplyr")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <-
    readRDS(
            testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncelev <-
    terra::unwrap(
      readRDS(testthat::test_path("..", "testdata", "nc_srtm15_otm.rds"))
    )
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")

  ncsamp <-
    terra::spatSample(
      terra::ext(ncelev),
      1e4L,
      lonlat = FALSE,
      as.points = TRUE
    )
  ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))

  nccompreg <-
    get_computational_regions(
      input = ncpnts,
      mode = "grid",
      nx = 6L,
      ny = 4L,
      padding = 3e4L
    )
  res <-
    suppressWarnings(
      distribute_process_grid(
        grids = nccompreg,
        grid_target_id = NULL,
        fun_dist = extract_with_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )

  testthat::expect_error(
    suppressWarnings(
      distribute_process_grid(
        grids = nccompreg,
        grid_target_id = "1/10",
        fun_dist = extract_with_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )

  testthat::expect_error(
    suppressWarnings(
      distribute_process_grid(
        grids = nccompreg,
        grid_target_id = c(1, 100, 125),
        fun_dist = extract_with_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )


  testthat::expect_no_error(
    suppressWarnings(
      distribute_process_grid(
        grids = nccompreg,
        grid_target_id = "1:10",
        fun_dist = extract_with_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )


  testthat::expect_no_error(
    suppressWarnings(
      distribute_process_grid(
        grids = nccompreg,
        grid_target_id = c(1, 3),
        fun_dist = extract_with_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )

  testthat::expect_true(is.list(nccompreg))
  testthat::expect_s4_class(nccompreg$original, "SpatVector")
  testthat::expect_s3_class(res, "data.frame")
  testthat::expect_true(!anyNA(unlist(res)))

  testthat::expect_no_error(
    suppressWarnings(
      resnas <-
        distribute_process_grid(
          grids = nccompreg,
          grid_target_id = "1:10",
          fun_dist = extract_with_buffer,
          points = ncpnts,
          surf = ncelev,
          qsegs = 90L,
          radius = -5e3L,
          id = "pid"
        )
    )
  )

  testthat::expect_s3_class(resnas, "data.frame")
  testthat::expect_true(anyNA(resnas))

  testthat::expect_no_error(
    suppressWarnings(
      resnas0 <-
        distribute_process_grid(
          grids = nccompreg,
          grid_target_id = "1:10",
          fun_dist = terra::nearest,
          x = ncpnts,
          y = ncsamp,
          id = "pid"
        )
    )
  )

})


```

```{r test-runhierarchy, eval = FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that(
  "Processes are properly spawned and compute over hierarchy", {
    withr::local_package("terra")
    withr::local_package("sf")
    withr::local_package("future")
    withr::local_package("future.apply")
    withr::local_package("dplyr")
    withr::local_options(list(sf_use_s2 = FALSE))

    ncpath <- testthat::test_path("..", "testdata", "nc_hierarchy.gpkg")
    nccnty <- terra::vect(ncpath, layer = "county")
    nctrct <- sf::st_read(ncpath, layer = "tracts")
    nctrct <- terra::vect(nctrct)
    ncelev <-
      terra::unwrap(
        readRDS(
          testthat::test_path("..", "testdata", "nc_srtm15_otm.rds")
        )
      )
    terra::crs(ncelev) <- "EPSG:5070"
    names(ncelev) <- c("srtm15")

    ncsamp <-
      terra::spatSample(
        terra::ext(ncelev),
        1e4L,
        lonlat = FALSE,
        as.points = TRUE
      )
    ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))

    testthat::expect_no_error(
      res <-
        suppressWarnings(
          distribute_process_hierarchy(
            regions = nccnty,
            split_level = "GEOID",
            fun_dist = extract_with_polygons,
            polys = nctrct,
            surf = ncelev,
            id = "GEOID",
            func = "mean"
          )
        )
    )

    testthat::expect_error(
      suppressWarnings(
        distribute_process_hierarchy(
          regions = nccnty,
          split_level = c(1, 2, 3),
          fun_dist = extract_with_polygons,
          polys = nctrct,
          surf = ncelev,
          id = "GEOID",
          func = "mean"
        )
      )
    )

    testthat::expect_s3_class(res, "data.frame")
    testthat::expect_equal(!any(is.na(unlist(res))), TRUE)

    testthat::expect_no_error(
      suppressWarnings(
        resnas <-
          distribute_process_hierarchy(
            regions = nccnty,
            split_level = "GEOID",
            fun_dist = terra::nearest,
            polys = nctrct,
            surf = ncelev
          )
      )
    )

    testthat::expect_s3_class(resnas, "data.frame")
    testthat::expect_true(anyNA(resnas))

    testthat::expect_no_error(
      suppressWarnings(
        resnasx <-
          distribute_process_hierarchy(
            regions = nccnty,
            debug = TRUE,
            split_level = "GEOID",
            fun_dist = extract_with_buffer,
            points = terra::centroids(nctrct),
            surf = ncelev,
            id = "GEOID",
            radius = -1e3L
          )
      )
    )

    testthat::expect_no_error(
      suppressWarnings(
        resnasz <-
          distribute_process_hierarchy(
            regions = nccnty,
            debug = TRUE,
            split_level = "GEOID",
            fun_dist = terra::nearest,
            x = nctrct,
            y = ncsamp
          )
      )
    )
  }
)



```


```{r test-generic-function, eval = FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that("generic function should be parallelized properly", {
  withr::local_package("terra")
  withr::local_package("sf")
  withr::local_package("future")
  withr::local_package("future.apply")
  withr::local_package("dplyr")
  withr::local_options(list(sf_use_s2 = FALSE))

  # main test
  pnts <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  pnts <- terra::vect(pnts)
  rd1 <-
    terra::vect(testthat::test_path("..", "testdata", "ncroads_first.gpkg"))

  pnts <- terra::project(pnts, "EPSG:5070")
  rd1 <- terra::project(rd1, "EPSG:5070")
  # expect

  nccompreg <-
    get_computational_regions(
      input = pnts,
      mode = "grid",
      nx = 6L,
      ny = 4L,
      padding = 3e4L
    )
  future::plan(future::multicore, workers = 6L)
  testthat::expect_no_error(
    res <-
      suppressWarnings(
        distribute_process_grid(
          grids = nccompreg,
          fun_dist = terra::nearest,
          x = pnts,
          y = rd1
        )
      )
  )
  testthat::expect_s3_class(res, "data.frame")
  testthat::expect_equal(nrow(res), nrow(pnts))

})

```

```{r test-multirasters, eval = FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that(
  "Processes are properly spawned and compute over multirasters", {
  withr::local_package("terra")
  withr::local_package("sf")
  withr::local_package("future")
  withr::local_package("future.apply")
  withr::local_package("dplyr")
  withr::local_options(
    list(
      sf_use_s2 = FALSE,
      future.resolve.recursive = 2L
    )
  )

  ncpath <- testthat::test_path("..", "testdata", "nc_hierarchy.gpkg")
  nccnty <- terra::vect(ncpath, layer = "county")
  ncelev <-
    terra::unwrap(
      readRDS(
        testthat::test_path("..", "testdata", "nc_srtm15_otm.rds")
      )
    )
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")
  tdir <- tempdir(check = TRUE)
  terra::writeRaster(ncelev, file.path(tdir, "test1.tif"), overwrite = TRUE)
  terra::writeRaster(ncelev, file.path(tdir, "test2.tif"), overwrite = TRUE)
  terra::writeRaster(ncelev, file.path(tdir, "test3.tif"), overwrite = TRUE)
  terra::writeRaster(ncelev, file.path(tdir, "test4.tif"), overwrite = TRUE)
  terra::writeRaster(ncelev, file.path(tdir, "test5.tif"), overwrite = TRUE)

  testfiles <- list.files(tdir, pattern = "tif$", full.names = TRUE)
  testthat::expect_no_error(
    res <- distribute_process_multirasters(
      filenames = testfiles,
      fun_dist = extract_with_polygons,
      polys = nccnty,
      surf = ncelev,
      id = "GEOID",
      func = "mean"
    )
  )
  testthat::expect_s3_class(res, "data.frame")
  testthat::expect_true(!anyNA(res))

  testfiles_corrupted <- c(testfiles, "/home/runner/fallin.tif")
  testthat::expect_condition(
    resnas <- distribute_process_multirasters(
      filenames = testfiles_corrupted,
      fun_dist = extract_with_polygons,
      polys = nccnty,
      surf = ncelev,
      id = "GEOID",
      func = "mean"
    )
  )

  testthat::expect_s3_class(resnas, "data.frame")
  testthat::expect_true(anyNA(resnas))

  # error case
  future::plan(future::sequential)
  testthat::expect_condition(
    resnasx <- distribute_process_multirasters(
      filenames = testfiles_corrupted,
      debug = TRUE,
      fun_dist = extract_with_polygons,
      polys = nccnty,
      surf = ncelev,
      id = "GEOID",
      func = "mean"
    )
  )

})

```

```{r, eval = FALSE, include = FALSE}
adhoc <- function() {
  library(sf)
  library(terra)
  library(dplyr)
  library(future)
  library(future.apply)
  library(exactextractr)
  library(chopin)

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpnts <-
    readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncelev <-
    terra::unwrap(
      readRDS(
        testthat::test_path("..", "testdata", "nc_srtm15_otm.rds")
      )
    )
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")

  nccompreg <-
    get_computational_regions(
      input = ncpnts,
      mode = "grid",
      nx = 6L,
      ny = 4L,
      padding = 3e4L
    )

  distribute_process_grid(
    grids = nccompreg,
    grid_target_id = NULL,
    fun_dist = extract_with_buffer,
    points = ncpnts,
    qsegs = 90L,
    surf = ncelev,
    radius = 5e3L,
    id = "pid"
  )

}
adhoc()


adhoc2 <- function() {
        library(sf)
  library(terra)
  library(dplyr)
  library(future)
  library(future.apply)
  library(exactextractr)
  library(chopin)

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <- readRDS(testthat::test_path("..", "testdata", "nc_random_point.rds"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncelev <- terra::unwrap(readRDS(testthat::test_path("..", "testdata", "nc_srtm15_otm.rds")))
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")

  nccompreg <-
    get_computational_regions(
      input = ncpnts,
      mode = 'grid',
      nx = 6L,
      ny = 4L,
      padding = 3e4L)

      detected_id <- "pid"
      grids_target_list <- split(nccompreg$original, unlist(nccompreg$original[["CGRIDID"]]))
      future.apply::future_lapply(
      grids_target_list,
      \(x) {
        sf::sf_use_s2(FALSE)
        
        run_result <- tryCatch({
          res <- extract_with_buffer(ncpnts, ncelev, 5e3L, "pid")
          cat(sprintf("Your input function was 
          successfully run at CGRIDID: %s\n",
            
            as.character(unlist(x[["CGRIDID"]]))))
          
          return(res)
        },
        error = function(e) {
          fallback <- data.frame(ID = NA)
          colnames(fallback)[1] <- detected_id
          return(fallback)
        })
        
        return(run_result)
      },
      future.seed = TRUE,
      future.packages = c("terra", "sf", "dplyr", "chopin", "exactextractr"))
}
adhoc2()


extract_with_buffer(points = ncpnts, surf = ncelev, radius = 5e3L, qsegs = 90L, id = "pid")
exactextractr::exact_extract(ncelev, sf::st_as_sf(terra::buffer(ncpnts, 5e3L)), fun = "mean", force_df = TRUE)
```


```{r, eval = FALSE, include = FALSE}
  # future.apply::future_lapply(
  #   nccompreg %>% split(., .$CGRIDID),
  #   \(x) {
  #     sf::sf_use_s2(FALSE)
      
  #     run_result <- tryCatch({
  #       kk <- chopin::extract_with_buffer(ncpnts, ncelev, 30000L, "pid", grid_ref = x)
  #       #fun(...)
  #       #print(xx)
  #       cat(sprintf("Your input function %s was successfully run at CGRIDID: %s\n",
  #         paste0(quote(fun)), as.character(unlist(x[["CGRIDID"]]))))
  #       return(kk)
  #     },
  #     error = function(e) return(data.frame(ID = NA)))
  #     return(run_result)
  #   },
  #   future.seed = TRUE,
  #   future.packages = c("terra", "sf", "dplyr", "chopin", "future"))

  # chopin::extract_with_buffer(ncpnts, ncelev, 30000L, "pid", grid_ref = nccompreg %>% split(., .$CGRIDID) %>% .[[5]])
```

## Documenting the package and building

We finish by running commands that will document, build, and install the package.  It may also be a good idea to check the package from within this file.

```{r run-devtools, eval = TRUE, results = "asis", message = TRUE, echo = TRUE}
litr::document()

# knitr::knit(
#   "./tools/vignettes-sources/v02_distribute_process.Rmd.orig",
#   output = "./tools/vignettes-sources/v02_distribute_process.Rmd"
#   )

if (dir.exists("../figure")) {
  if (!dir.exists("./vignettes/figure")) {
    dir.create("./vignettes/figure")
  }
  file.copy(from = "../figure", to = "./vignettes/figure", recursive = TRUE)
  # unlink("../figure", recursive = TRUE)
}

# devtools::build(pkg = ".")
# knitr::knit(
#   "../tools/vignettes-sources/v02_distribute_process.Rmd.orig",
#   output = "./vignettes/v02_distribute_process.Rmd"
#   )
# cat(getwd())
# print(getwd())
```

```{r, eval = FALSE}
litr::add_pkgdown("../tools/pkgdown-source/_pkgdown.yml")
```


```{r comment=''}
cat(readLines("../tools/pkgdown-source/_pkgdown.yml"), sep = '\n')
```


```{r copy-prebuilt-figures, eval = TRUE}
# here we return to the current working directory "you see"
# for pre-built vignettes
if (dir.exists("../tools/vignettes-sources/figure")) {
  # if (!dir.exists("./vignettes/figure")) {
  #   dir.create("./vignettes/figure")
  # }
  file.copy(from = "../tools/vignettes-sources/figure", to = "./vignettes", recursive = TRUE)
  # unlink("../figure", recursive = TRUE)
}
# pkgbuild::build(path = ".")


```

```{r, include = FALSE}
# When the build was stuck after major/minor function update and
# any vignette is changed, run below.
# knitr::knit(
#   "./tools/vignettes-sources/v02_distribute_process.Rmd.orig",
#   output = "./tools/vignettes-sources/v02_distribute_process.Rmd"
#   )

```

```{r post-hoc-cleaning, echo = F, eval = FALSE}
if (!dir.exists(getwd())) {
  dir.create(getwd())
}


gitpath = gsub("/chopin", "", getwd())
# packdir <- paste0(getwd(), "/chopin")

# if (!dir.exists(paste0(getwd(), "/chopin"))) {
#   dir.create(paste0(getwd(), "/chopin"))
# }
system("unalias cp")
system(paste0("cp -r ", getwd(), "/* ", gitpath))

Sys.sleep(1)

system(paste0("rm -r ", getwd()))

```

```{r post-hoc-manualrun, eval = FALSE}
system(paste0("cp -r ./chopin/* ."))
system("rm -r ./chopin")
# if (!dir.exists("./docs")) {
#   dir.create("./docs")
# }
# system("mv _pkgdown.yml ./docs")

devtools::install(build = TRUE, dependencies = FALSE, build_vignettes = TRUE, quick = TRUE)


devtools::test()
covr::package_coverage()
```

```{r slurm-submission-template, eval = FALSE, include = FALSE}
# slurm submission is here

```